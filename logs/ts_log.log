2025-03-28T17:12:58,317 [DEBUG] main org.pytorch.serve.util.ConfigManager - xpu-smi not available or failed: Cannot run program "xpu-smi": error=2, No such file or directory
2025-03-28T17:12:58,317 [DEBUG] main org.pytorch.serve.util.ConfigManager - xpu-smi not available or failed: Cannot run program "xpu-smi": error=2, No such file or directory
2025-03-28T17:12:58,320 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2025-03-28T17:12:58,320 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2025-03-28T17:12:58,333 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-03-28T17:12:58,333 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-03-28T17:12:58,371 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml
2025-03-28T17:12:58,371 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml
2025-03-28T17:12:58,453 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.12.0
TS Home: /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages
Current directory: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo
Temp directory: /tmp
Metrics config path: /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 20
Max heap size: 16000 M
Python executable: /home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/model_store
Initial Models: model_store/densenet161.mar
Log dir: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/logs
Metrics dir: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 20
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: false
Workflow Store: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
Model API enabled: false
2025-03-28T17:12:58,453 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.12.0
TS Home: /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages
Current directory: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo
Temp directory: /tmp
Metrics config path: /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 20
Max heap size: 16000 M
Python executable: /home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/model_store
Initial Models: model_store/densenet161.mar
Log dir: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/logs
Metrics dir: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 20
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: false
Workflow Store: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
Model API enabled: false
2025-03-28T17:12:58,462 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-03-28T17:12:58,462 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-03-28T17:12:58,471 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model_store/densenet161.mar
2025-03-28T17:12:58,471 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model_store/densenet161.mar
2025-03-28T17:12:59,176 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model densenet161
2025-03-28T17:12:59,176 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model densenet161
2025-03-28T17:12:59,176 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model densenet161
2025-03-28T17:12:59,176 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model densenet161
2025-03-28T17:12:59,176 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model densenet161 loaded.
2025-03-28T17:12:59,176 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model densenet161 loaded.
2025-03-28T17:12:59,176 [WARN ] main org.pytorch.serve.ModelServer - Invalid model config in mar, minWorkers:0, maxWorkers:0
2025-03-28T17:12:59,176 [WARN ] main org.pytorch.serve.ModelServer - Invalid model config in mar, minWorkers:0, maxWorkers:0
2025-03-28T17:12:59,176 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: densenet161, count: 20
2025-03-28T17:12:59,176 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: densenet161, count: 20
2025-03-28T17:12:59,184 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,184 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,184 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,184 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,184 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,186 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,186 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,184 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,185 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,186 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,188 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2025-03-28T17:12:59,188 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2025-03-28T17:12:59,186 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:12:59,303 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2025-03-28T17:12:59,303 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2025-03-28T17:12:59,305 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2025-03-28T17:12:59,305 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2025-03-28T17:12:59,310 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2025-03-28T17:12:59,310 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2025-03-28T17:12:59,311 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2025-03-28T17:12:59,311 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2025-03-28T17:12:59,312 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2025-03-28T17:12:59,312 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2025-03-28T17:12:59,702 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2025-03-28T17:12:59,702 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2025-03-28T17:12:59,888 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743196379
2025-03-28T17:12:59,897 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:216.53779983520508|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743196379
2025-03-28T17:12:59,899 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:733.8427543640137|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743196379
2025-03-28T17:12:59,902 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:77.2|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743196379
2025-03-28T17:12:59,906 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:32773.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743196379
2025-03-28T17:12:59,906 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:21684.14453125|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743196379
2025-03-28T17:12:59,906 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:48.8|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743196379
2025-03-28T17:13:01,038 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9019, pid=301626
2025-03-28T17:13:01,041 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9019
2025-03-28T17:13:01,054 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,056 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - [PID]301626
2025-03-28T17:13:01,057 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,057 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,058 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,057 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,064 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:13:01,064 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:13:01,073 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9019.
2025-03-28T17:13:01,075 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381075
2025-03-28T17:13:01,075 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381075
2025-03-28T17:13:01,078 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381078
2025-03-28T17:13:01,078 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381078
2025-03-28T17:13:01,078 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9012, pid=301620
2025-03-28T17:13:01,081 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9012
2025-03-28T17:13:01,093 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9015, pid=301622
2025-03-28T17:13:01,094 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9015
2025-03-28T17:13:01,103 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,104 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - [PID]301620
2025-03-28T17:13:01,104 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,104 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,104 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,104 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:13:01,104 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:13:01,107 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381107
2025-03-28T17:13:01,107 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381107
2025-03-28T17:13:01,104 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,108 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381107
2025-03-28T17:13:01,108 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381107
2025-03-28T17:13:01,109 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,110 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - [PID]301622
2025-03-28T17:13:01,110 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,110 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,109 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9012.
2025-03-28T17:13:01,110 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,110 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,111 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:13:01,111 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:13:01,115 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381115
2025-03-28T17:13:01,115 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381115
2025-03-28T17:13:01,115 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9015.
2025-03-28T17:13:01,117 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381117
2025-03-28T17:13:01,117 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381117
2025-03-28T17:13:01,122 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=301619
2025-03-28T17:13:01,176 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-03-28T17:13:01,176 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,176 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - [PID]301619
2025-03-28T17:13:01,177 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,177 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,177 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:13:01,177 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:13:01,118 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,118 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,179 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,179 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,179 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,179 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,180 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,180 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,180 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,180 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,180 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,180 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,180 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,180 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,180 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9014, pid=301618
2025-03-28T17:13:01,181 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,181 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,181 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,181 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,118 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,181 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,181 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,181 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,181 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,181 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,182 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,182 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9014
2025-03-28T17:13:01,184 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,184 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,182 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,185 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,185 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,185 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,186 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,186 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,186 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,186 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,186 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,186 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,186 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,186 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,186 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,186 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,187 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,187 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,187 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,189 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,176 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,191 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,192 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,193 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,193 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,193 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,193 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,193 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,193 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,193 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,194 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,194 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,194 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,194 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,194 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,194 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,194 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,194 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,194 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,194 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,195 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,195 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,197 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,196 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-03-28T17:13:01,195 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,199 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,199 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - [PID]301618
2025-03-28T17:13:01,199 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,200 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,200 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,195 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,200 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,200 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,200 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,200 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,200 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:13:01,200 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381200
2025-03-28T17:13:01,200 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:13:01,200 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,200 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381200
2025-03-28T17:13:01,200 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,200 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381200
2025-03-28T17:13:01,200 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381200
2025-03-28T17:13:01,200 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,200 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,200 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,212 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,212 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381212
2025-03-28T17:13:01,212 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381212
2025-03-28T17:13:01,212 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,212 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,212 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,213 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,213 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,213 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381213
2025-03-28T17:13:01,213 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381213
2025-03-28T17:13:01,213 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,213 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,213 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,213 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,214 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,211 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9010, pid=301623
2025-03-28T17:13:01,214 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,211 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9011, pid=301615
2025-03-28T17:13:01,214 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9011
2025-03-28T17:13:01,211 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9014.
2025-03-28T17:13:01,214 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9010
2025-03-28T17:13:01,216 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,217 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - [PID]301615
2025-03-28T17:13:01,217 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,217 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,218 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:13:01,218 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:13:01,217 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,219 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=301614
2025-03-28T17:13:01,221 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,221 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,221 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,224 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381224
2025-03-28T17:13:01,224 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381224
2025-03-28T17:13:01,189 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,224 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381224
2025-03-28T17:13:01,224 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381224
2025-03-28T17:13:01,199 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,199 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,225 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-03-28T17:13:01,227 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,227 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,227 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,227 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,227 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,227 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,227 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,227 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,227 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,227 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,227 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,227 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,227 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,227 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,228 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,228 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,228 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,228 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,228 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,228 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,228 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,228 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,228 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,228 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,228 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,228 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,228 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,228 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,228 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,229 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,229 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,229 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,229 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,230 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,229 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9011.
2025-03-28T17:13:01,230 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,229 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,230 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - [PID]301623
2025-03-28T17:13:01,230 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,230 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,230 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,230 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,231 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,231 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,231 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381231
2025-03-28T17:13:01,231 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381231
2025-03-28T17:13:01,231 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:13:01,231 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:13:01,231 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,233 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,231 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,233 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,189 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,234 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,234 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,234 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,235 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,235 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,235 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381235
2025-03-28T17:13:01,235 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381235
2025-03-28T17:13:01,235 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - [PID]301614
2025-03-28T17:13:01,235 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9010.
2025-03-28T17:13:01,236 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,236 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,236 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:13:01,236 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:13:01,260 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381260
2025-03-28T17:13:01,260 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381260
2025-03-28T17:13:01,260 [INFO ] W-9019-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stderr
2025-03-28T17:13:01,260 [INFO ] W-9019-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stderr
2025-03-28T17:13:01,260 [INFO ] W-9019-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stdout
2025-03-28T17:13:01,260 [INFO ] W-9019-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stdout
2025-03-28T17:13:01,261 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 1 seconds.
2025-03-28T17:13:01,261 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 1 seconds.
2025-03-28T17:13:01,260 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,261 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9006, pid=301612
2025-03-28T17:13:01,261 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381261
2025-03-28T17:13:01,261 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,261 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9006
2025-03-28T17:13:01,264 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,265 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stdout
2025-03-28T17:13:01,265 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stdout
2025-03-28T17:13:01,265 [INFO ] W-9015-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stderr
2025-03-28T17:13:01,263 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9013, pid=301630
2025-03-28T17:13:01,261 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381261
2025-03-28T17:13:01,268 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,268 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,268 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,268 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,268 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,269 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,269 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,269 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,269 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,269 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,269 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,269 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,269 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,269 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,269 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,269 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,269 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,269 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,269 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,270 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,270 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,270 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,270 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,270 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,270 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,270 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,270 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,270 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,270 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,270 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,270 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,270 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,271 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,271 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,271 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,271 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,271 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,271 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,271 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,271 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=301628
2025-03-28T17:13:01,271 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-03-28T17:13:01,274 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,274 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - [PID]301612
2025-03-28T17:13:01,274 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,274 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,274 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,274 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,274 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:13:01,274 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:13:01,276 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,276 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,283 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,286 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,286 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,286 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,286 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,286 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,286 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,286 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,286 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,287 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,287 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,287 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,288 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,288 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,287 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,290 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9006.
2025-03-28T17:13:01,301 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,302 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,302 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,302 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,302 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,302 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,302 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,302 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,302 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,302 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,302 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,302 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,302 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9013
2025-03-28T17:13:01,302 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,302 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,302 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,321 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,322 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,322 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,322 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381322
2025-03-28T17:13:01,322 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381322
2025-03-28T17:13:01,322 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - [PID]301628
2025-03-28T17:13:01,322 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,322 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,322 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 1 seconds.
2025-03-28T17:13:01,322 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 1 seconds.
2025-03-28T17:13:01,319 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9017, pid=301624
2025-03-28T17:13:01,322 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9017
2025-03-28T17:13:01,312 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381312
2025-03-28T17:13:01,312 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381312
2025-03-28T17:13:01,323 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381323
2025-03-28T17:13:01,323 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381323
2025-03-28T17:13:01,323 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,323 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,311 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,323 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,323 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,323 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,323 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,323 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,323 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,323 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,323 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,323 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,323 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,323 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,323 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,323 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,323 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,323 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,323 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,323 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,323 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,323 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,323 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,323 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,323 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,323 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,323 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,324 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,324 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,324 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,324 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,324 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,324 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,325 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,325 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,325 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,325 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,325 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,325 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,311 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,311 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,267 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 1 seconds.
2025-03-28T17:13:01,267 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 1 seconds.
2025-03-28T17:13:01,266 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-03-28T17:13:01,307 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,307 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,326 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:159) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:430) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,326 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:159) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:430) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,326 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,326 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,326 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,326 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,326 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381326
2025-03-28T17:13:01,326 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381326
2025-03-28T17:13:01,326 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,326 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,327 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,327 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,327 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,327 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,327 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,327 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,327 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381327
2025-03-28T17:13:01,327 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381327
2025-03-28T17:13:01,266 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,327 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,327 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,327 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,327 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,327 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,328 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,329 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,329 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,329 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,329 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,329 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,331 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 1 seconds.
2025-03-28T17:13:01,331 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 1 seconds.
2025-03-28T17:13:01,331 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 1 seconds.
2025-03-28T17:13:01,331 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 1 seconds.
2025-03-28T17:13:01,265 [INFO ] W-9015-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stderr
2025-03-28T17:13:01,304 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381304
2025-03-28T17:13:01,304 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381304
2025-03-28T17:13:01,303 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,323 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:13:01,332 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381332
2025-03-28T17:13:01,323 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:13:01,332 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381332
2025-03-28T17:13:01,304 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,332 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - [PID]301630
2025-03-28T17:13:01,333 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,304 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,333 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,333 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,333 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,333 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,333 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,333 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,333 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:13:01,333 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:13:01,333 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,333 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,333 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,333 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,333 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,333 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381333
2025-03-28T17:13:01,333 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381333
2025-03-28T17:13:01,333 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-03-28T17:13:01,333 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-03-28T17:13:01,304 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,304 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,334 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,334 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,334 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,334 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,335 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,335 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,335 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,335 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,335 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381335
2025-03-28T17:13:01,335 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381335
2025-03-28T17:13:01,335 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,335 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - [PID]301624
2025-03-28T17:13:01,335 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,335 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,335 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,335 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,335 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:13:01,335 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:13:01,336 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381336
2025-03-28T17:13:01,336 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381336
2025-03-28T17:13:01,337 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381337
2025-03-28T17:13:01,337 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381337
2025-03-28T17:13:01,337 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-03-28T17:13:01,339 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 1 seconds.
2025-03-28T17:13:01,339 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 1 seconds.
2025-03-28T17:13:01,342 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,342 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381342
2025-03-28T17:13:01,342 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381342
2025-03-28T17:13:01,342 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381342
2025-03-28T17:13:01,342 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381342
2025-03-28T17:13:01,342 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9017.
2025-03-28T17:13:01,343 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,343 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9013.
2025-03-28T17:13:01,343 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,343 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,345 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,346 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,346 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,346 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,346 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,345 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381345
2025-03-28T17:13:01,346 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,345 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381345
2025-03-28T17:13:01,346 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,347 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,348 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,348 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,348 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,348 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,348 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,348 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,348 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,348 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,348 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,348 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,348 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,348 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,348 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,348 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=301610
2025-03-28T17:13:01,349 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-03-28T17:13:01,349 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,349 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,350 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,350 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,350 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,350 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,350 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381350
2025-03-28T17:13:01,350 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381350
2025-03-28T17:13:01,350 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-03-28T17:13:01,350 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-03-28T17:13:01,351 [INFO ] W-9010-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stdout
2025-03-28T17:13:01,351 [INFO ] W-9010-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stdout
2025-03-28T17:13:01,351 [INFO ] W-9011-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stderr
2025-03-28T17:13:01,351 [INFO ] W-9011-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stderr
2025-03-28T17:13:01,351 [INFO ] W-9011-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stdout
2025-03-28T17:13:01,351 [INFO ] W-9011-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stdout
2025-03-28T17:13:01,351 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381347
2025-03-28T17:13:01,351 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381347
2025-03-28T17:13:01,351 [INFO ] W-9012-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stderr
2025-03-28T17:13:01,351 [INFO ] W-9012-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stderr
2025-03-28T17:13:01,352 [INFO ] W-9012-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stdout
2025-03-28T17:13:01,352 [INFO ] W-9012-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stdout
2025-03-28T17:13:01,352 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,353 [INFO ] W-9010-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stderr
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,353 [INFO ] W-9010-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stderr
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stdout
2025-03-28T17:13:01,353 [INFO ] W-9003-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stdout
2025-03-28T17:13:01,354 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9008, pid=301613
2025-03-28T17:13:01,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9008
2025-03-28T17:13:01,355 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,355 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,356 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,356 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,356 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,356 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,356 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,356 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,356 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,356 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,356 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381356
2025-03-28T17:13:01,356 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381356
2025-03-28T17:13:01,356 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2025-03-28T17:13:01,356 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2025-03-28T17:13:01,361 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,362 [INFO ] W-9006-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stdout
2025-03-28T17:13:01,362 [INFO ] W-9006-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stdout
2025-03-28T17:13:01,363 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,363 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - [PID]301610
2025-03-28T17:13:01,363 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,363 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,363 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:13:01,363 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:13:01,363 [INFO ] W-9014-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stdout
2025-03-28T17:13:01,363 [INFO ] W-9014-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stdout
2025-03-28T17:13:01,363 [INFO ] W-9014-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stderr
2025-03-28T17:13:01,364 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381364
2025-03-28T17:13:01,365 [INFO ] W-9005-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stderr
2025-03-28T17:13:01,365 [INFO ] W-9005-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stdout
2025-03-28T17:13:01,363 [INFO ] W-9014-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stderr
2025-03-28T17:13:01,365 [INFO ] W-9005-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stderr
2025-03-28T17:13:01,365 [INFO ] W-9005-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stdout
2025-03-28T17:13:01,364 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381364
2025-03-28T17:13:01,364 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,365 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381365
2025-03-28T17:13:01,365 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,365 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381365
2025-03-28T17:13:01,365 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-03-28T17:13:01,367 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,368 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,369 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,369 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,369 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,369 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,369 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,369 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,369 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,369 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,369 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,369 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,369 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,369 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,369 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,369 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,369 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,369 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,369 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,369 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,370 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - [PID]301613
2025-03-28T17:13:01,370 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,370 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,370 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,370 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,370 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,370 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,370 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:13:01,370 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,370 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:13:01,370 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,370 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,370 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,370 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,370 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,370 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,370 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,370 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,370 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,370 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,370 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,370 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,370 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,370 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,370 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,370 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,370 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,370 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,371 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,370 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,371 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,371 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,371 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,371 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,371 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,371 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,371 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,371 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,371 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,371 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381371
2025-03-28T17:13:01,371 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381371
2025-03-28T17:13:01,370 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,371 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 1 seconds.
2025-03-28T17:13:01,371 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 1 seconds.
2025-03-28T17:13:01,370 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,371 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,371 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381371
2025-03-28T17:13:01,371 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381371
2025-03-28T17:13:01,371 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,371 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,371 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,371 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,371 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,371 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,371 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-03-28T17:13:01,371 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9008.
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,372 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381372
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-03-28T17:13:01,372 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381372
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,372 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381372
2025-03-28T17:13:01,371 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,372 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381372
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,372 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,372 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,372 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,372 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,372 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,372 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,372 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,372 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stdout
2025-03-28T17:13:01,372 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,372 [INFO ] W-9000-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stdout
2025-03-28T17:13:01,372 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,373 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,373 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,373 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,373 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,373 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,373 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,373 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,373 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,373 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,373 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,373 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,373 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,373 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,373 [INFO ] W-9017-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stdout
2025-03-28T17:13:01,373 [INFO ] W-9017-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stdout
2025-03-28T17:13:01,374 [INFO ] W-9003-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stderr
2025-03-28T17:13:01,374 [INFO ] W-9003-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stderr
2025-03-28T17:13:01,376 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,377 [INFO ] W-9006-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stderr
2025-03-28T17:13:01,377 [INFO ] W-9006-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stderr
2025-03-28T17:13:01,379 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,379 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,379 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,379 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,379 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,379 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,379 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,379 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,379 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,379 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,379 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,379 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,379 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,379 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,379 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,380 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,380 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,380 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,380 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,381 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,381 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,381 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,381 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,380 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,381 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,381 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,381 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,381 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,381 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,381 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,381 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,381 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,381 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,382 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381382
2025-03-28T17:13:01,382 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381382
2025-03-28T17:13:01,383 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 1 seconds.
2025-03-28T17:13:01,383 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 1 seconds.
2025-03-28T17:13:01,386 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,386 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,388 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,388 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,388 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,388 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,388 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,388 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,388 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,388 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,388 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,388 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,388 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,388 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,388 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,388 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,388 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,389 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,389 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,389 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,388 [INFO ] W-9000-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stderr
2025-03-28T17:13:01,389 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,389 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,389 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,388 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,389 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,389 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,389 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,389 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,389 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,389 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,388 [INFO ] W-9000-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stderr
2025-03-28T17:13:01,389 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,389 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,389 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381389
2025-03-28T17:13:01,389 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381389
2025-03-28T17:13:01,389 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,389 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,389 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,389 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,390 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,389 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,389 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,390 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,390 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,390 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,390 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,390 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,390 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,390 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,390 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,390 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,390 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381390
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381390
2025-03-28T17:13:01,390 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,390 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,390 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,390 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 1 seconds.
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 1 seconds.
2025-03-28T17:13:01,390 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-03-28T17:13:01,390 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,390 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,390 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,390 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,391 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,391 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,391 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,391 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,391 [INFO ] W-9017-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stderr
2025-03-28T17:13:01,391 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,391 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,391 [INFO ] W-9017-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stderr
2025-03-28T17:13:01,391 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,391 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,391 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,391 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,391 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,391 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,391 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,391 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,391 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,391 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,391 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,391 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,391 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,391 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,391 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,391 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,391 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,391 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,391 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,391 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,391 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,392 [INFO ] W-9001-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stdout
2025-03-28T17:13:01,392 [INFO ] W-9001-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stdout
2025-03-28T17:13:01,392 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,392 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,392 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,392 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,392 [INFO ] W-9008-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stdout
2025-03-28T17:13:01,392 [INFO ] W-9008-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stdout
2025-03-28T17:13:01,399 [INFO ] W-9013-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stdout
2025-03-28T17:13:01,399 [INFO ] W-9013-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stdout
2025-03-28T17:13:01,399 [INFO ] W-9013-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stderr
2025-03-28T17:13:01,399 [INFO ] W-9013-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stderr
2025-03-28T17:13:01,404 [INFO ] W-9008-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stderr
2025-03-28T17:13:01,404 [INFO ] W-9001-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stderr
2025-03-28T17:13:01,404 [INFO ] W-9001-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stderr
2025-03-28T17:13:01,404 [INFO ] W-9008-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stderr
2025-03-28T17:13:01,415 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9007, pid=301617
2025-03-28T17:13:01,416 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9007
2025-03-28T17:13:01,422 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,422 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - [PID]301617
2025-03-28T17:13:01,422 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,423 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,423 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,423 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,423 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:13:01,423 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:13:01,423 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9016, pid=301625
2025-03-28T17:13:01,424 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9016
2025-03-28T17:13:01,424 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381424
2025-03-28T17:13:01,424 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381424
2025-03-28T17:13:01,424 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9007.
2025-03-28T17:13:01,424 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381424
2025-03-28T17:13:01,424 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9009, pid=301611
2025-03-28T17:13:01,424 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381424
2025-03-28T17:13:01,424 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9009
2025-03-28T17:13:01,424 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9018, pid=301632
2025-03-28T17:13:01,424 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9018
2025-03-28T17:13:01,430 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,430 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - [PID]301625
2025-03-28T17:13:01,430 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,431 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,431 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,431 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,431 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:13:01,431 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:13:01,431 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,431 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - [PID]301632
2025-03-28T17:13:01,431 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,431 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,431 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,431 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,431 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:13:01,431 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:13:01,432 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381432
2025-03-28T17:13:01,432 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381432
2025-03-28T17:13:01,432 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9016.
2025-03-28T17:13:01,432 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381432
2025-03-28T17:13:01,432 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381432
2025-03-28T17:13:01,432 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381432
2025-03-28T17:13:01,432 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9018.
2025-03-28T17:13:01,432 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381432
2025-03-28T17:13:01,432 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381432
2025-03-28T17:13:01,432 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381432
2025-03-28T17:13:01,435 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,435 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - [PID]301611
2025-03-28T17:13:01,435 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,435 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,435 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,435 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,435 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:13:01,435 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:13:01,436 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381436
2025-03-28T17:13:01,436 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9009.
2025-03-28T17:13:01,436 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381436
2025-03-28T17:13:01,436 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381436
2025-03-28T17:13:01,436 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381436
2025-03-28T17:13:01,436 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,437 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,437 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,437 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,437 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,437 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,437 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,437 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,437 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,437 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,438 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,438 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,438 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,438 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,438 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,438 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,438 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,438 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381438
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381438
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,438 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,439 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,439 [INFO ] W-9007-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stdout
2025-03-28T17:13:01,439 [INFO ] W-9007-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stdout
2025-03-28T17:13:01,447 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,448 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,449 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,449 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,449 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,449 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,449 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,449 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,449 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,449 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,449 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,450 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,450 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,450 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381450
2025-03-28T17:13:01,450 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381450
2025-03-28T17:13:01,450 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 1 seconds.
2025-03-28T17:13:01,450 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 1 seconds.
2025-03-28T17:13:01,450 [INFO ] W-9007-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stderr
2025-03-28T17:13:01,450 [INFO ] W-9007-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stderr
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,450 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=301627
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,450 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,450 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,450 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,450 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,450 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,450 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,450 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,451 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,450 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,451 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,451 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,451 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,451 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,451 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,451 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,451 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,451 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,451 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,451 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381451
2025-03-28T17:13:01,451 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381451
2025-03-28T17:13:01,451 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,451 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,451 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,451 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 1 seconds.
2025-03-28T17:13:01,451 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 1 seconds.
2025-03-28T17:13:01,452 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,454 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,454 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,454 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,454 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,454 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,454 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,454 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,454 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,454 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,455 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,455 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381455
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381455
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 1 seconds.
2025-03-28T17:13:01,455 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 1 seconds.
2025-03-28T17:13:01,456 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,456 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - [PID]301627
2025-03-28T17:13:01,457 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,457 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,457 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,457 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,457 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:13:01,457 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:13:01,458 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-03-28T17:13:01,458 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381458
2025-03-28T17:13:01,458 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381458
2025-03-28T17:13:01,458 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381458
2025-03-28T17:13:01,458 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381458
2025-03-28T17:13:01,462 [INFO ] W-9018-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stdout
2025-03-28T17:13:01,462 [INFO ] W-9018-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stdout
2025-03-28T17:13:01,462 [INFO ] W-9018-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stderr
2025-03-28T17:13:01,462 [INFO ] W-9018-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stderr
2025-03-28T17:13:01,463 [INFO ] W-9016-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stdout
2025-03-28T17:13:01,463 [INFO ] W-9016-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stdout
2025-03-28T17:13:01,463 [INFO ] W-9016-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stderr
2025-03-28T17:13:01,463 [INFO ] W-9016-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stderr
2025-03-28T17:13:01,467 [INFO ] W-9009-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stdout
2025-03-28T17:13:01,467 [INFO ] W-9009-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stdout
2025-03-28T17:13:01,467 [INFO ] W-9009-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stderr
2025-03-28T17:13:01,467 [INFO ] W-9009-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stderr
2025-03-28T17:13:01,469 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,470 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,470 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,470 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,470 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,470 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,470 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,470 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,471 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,471 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,471 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,471 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,471 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,471 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,471 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,471 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,471 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,471 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381471
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381471
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,471 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,472 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,472 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,472 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,472 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,472 [INFO ] W-9004-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stdout
2025-03-28T17:13:01,472 [INFO ] W-9004-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stdout
2025-03-28T17:13:01,481 [INFO ] W-9004-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stderr
2025-03-28T17:13:01,481 [INFO ] W-9004-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stderr
2025-03-28T17:13:01,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=301621
2025-03-28T17:13:01,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-03-28T17:13:01,496 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:01,496 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - [PID]301621
2025-03-28T17:13:01,496 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:01,496 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:01,496 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,496 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:13:01,497 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:13:01,497 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:13:01,498 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381498
2025-03-28T17:13:01,498 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196381498
2025-03-28T17:13:01,498 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381498
2025-03-28T17:13:01,498 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196381498
2025-03-28T17:13:01,498 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-03-28T17:13:01,509 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:01,510 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:01,510 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:01,510 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:01,510 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:01,510 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:01,510 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:01,510 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,510 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:01,510 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,510 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381510
2025-03-28T17:13:01,510 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1743196381510
2025-03-28T17:13:01,511 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-03-28T17:13:01,511 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-03-28T17:13:01,520 [INFO ] W-9002-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stdout
2025-03-28T17:13:01,520 [INFO ] W-9002-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stdout
2025-03-28T17:13:01,520 [INFO ] W-9002-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stderr
2025-03-28T17:13:01,520 [INFO ] W-9002-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stderr
2025-03-28T17:13:02,263 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,263 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,268 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,268 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,323 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,323 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,332 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,332 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,332 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,332 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,334 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,334 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,339 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,339 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,351 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,351 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,357 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,357 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,372 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,372 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,372 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,372 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,383 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,383 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,391 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,391 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,391 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,391 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,439 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,439 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,450 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,450 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,452 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,452 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,456 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,456 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,472 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,472 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,513 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:02,513 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:04,346 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9010, pid=302133
2025-03-28T17:13:04,350 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9010
2025-03-28T17:13:04,361 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,362 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - [PID]302133
2025-03-28T17:13:04,362 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,363 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,363 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,363 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,363 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:13:04,363 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:13:04,371 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9010.
2025-03-28T17:13:04,372 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384372
2025-03-28T17:13:04,372 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384372
2025-03-28T17:13:04,372 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384372
2025-03-28T17:13:04,372 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384372
2025-03-28T17:13:04,405 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,407 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,407 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,408 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,408 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,408 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,408 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,409 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,409 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,409 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,409 [INFO ] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,409 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,409 [INFO ] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,410 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,410 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,410 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,410 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,410 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,410 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,410 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,412 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,412 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,412 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,412 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,412 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,412 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,412 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,412 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,412 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,412 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,412 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,413 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,413 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,413 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,413 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,413 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,410 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,414 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,414 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,415 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,415 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,415 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,415 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,415 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 1 seconds.
2025-03-28T17:13:04,415 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 1 seconds.
2025-03-28T17:13:04,415 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,416 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,416 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,416 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,416 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,416 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,416 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,416 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,416 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,416 [INFO ] W-9010-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stdout
2025-03-28T17:13:04,416 [INFO ] W-9010-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stdout
2025-03-28T17:13:04,421 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9008, pid=302160
2025-03-28T17:13:04,425 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9008
2025-03-28T17:13:04,426 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9015, pid=302127
2025-03-28T17:13:04,426 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9015
2025-03-28T17:13:04,428 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9017, pid=302151
2025-03-28T17:13:04,428 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9017
2025-03-28T17:13:04,437 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,437 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - [PID]302127
2025-03-28T17:13:04,437 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,438 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,438 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,438 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,438 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:13:04,438 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:13:04,439 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,440 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - [PID]302160
2025-03-28T17:13:04,440 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,440 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,440 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,440 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,440 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:13:04,440 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:13:04,440 [INFO ] W-9010-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stderr
2025-03-28T17:13:04,440 [INFO ] W-9010-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stderr
2025-03-28T17:13:04,441 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9015.
2025-03-28T17:13:04,442 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,442 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384442
2025-03-28T17:13:04,442 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384442
2025-03-28T17:13:04,442 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384442
2025-03-28T17:13:04,442 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384442
2025-03-28T17:13:04,442 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - [PID]302151
2025-03-28T17:13:04,443 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,443 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,443 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,443 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,444 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:13:04,444 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:13:04,445 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384444
2025-03-28T17:13:04,445 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384444
2025-03-28T17:13:04,445 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384445
2025-03-28T17:13:04,445 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384445
2025-03-28T17:13:04,445 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9008.
2025-03-28T17:13:04,445 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384445
2025-03-28T17:13:04,445 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384445
2025-03-28T17:13:04,445 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384445
2025-03-28T17:13:04,445 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384445
2025-03-28T17:13:04,445 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9017.
2025-03-28T17:13:04,459 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=302145
2025-03-28T17:13:04,459 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-03-28T17:13:04,460 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,461 [INFO ] epollEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,461 [INFO ] epollEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,463 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,462 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,465 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,466 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,466 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,466 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,466 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,463 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,466 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,466 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,466 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,466 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,466 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,466 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,466 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,466 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,467 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 1 seconds.
2025-03-28T17:13:04,467 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 1 seconds.
2025-03-28T17:13:04,468 [INFO ] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,468 [INFO ] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,470 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,470 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,470 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,470 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,470 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,470 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,470 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,470 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,470 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,471 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,471 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 1 seconds.
2025-03-28T17:13:04,469 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,472 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,472 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,472 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,472 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,472 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,472 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,472 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,472 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,472 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,472 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,472 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,472 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,472 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,472 [INFO ] W-9017-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stdout
2025-03-28T17:13:04,472 [INFO ] W-9017-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stdout
2025-03-28T17:13:04,472 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,472 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,472 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,472 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,472 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,472 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,472 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,472 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,472 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,472 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,472 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,472 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,473 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,474 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,474 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - [PID]302145
2025-03-28T17:13:04,474 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,474 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,475 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,475 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,475 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:13:04,475 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:13:04,475 [INFO ] epollEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,475 [INFO ] epollEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,475 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,475 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,475 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,475 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,476 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,476 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,476 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,476 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,476 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,476 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,476 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 1 seconds.
2025-03-28T17:13:04,476 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-03-28T17:13:04,471 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 1 seconds.
2025-03-28T17:13:04,476 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 1 seconds.
2025-03-28T17:13:04,477 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384477
2025-03-28T17:13:04,477 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384477
2025-03-28T17:13:04,477 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384477
2025-03-28T17:13:04,477 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384477
2025-03-28T17:13:04,484 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stdout
2025-03-28T17:13:04,484 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stdout
2025-03-28T17:13:04,484 [INFO ] W-9015-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stderr
2025-03-28T17:13:04,484 [INFO ] W-9015-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stderr
2025-03-28T17:13:04,495 [INFO ] W-9008-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stdout
2025-03-28T17:13:04,495 [INFO ] W-9008-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stdout
2025-03-28T17:13:04,495 [INFO ] W-9017-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stderr
2025-03-28T17:13:04,495 [INFO ] W-9017-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stderr
2025-03-28T17:13:04,497 [INFO ] W-9008-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stderr
2025-03-28T17:13:04,497 [INFO ] W-9008-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stderr
2025-03-28T17:13:04,497 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,497 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,497 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,497 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,497 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,497 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,498 [INFO ] epollEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,498 [INFO ] epollEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,498 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,499 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,499 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,499 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,499 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,499 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,499 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,500 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,500 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,500 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,500 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,500 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,500 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,500 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,500 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,500 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-03-28T17:13:04,500 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-03-28T17:13:04,505 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9016, pid=302172
2025-03-28T17:13:04,506 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9016
2025-03-28T17:13:04,507 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=302178
2025-03-28T17:13:04,507 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-03-28T17:13:04,514 [INFO ] W-9003-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stdout
2025-03-28T17:13:04,514 [INFO ] W-9003-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stdout
2025-03-28T17:13:04,515 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,515 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - [PID]302178
2025-03-28T17:13:04,515 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,515 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,515 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,515 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,515 [INFO ] W-9003-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stderr
2025-03-28T17:13:04,515 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:13:04,515 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:13:04,515 [INFO ] W-9003-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stderr
2025-03-28T17:13:04,516 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-03-28T17:13:04,516 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384516
2025-03-28T17:13:04,516 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384516
2025-03-28T17:13:04,516 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384516
2025-03-28T17:13:04,516 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384516
2025-03-28T17:13:04,518 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9009, pid=302175
2025-03-28T17:13:04,519 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9009
2025-03-28T17:13:04,523 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,524 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - [PID]302172
2025-03-28T17:13:04,524 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,524 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,524 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,524 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,524 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:13:04,524 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:13:04,525 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9016.
2025-03-28T17:13:04,525 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384525
2025-03-28T17:13:04,525 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384525
2025-03-28T17:13:04,525 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384525
2025-03-28T17:13:04,525 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384525
2025-03-28T17:13:04,526 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,526 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - [PID]302175
2025-03-28T17:13:04,526 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,526 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,527 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,527 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,527 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:13:04,527 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:13:04,527 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9014, pid=302142
2025-03-28T17:13:04,527 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9014
2025-03-28T17:13:04,528 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384528
2025-03-28T17:13:04,528 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9009.
2025-03-28T17:13:04,528 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384528
2025-03-28T17:13:04,528 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384528
2025-03-28T17:13:04,528 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384528
2025-03-28T17:13:04,538 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,538 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9019, pid=302124
2025-03-28T17:13:04,538 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - [PID]302142
2025-03-28T17:13:04,539 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9019
2025-03-28T17:13:04,539 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,539 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,539 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,539 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,539 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,539 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:13:04,539 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:13:04,539 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9013, pid=302157
2025-03-28T17:13:04,539 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9013
2025-03-28T17:13:04,540 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384540
2025-03-28T17:13:04,540 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9014.
2025-03-28T17:13:04,540 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384540
2025-03-28T17:13:04,540 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384540
2025-03-28T17:13:04,540 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384540
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,540 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,541 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,541 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,541 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,541 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,541 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,541 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,541 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,541 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,541 [INFO ] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,541 [INFO ] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,541 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,541 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,541 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,541 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,541 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,541 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,541 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,541 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,541 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,541 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,542 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,542 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,542 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,542 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,542 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,542 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,542 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,542 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,542 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,542 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,542 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,542 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,542 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,542 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,542 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,543 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-03-28T17:13:04,543 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-03-28T17:13:04,546 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,547 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,547 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - [PID]302124
2025-03-28T17:13:04,547 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,547 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,547 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,548 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,548 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,548 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,548 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,548 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,548 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,548 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,548 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,548 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,548 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,548 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,548 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:13:04,548 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:13:04,548 [INFO ] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,548 [INFO ] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,548 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,548 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,548 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,549 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,549 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,549 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,549 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,549 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,549 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,549 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,549 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 1 seconds.
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 1 seconds.
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stdout
2025-03-28T17:13:04,549 [INFO ] W-9016-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stdout
2025-03-28T17:13:04,550 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384550
2025-03-28T17:13:04,550 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384550
2025-03-28T17:13:04,550 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9019.
2025-03-28T17:13:04,551 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384551
2025-03-28T17:13:04,551 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384551
2025-03-28T17:13:04,551 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,551 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - [PID]302157
2025-03-28T17:13:04,551 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,551 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,551 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,551 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,552 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:13:04,552 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:13:04,553 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9013.
2025-03-28T17:13:04,553 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384553
2025-03-28T17:13:04,553 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384553
2025-03-28T17:13:04,553 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384553
2025-03-28T17:13:04,553 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384553
2025-03-28T17:13:04,555 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,555 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,555 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9011, pid=302134
2025-03-28T17:13:04,556 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9011
2025-03-28T17:13:04,556 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,556 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,556 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,556 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,556 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,556 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,556 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,556 [INFO ] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,556 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,556 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,556 [INFO ] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,556 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,556 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,556 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,556 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,557 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,557 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,557 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,557 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,557 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,557 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,557 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,557 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,557 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,557 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,557 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,557 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,557 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,557 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,557 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,557 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,557 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,558 [INFO ] W-9004-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stderr
2025-03-28T17:13:04,558 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,557 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,558 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,558 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,558 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,558 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,558 [INFO ] W-9004-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stderr
2025-03-28T17:13:04,558 [INFO ] epollEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,558 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,558 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,558 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,558 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,558 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,558 [INFO ] W-9004-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stdout
2025-03-28T17:13:04,558 [INFO ] W-9004-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stdout
2025-03-28T17:13:04,558 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,558 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,559 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,558 [INFO ] epollEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,559 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,559 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,559 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,559 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,559 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,559 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,559 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,559 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 1 seconds.
2025-03-28T17:13:04,559 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,559 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 1 seconds.
2025-03-28T17:13:04,559 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,559 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,559 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,559 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,559 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,559 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,559 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,560 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 1 seconds.
2025-03-28T17:13:04,560 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 1 seconds.
2025-03-28T17:13:04,560 [INFO ] W-9009-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stdout
2025-03-28T17:13:04,560 [INFO ] W-9009-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stdout
2025-03-28T17:13:04,566 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,567 [INFO ] W-9016-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stderr
2025-03-28T17:13:04,567 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=302152
2025-03-28T17:13:04,567 [INFO ] W-9016-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stderr
2025-03-28T17:13:04,568 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,568 [INFO ] epollEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,568 [INFO ] epollEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,568 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,568 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,569 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - [PID]302134
2025-03-28T17:13:04,569 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,569 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,569 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,569 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,569 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,569 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,569 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,569 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,569 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,569 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,569 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,569 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,569 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,569 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 1 seconds.
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 1 seconds.
2025-03-28T17:13:04,570 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,570 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,570 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:13:04,570 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stdout
2025-03-28T17:13:04,570 [INFO ] W-9019-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stdout
2025-03-28T17:13:04,571 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384571
2025-03-28T17:13:04,571 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9011.
2025-03-28T17:13:04,571 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384571
2025-03-28T17:13:04,571 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384571
2025-03-28T17:13:04,571 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384571
2025-03-28T17:13:04,571 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,573 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,573 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,573 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,573 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,573 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,573 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,573 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,573 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,573 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,573 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,573 [INFO ] epollEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,573 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,573 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,573 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,573 [INFO ] epollEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,573 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,574 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,574 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,574 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,574 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,574 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=302161
2025-03-28T17:13:04,574 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,574 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,574 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,574 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,574 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,574 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,574 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stdout
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 1 seconds.
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 1 seconds.
2025-03-28T17:13:04,574 [INFO ] W-9013-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stdout
2025-03-28T17:13:04,576 [INFO ] W-9014-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stdout
2025-03-28T17:13:04,576 [INFO ] W-9014-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stdout
2025-03-28T17:13:04,576 [INFO ] W-9014-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stderr
2025-03-28T17:13:04,576 [INFO ] W-9014-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stderr
2025-03-28T17:13:04,577 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,577 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - [PID]302152
2025-03-28T17:13:04,577 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,577 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,577 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,577 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,577 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:13:04,577 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:13:04,578 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-03-28T17:13:04,579 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384579
2025-03-28T17:13:04,579 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384579
2025-03-28T17:13:04,579 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384579
2025-03-28T17:13:04,579 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384579
2025-03-28T17:13:04,580 [INFO ] W-9009-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stderr
2025-03-28T17:13:04,580 [INFO ] W-9009-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stderr
2025-03-28T17:13:04,584 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,584 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - [PID]302161
2025-03-28T17:13:04,584 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,584 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,584 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,584 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,584 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:13:04,584 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:13:04,585 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-03-28T17:13:04,585 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384585
2025-03-28T17:13:04,585 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384585
2025-03-28T17:13:04,585 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384585
2025-03-28T17:13:04,585 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384585
2025-03-28T17:13:04,586 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,586 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=302181
2025-03-28T17:13:04,586 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,587 [INFO ] epollEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,587 [INFO ] epollEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,587 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,587 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,587 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,587 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,587 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,588 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,588 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,588 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,588 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,588 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,588 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,588 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 1 seconds.
2025-03-28T17:13:04,588 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 1 seconds.
2025-03-28T17:13:04,588 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,588 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,588 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,588 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,588 [INFO ] W-9011-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stdout
2025-03-28T17:13:04,588 [INFO ] W-9011-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stdout
2025-03-28T17:13:04,589 [INFO ] W-9019-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stderr
2025-03-28T17:13:04,589 [INFO ] W-9019-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stderr
2025-03-28T17:13:04,591 [INFO ] W-9013-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stderr
2025-03-28T17:13:04,591 [INFO ] W-9013-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stderr
2025-03-28T17:13:04,595 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,595 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - [PID]302181
2025-03-28T17:13:04,595 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,595 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,596 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,596 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,596 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:13:04,596 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:13:04,597 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384597
2025-03-28T17:13:04,597 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384597
2025-03-28T17:13:04,597 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-03-28T17:13:04,597 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384597
2025-03-28T17:13:04,597 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384597
2025-03-28T17:13:04,597 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,598 [INFO ] epollEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,598 [INFO ] epollEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,598 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,598 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,598 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,599 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,598 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,598 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,599 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,599 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,599 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,599 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,599 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,599 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,599 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-03-28T17:13:04,599 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-03-28T17:13:04,599 [INFO ] W-9011-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stderr
2025-03-28T17:13:04,599 [INFO ] W-9011-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stderr
2025-03-28T17:13:04,600 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,601 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,602 [INFO ] epollEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,602 [INFO ] epollEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,602 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,602 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,602 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,602 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,602 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,602 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,602 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,602 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,602 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,602 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stdout
2025-03-28T17:13:04,602 [INFO ] W-9001-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stdout
2025-03-28T17:13:04,610 [INFO ] W-9000-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stdout
2025-03-28T17:13:04,610 [INFO ] W-9000-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stdout
2025-03-28T17:13:04,610 [INFO ] W-9000-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stderr
2025-03-28T17:13:04,610 [INFO ] W-9000-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stderr
2025-03-28T17:13:04,610 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,611 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,611 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,611 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,611 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,611 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,611 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,611 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,611 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,611 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,611 [INFO ] epollEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,611 [INFO ] epollEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,612 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,612 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,612 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,612 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,612 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,612 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,612 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,612 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,612 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,612 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-03-28T17:13:04,612 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-03-28T17:13:04,616 [INFO ] W-9001-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stderr
2025-03-28T17:13:04,616 [INFO ] W-9001-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stderr
2025-03-28T17:13:04,624 [INFO ] W-9002-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stdout
2025-03-28T17:13:04,624 [INFO ] W-9002-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stdout
2025-03-28T17:13:04,624 [INFO ] W-9002-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stderr
2025-03-28T17:13:04,624 [INFO ] W-9002-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stderr
2025-03-28T17:13:04,626 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9006, pid=302148
2025-03-28T17:13:04,626 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9006
2025-03-28T17:13:04,629 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9012, pid=302130
2025-03-28T17:13:04,629 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9012
2025-03-28T17:13:04,633 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,633 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - [PID]302148
2025-03-28T17:13:04,633 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,633 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,633 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,633 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,633 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:13:04,633 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:13:04,634 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384634
2025-03-28T17:13:04,634 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384634
2025-03-28T17:13:04,634 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9006.
2025-03-28T17:13:04,634 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384634
2025-03-28T17:13:04,634 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384634
2025-03-28T17:13:04,636 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,636 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - [PID]302130
2025-03-28T17:13:04,636 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,636 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,636 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,636 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,636 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:13:04,636 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:13:04,637 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384637
2025-03-28T17:13:04,637 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384637
2025-03-28T17:13:04,637 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384637
2025-03-28T17:13:04,637 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384637
2025-03-28T17:13:04,637 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9012.
2025-03-28T17:13:04,647 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,648 [INFO ] epollEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,648 [INFO ] epollEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,648 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,648 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,648 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,649 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,649 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,649 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,649 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,649 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,649 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,649 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,648 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,649 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,648 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,649 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,649 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,649 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,649 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,649 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,649 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,649 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,649 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,649 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2025-03-28T17:13:04,649 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2025-03-28T17:13:04,650 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,651 [INFO ] epollEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,651 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,652 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,651 [INFO ] epollEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,652 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,652 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,652 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,652 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,652 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,652 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,652 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,652 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,652 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,652 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,652 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,652 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,652 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,652 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,652 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,652 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,652 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,652 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,652 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 1 seconds.
2025-03-28T17:13:04,652 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 1 seconds.
2025-03-28T17:13:04,654 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9018, pid=302169
2025-03-28T17:13:04,654 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9018
2025-03-28T17:13:04,665 [INFO ] W-9006-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stdout
2025-03-28T17:13:04,665 [INFO ] W-9006-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stdout
2025-03-28T17:13:04,665 [INFO ] W-9006-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stderr
2025-03-28T17:13:04,665 [INFO ] W-9006-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stderr
2025-03-28T17:13:04,666 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,666 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - [PID]302169
2025-03-28T17:13:04,666 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,666 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,666 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,666 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,667 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:13:04,667 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:13:04,667 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384667
2025-03-28T17:13:04,667 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9018.
2025-03-28T17:13:04,667 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384667
2025-03-28T17:13:04,668 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384667
2025-03-28T17:13:04,668 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384667
2025-03-28T17:13:04,670 [INFO ] W-9012-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stdout
2025-03-28T17:13:04,670 [INFO ] W-9012-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stdout
2025-03-28T17:13:04,670 [INFO ] W-9012-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stderr
2025-03-28T17:13:04,670 [INFO ] W-9012-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stderr
2025-03-28T17:13:04,676 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=302139
2025-03-28T17:13:04,677 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-03-28T17:13:04,682 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,682 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,682 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,683 [INFO ] epollEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,683 [INFO ] epollEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,683 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,683 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,683 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,683 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,683 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,683 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,683 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,684 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,684 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,684 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,684 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,684 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 1 seconds.
2025-03-28T17:13:04,684 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 1 seconds.
2025-03-28T17:13:04,689 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,689 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - [PID]302139
2025-03-28T17:13:04,689 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,689 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,689 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,689 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,689 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:13:04,689 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:13:04,690 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-03-28T17:13:04,690 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384690
2025-03-28T17:13:04,690 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384690
2025-03-28T17:13:04,690 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384690
2025-03-28T17:13:04,690 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384690
2025-03-28T17:13:04,693 [INFO ] W-9018-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stdout
2025-03-28T17:13:04,693 [INFO ] W-9018-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stderr
2025-03-28T17:13:04,693 [INFO ] W-9018-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stdout
2025-03-28T17:13:04,693 [INFO ] W-9018-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stderr
2025-03-28T17:13:04,699 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,701 [INFO ] epollEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,701 [INFO ] epollEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,701 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,701 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,701 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,702 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,702 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,702 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,702 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,702 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,702 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,702 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,702 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stdout
2025-03-28T17:13:04,702 [INFO ] W-9005-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stdout
2025-03-28T17:13:04,711 [INFO ] W-9005-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stderr
2025-03-28T17:13:04,711 [INFO ] W-9005-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stderr
2025-03-28T17:13:04,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9007, pid=302166
2025-03-28T17:13:04,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9007
2025-03-28T17:13:04,761 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:04,761 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - [PID]302166
2025-03-28T17:13:04,762 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:04,762 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:04,762 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,762 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:04,762 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:13:04,762 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:13:04,763 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9007.
2025-03-28T17:13:04,763 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384763
2025-03-28T17:13:04,763 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196384763
2025-03-28T17:13:04,763 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384763
2025-03-28T17:13:04,763 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196384763
2025-03-28T17:13:04,775 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:04,775 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:04,775 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,775 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:04,775 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:04,776 [INFO ] epollEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:04,776 [INFO ] epollEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:04,776 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:04,776 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:04,776 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,776 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:04,776 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,776 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:04,776 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,776 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:04,776 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,776 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2025-03-28T17:13:04,776 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2025-03-28T17:13:04,789 [INFO ] W-9007-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stdout
2025-03-28T17:13:04,789 [INFO ] W-9007-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stdout
2025-03-28T17:13:04,789 [INFO ] W-9007-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stderr
2025-03-28T17:13:04,789 [INFO ] W-9007-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stderr
2025-03-28T17:13:05,416 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,416 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,467 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,467 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,471 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,471 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,476 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,476 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,501 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,501 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,543 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,543 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,550 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,550 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,560 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,560 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,560 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,560 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,570 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,570 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,575 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,575 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,588 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,588 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,599 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,599 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,603 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,603 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,613 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,613 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,650 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,650 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,653 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,653 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,685 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,685 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,703 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,703 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,777 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:05,777 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:07,466 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9010, pid=302589
2025-03-28T17:13:07,466 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9010
2025-03-28T17:13:07,472 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9015, pid=302592
2025-03-28T17:13:07,472 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9015
2025-03-28T17:13:07,480 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,484 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - [PID]302589
2025-03-28T17:13:07,484 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,484 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,484 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,484 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,485 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:13:07,485 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:13:07,487 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,487 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - [PID]302592
2025-03-28T17:13:07,487 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,487 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,487 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,487 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,487 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:13:07,487 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:13:07,488 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9010.
2025-03-28T17:13:07,489 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387489
2025-03-28T17:13:07,489 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387489
2025-03-28T17:13:07,489 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387489
2025-03-28T17:13:07,489 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387489
2025-03-28T17:13:07,489 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,492 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387492
2025-03-28T17:13:07,492 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387492
2025-03-28T17:13:07,492 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387492
2025-03-28T17:13:07,492 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387492
2025-03-28T17:13:07,493 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9015.
2025-03-28T17:13:07,493 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,493 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,493 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,494 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,494 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,494 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,494 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,498 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,498 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,498 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,498 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,498 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,498 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,498 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 2 seconds.
2025-03-28T17:13:07,498 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 2 seconds.
2025-03-28T17:13:07,499 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,499 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,499 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,499 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,499 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,499 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,499 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,499 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,499 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,499 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,499 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,499 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,499 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 2 seconds.
2025-03-28T17:13:07,499 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 2 seconds.
2025-03-28T17:13:07,500 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stdout
2025-03-28T17:13:07,500 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stdout
2025-03-28T17:13:07,510 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9017, pid=302595
2025-03-28T17:13:07,510 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9017
2025-03-28T17:13:07,517 [INFO ] W-9010-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stdout
2025-03-28T17:13:07,517 [INFO ] W-9010-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stdout
2025-03-28T17:13:07,518 [INFO ] W-9010-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stderr
2025-03-28T17:13:07,518 [INFO ] W-9010-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stderr
2025-03-28T17:13:07,527 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,527 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - [PID]302595
2025-03-28T17:13:07,528 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,528 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,528 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,528 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,528 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:13:07,528 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:13:07,532 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387532
2025-03-28T17:13:07,532 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387532
2025-03-28T17:13:07,532 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387532
2025-03-28T17:13:07,532 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387532
2025-03-28T17:13:07,532 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9017.
2025-03-28T17:13:07,534 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,535 [INFO ] W-9015-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stderr
2025-03-28T17:13:07,535 [INFO ] W-9015-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stderr
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,535 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,536 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,536 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,536 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,537 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,537 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,537 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,537 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,537 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,537 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,538 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,538 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,538 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,538 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,538 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 2 seconds.
2025-03-28T17:13:07,538 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 2 seconds.
2025-03-28T17:13:07,558 [INFO ] W-9017-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stdout
2025-03-28T17:13:07,558 [INFO ] W-9017-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stdout
2025-03-28T17:13:07,560 [INFO ] W-9017-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stderr
2025-03-28T17:13:07,560 [INFO ] W-9017-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stderr
2025-03-28T17:13:07,596 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=302601
2025-03-28T17:13:07,597 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-03-28T17:13:07,610 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,611 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - [PID]302601
2025-03-28T17:13:07,611 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,611 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,611 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,611 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,611 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:13:07,611 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:13:07,614 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-03-28T17:13:07,615 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387615
2025-03-28T17:13:07,615 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387615
2025-03-28T17:13:07,615 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387615
2025-03-28T17:13:07,615 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387615
2025-03-28T17:13:07,615 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,618 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,618 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,617 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,618 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,618 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,618 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,619 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,619 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,619 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,619 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,619 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,619 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,619 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,619 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,619 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,619 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,619 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2025-03-28T17:13:07,619 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2025-03-28T17:13:07,619 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,619 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9016, pid=302607
2025-03-28T17:13:07,620 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,621 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,620 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9016
2025-03-28T17:13:07,621 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,621 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,621 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,621 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,621 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,621 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,621 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,621 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,621 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,621 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,621 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,621 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,622 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,623 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,623 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,623 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,623 [INFO ] W-9003-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stdout
2025-03-28T17:13:07,623 [INFO ] W-9003-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stdout
2025-03-28T17:13:07,633 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,633 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - [PID]302607
2025-03-28T17:13:07,634 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,634 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,634 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:13:07,634 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:13:07,634 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,636 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,636 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9016.
2025-03-28T17:13:07,637 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387637
2025-03-28T17:13:07,637 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387637
2025-03-28T17:13:07,637 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387637
2025-03-28T17:13:07,637 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387637
2025-03-28T17:13:07,638 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,641 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,641 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,641 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,641 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,641 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,641 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,642 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,643 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,643 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,643 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,643 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,643 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,643 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,644 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,643 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,644 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,645 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,645 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,645 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,645 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,645 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,645 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,645 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,645 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,646 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 2 seconds.
2025-03-28T17:13:07,646 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 2 seconds.
2025-03-28T17:13:07,648 [INFO ] W-9003-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stderr
2025-03-28T17:13:07,648 [INFO ] W-9003-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stderr
2025-03-28T17:13:07,655 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9013, pid=302619
2025-03-28T17:13:07,656 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9013
2025-03-28T17:13:07,664 [INFO ] W-9016-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stdout
2025-03-28T17:13:07,664 [INFO ] W-9016-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stdout
2025-03-28T17:13:07,664 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,665 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - [PID]302619
2025-03-28T17:13:07,665 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,665 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,665 [INFO ] W-9016-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stderr
2025-03-28T17:13:07,665 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,665 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,665 [INFO ] W-9016-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stderr
2025-03-28T17:13:07,665 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:13:07,665 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:13:07,666 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387666
2025-03-28T17:13:07,666 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387666
2025-03-28T17:13:07,666 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9013.
2025-03-28T17:13:07,666 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387666
2025-03-28T17:13:07,666 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387666
2025-03-28T17:13:07,666 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,668 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,669 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,670 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,670 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,670 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,670 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,670 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,670 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,671 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,671 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,671 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,671 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,671 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,671 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,672 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 2 seconds.
2025-03-28T17:13:07,672 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 2 seconds.
2025-03-28T17:13:07,685 [INFO ] W-9013-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stdout
2025-03-28T17:13:07,685 [INFO ] W-9013-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stdout
2025-03-28T17:13:07,685 [INFO ] W-9013-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stderr
2025-03-28T17:13:07,685 [INFO ] W-9013-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stderr
2025-03-28T17:13:07,715 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=302604
2025-03-28T17:13:07,716 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-03-28T17:13:07,716 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9008, pid=302598
2025-03-28T17:13:07,716 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9008
2025-03-28T17:13:07,725 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,725 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - [PID]302604
2025-03-28T17:13:07,725 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,725 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,726 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,726 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,726 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:13:07,726 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:13:07,727 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-03-28T17:13:07,727 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387727
2025-03-28T17:13:07,727 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387727
2025-03-28T17:13:07,728 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387728
2025-03-28T17:13:07,728 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387728
2025-03-28T17:13:07,729 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,729 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - [PID]302598
2025-03-28T17:13:07,729 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,730 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,730 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,730 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,730 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:13:07,730 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:13:07,730 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,731 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387731
2025-03-28T17:13:07,731 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387731
2025-03-28T17:13:07,732 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387732
2025-03-28T17:13:07,732 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387732
2025-03-28T17:13:07,731 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9008.
2025-03-28T17:13:07,731 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,731 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,733 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,733 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,733 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,733 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,733 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,733 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,733 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,733 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,733 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,733 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,733 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,733 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,733 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,733 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,733 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,734 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,734 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,734 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,734 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,734 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,734 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,734 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,734 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,734 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,733 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,734 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,734 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,733 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,734 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,734 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,734 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,734 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,735 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,736 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,736 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,736 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,736 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,736 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,736 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,735 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,737 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,734 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,737 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,737 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,737 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,737 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,737 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,737 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,737 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,737 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,737 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2025-03-28T17:13:07,737 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2025-03-28T17:13:07,737 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,738 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,738 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,737 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,738 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,738 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,738 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,738 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,738 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,738 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,738 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,736 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,738 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,738 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,738 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,738 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,738 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,738 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,738 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,739 [INFO ] W-9004-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stdout
2025-03-28T17:13:07,739 [INFO ] W-9004-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stdout
2025-03-28T17:13:07,738 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,739 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,740 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,740 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,740 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,740 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,740 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,740 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,740 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,740 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,740 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,740 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,740 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,740 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,739 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9007, pid=302646
2025-03-28T17:13:07,741 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9007
2025-03-28T17:13:07,742 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 2 seconds.
2025-03-28T17:13:07,742 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 2 seconds.
2025-03-28T17:13:07,749 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=302631
2025-03-28T17:13:07,752 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,753 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - [PID]302646
2025-03-28T17:13:07,753 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,753 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,753 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,753 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,753 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:13:07,753 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:13:07,753 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9007.
2025-03-28T17:13:07,754 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387754
2025-03-28T17:13:07,754 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387754
2025-03-28T17:13:07,754 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387754
2025-03-28T17:13:07,754 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387754
2025-03-28T17:13:07,754 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-03-28T17:13:07,754 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,755 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,756 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,756 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,756 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,756 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,756 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,756 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,756 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,756 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,756 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,756 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,756 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,756 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2025-03-28T17:13:07,756 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2025-03-28T17:13:07,766 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,767 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - [PID]302631
2025-03-28T17:13:07,767 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,767 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,767 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,767 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,767 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:13:07,767 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:13:07,768 [INFO ] W-9004-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stderr
2025-03-28T17:13:07,768 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-03-28T17:13:07,768 [INFO ] W-9004-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stderr
2025-03-28T17:13:07,768 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387768
2025-03-28T17:13:07,768 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387768
2025-03-28T17:13:07,768 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387768
2025-03-28T17:13:07,768 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387768
2025-03-28T17:13:07,769 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,769 [INFO ] W-9008-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stderr
2025-03-28T17:13:07,769 [INFO ] W-9008-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stdout
2025-03-28T17:13:07,769 [INFO ] W-9008-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stderr
2025-03-28T17:13:07,769 [INFO ] W-9008-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stdout
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,771 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,772 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,774 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,774 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,774 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,774 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,774 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,774 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,774 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9019, pid=302616
2025-03-28T17:13:07,775 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,775 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,775 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,775 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,775 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,775 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9019
2025-03-28T17:13:07,775 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,775 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2025-03-28T17:13:07,775 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2025-03-28T17:13:07,777 [INFO ] W-9007-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stdout
2025-03-28T17:13:07,777 [INFO ] W-9007-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stdout
2025-03-28T17:13:07,777 [INFO ] W-9007-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stderr
2025-03-28T17:13:07,777 [INFO ] W-9007-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stderr
2025-03-28T17:13:07,783 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,784 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - [PID]302616
2025-03-28T17:13:07,784 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,784 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,784 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,784 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,784 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:13:07,784 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:13:07,785 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9019.
2025-03-28T17:13:07,785 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387785
2025-03-28T17:13:07,785 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387785
2025-03-28T17:13:07,785 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387785
2025-03-28T17:13:07,785 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387785
2025-03-28T17:13:07,785 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,787 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,787 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,787 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,787 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,787 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,787 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,788 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,788 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,788 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,787 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,788 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,788 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,788 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,788 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,788 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,788 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 2 seconds.
2025-03-28T17:13:07,788 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 2 seconds.
2025-03-28T17:13:07,792 [INFO ] W-9002-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stdout
2025-03-28T17:13:07,792 [INFO ] W-9002-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stdout
2025-03-28T17:13:07,792 [INFO ] W-9002-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stderr
2025-03-28T17:13:07,792 [INFO ] W-9002-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stderr
2025-03-28T17:13:07,801 [INFO ] W-9019-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stdout
2025-03-28T17:13:07,801 [INFO ] W-9019-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stdout
2025-03-28T17:13:07,801 [INFO ] W-9019-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stderr
2025-03-28T17:13:07,801 [INFO ] W-9019-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stderr
2025-03-28T17:13:07,831 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9006, pid=302634
2025-03-28T17:13:07,831 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9006
2025-03-28T17:13:07,839 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,839 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - [PID]302634
2025-03-28T17:13:07,839 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,839 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,839 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,839 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,839 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:13:07,839 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:13:07,840 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9006.
2025-03-28T17:13:07,840 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387840
2025-03-28T17:13:07,840 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387840
2025-03-28T17:13:07,840 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387840
2025-03-28T17:13:07,840 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387840
2025-03-28T17:13:07,840 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,841 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,841 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,841 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,841 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,841 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,841 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,841 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,841 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,841 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,841 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,841 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,841 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,841 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,842 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,842 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,842 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,842 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,842 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,842 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,842 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,842 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,842 [INFO ] W-9006-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stdout
2025-03-28T17:13:07,842 [INFO ] W-9006-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stdout
2025-03-28T17:13:07,842 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2025-03-28T17:13:07,842 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2025-03-28T17:13:07,854 [INFO ] W-9006-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stderr
2025-03-28T17:13:07,854 [INFO ] W-9006-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stderr
2025-03-28T17:13:07,862 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9011, pid=302622
2025-03-28T17:13:07,862 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9011
2025-03-28T17:13:07,868 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9009, pid=302611
2025-03-28T17:13:07,868 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9009
2025-03-28T17:13:07,869 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,869 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - [PID]302622
2025-03-28T17:13:07,869 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,870 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,870 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,870 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,870 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:13:07,870 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:13:07,870 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9011.
2025-03-28T17:13:07,870 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387870
2025-03-28T17:13:07,870 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387870
2025-03-28T17:13:07,870 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387870
2025-03-28T17:13:07,870 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387870
2025-03-28T17:13:07,871 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,872 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,873 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,873 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,873 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,873 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,873 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,873 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,873 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,873 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,873 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,873 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,873 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,873 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 2 seconds.
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 2 seconds.
2025-03-28T17:13:07,873 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,874 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,874 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,874 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,874 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,874 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,874 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,874 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,874 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,874 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,874 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,874 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,874 [INFO ] W-9011-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stdout
2025-03-28T17:13:07,874 [INFO ] W-9011-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stdout
2025-03-28T17:13:07,877 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=302643
2025-03-28T17:13:07,877 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-03-28T17:13:07,881 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,881 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - [PID]302611
2025-03-28T17:13:07,881 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,881 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,881 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,881 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,881 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:13:07,881 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:13:07,882 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9009.
2025-03-28T17:13:07,882 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387882
2025-03-28T17:13:07,882 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387882
2025-03-28T17:13:07,882 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387882
2025-03-28T17:13:07,882 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387882
2025-03-28T17:13:07,882 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9012, pid=302637
2025-03-28T17:13:07,882 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9012
2025-03-28T17:13:07,883 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,884 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,884 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,884 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,884 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,884 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,884 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,884 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,884 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,884 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,884 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,884 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,884 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,884 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,885 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 2 seconds.
2025-03-28T17:13:07,885 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 2 seconds.
2025-03-28T17:13:07,885 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - [PID]302643
2025-03-28T17:13:07,885 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,885 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,885 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,885 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,886 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:13:07,886 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:13:07,886 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-03-28T17:13:07,886 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387886
2025-03-28T17:13:07,886 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387886
2025-03-28T17:13:07,886 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387886
2025-03-28T17:13:07,886 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387886
2025-03-28T17:13:07,886 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,887 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,887 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,887 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,887 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,888 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,888 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,888 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,888 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,888 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,888 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,888 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,888 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,888 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,888 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,888 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,888 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,888 [INFO ] W-9011-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stderr
2025-03-28T17:13:07,888 [INFO ] W-9011-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stderr
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stdout
2025-03-28T17:13:07,888 [INFO ] W-9005-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stdout
2025-03-28T17:13:07,890 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,890 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - [PID]302637
2025-03-28T17:13:07,890 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,890 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,890 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,890 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,891 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:13:07,891 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:13:07,891 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9012.
2025-03-28T17:13:07,891 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387891
2025-03-28T17:13:07,891 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387891
2025-03-28T17:13:07,891 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387891
2025-03-28T17:13:07,891 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387891
2025-03-28T17:13:07,892 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,892 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,892 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,892 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,893 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,893 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,893 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,893 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,893 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,893 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,893 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,893 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,893 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,893 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,893 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,893 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 2 seconds.
2025-03-28T17:13:07,893 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 2 seconds.
2025-03-28T17:13:07,897 [INFO ] W-9009-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stdout
2025-03-28T17:13:07,897 [INFO ] W-9009-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stdout
2025-03-28T17:13:07,897 [INFO ] W-9009-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stderr
2025-03-28T17:13:07,897 [INFO ] W-9009-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stderr
2025-03-28T17:13:07,900 [INFO ] W-9005-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stderr
2025-03-28T17:13:07,900 [INFO ] W-9005-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stderr
2025-03-28T17:13:07,904 [INFO ] W-9012-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stdout
2025-03-28T17:13:07,904 [INFO ] W-9012-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stdout
2025-03-28T17:13:07,904 [INFO ] W-9012-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stderr
2025-03-28T17:13:07,904 [INFO ] W-9012-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stderr
2025-03-28T17:13:07,914 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=302625
2025-03-28T17:13:07,914 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-03-28T17:13:07,921 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9018, pid=302640
2025-03-28T17:13:07,921 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9018
2025-03-28T17:13:07,923 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,923 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - [PID]302625
2025-03-28T17:13:07,923 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,923 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,923 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,923 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,923 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:13:07,923 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:13:07,924 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-03-28T17:13:07,924 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387924
2025-03-28T17:13:07,924 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387924
2025-03-28T17:13:07,924 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387924
2025-03-28T17:13:07,924 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387924
2025-03-28T17:13:07,924 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,925 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,925 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,925 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,925 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,925 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,925 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,925 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,925 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,925 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,925 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,925 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,925 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,925 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,926 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2025-03-28T17:13:07,926 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2025-03-28T17:13:07,928 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,928 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - [PID]302640
2025-03-28T17:13:07,928 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,928 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,928 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,928 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,928 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:13:07,928 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:13:07,929 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387929
2025-03-28T17:13:07,929 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387929
2025-03-28T17:13:07,929 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=302628
2025-03-28T17:13:07,929 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387929
2025-03-28T17:13:07,929 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387929
2025-03-28T17:13:07,929 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-03-28T17:13:07,929 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9018.
2025-03-28T17:13:07,929 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,931 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,931 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,931 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,931 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,931 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,931 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,931 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,931 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,931 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,931 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,931 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,931 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 2 seconds.
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,931 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 2 seconds.
2025-03-28T17:13:07,932 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,932 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,932 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,932 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,932 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,932 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,932 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,932 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,932 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,932 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,932 [INFO ] W-9018-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stdout
2025-03-28T17:13:07,932 [INFO ] W-9018-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stdout
2025-03-28T17:13:07,936 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,936 [INFO ] W-9000-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stdout
2025-03-28T17:13:07,936 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - [PID]302628
2025-03-28T17:13:07,936 [INFO ] W-9000-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stdout
2025-03-28T17:13:07,936 [INFO ] W-9000-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stderr
2025-03-28T17:13:07,936 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,936 [INFO ] W-9000-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stderr
2025-03-28T17:13:07,936 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,936 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,936 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,936 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:13:07,936 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:13:07,936 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-03-28T17:13:07,937 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387936
2025-03-28T17:13:07,937 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387936
2025-03-28T17:13:07,937 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387937
2025-03-28T17:13:07,937 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387937
2025-03-28T17:13:07,937 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,938 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,938 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,938 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,938 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,938 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,938 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,938 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,938 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,938 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,938 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,938 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,938 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stdout
2025-03-28T17:13:07,938 [INFO ] W-9001-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stdout
2025-03-28T17:13:07,943 [INFO ] W-9018-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stderr
2025-03-28T17:13:07,943 [INFO ] W-9018-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stderr
2025-03-28T17:13:07,949 [INFO ] W-9001-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stderr
2025-03-28T17:13:07,949 [INFO ] W-9001-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stderr
2025-03-28T17:13:07,958 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9014, pid=302610
2025-03-28T17:13:07,958 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9014
2025-03-28T17:13:07,964 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:07,965 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - [PID]302610
2025-03-28T17:13:07,965 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:07,965 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:07,965 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,965 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:07,965 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:13:07,965 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:13:07,965 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387965
2025-03-28T17:13:07,965 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196387965
2025-03-28T17:13:07,965 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387965
2025-03-28T17:13:07,965 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196387965
2025-03-28T17:13:07,965 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9014.
2025-03-28T17:13:07,966 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:07,967 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:07,967 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:07,967 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:07,967 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:07,967 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:07,967 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:07,967 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:07,967 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,967 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:07,967 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,967 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:07,967 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,967 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:07,968 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 2 seconds.
2025-03-28T17:13:07,968 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 2 seconds.
2025-03-28T17:13:07,978 [INFO ] W-9014-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stdout
2025-03-28T17:13:07,978 [INFO ] W-9014-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stdout
2025-03-28T17:13:07,978 [INFO ] W-9014-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stderr
2025-03-28T17:13:07,978 [INFO ] W-9014-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stderr
2025-03-28T17:13:09,499 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,499 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,500 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,500 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,539 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,539 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,620 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,620 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,646 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,646 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,672 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,672 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,738 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,738 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,742 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,742 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,757 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,757 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,776 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,776 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,789 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,789 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,842 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,842 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,875 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,875 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,886 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,886 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,889 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,889 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,895 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,895 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,926 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,926 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,933 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,933 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,939 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,939 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,968 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:09,968 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:11,491 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9010, pid=303046
2025-03-28T17:13:11,492 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9015, pid=303047
2025-03-28T17:13:11,492 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9015
2025-03-28T17:13:11,493 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9010
2025-03-28T17:13:11,502 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:11,502 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - [PID]303046
2025-03-28T17:13:11,503 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,502 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:11,503 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:11,503 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,503 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:13:11,503 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:13:11,504 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391504
2025-03-28T17:13:11,504 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391504
2025-03-28T17:13:11,504 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391504
2025-03-28T17:13:11,504 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391504
2025-03-28T17:13:11,505 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:11,505 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - [PID]303047
2025-03-28T17:13:11,506 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,506 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:11,506 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,508 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:13:11,508 [INFO ] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,507 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:11,508 [INFO ] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,508 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:13:11,509 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,509 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,509 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,509 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,511 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,511 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,514 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,514 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,514 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,514 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,514 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 3 seconds.
2025-03-28T17:13:11,514 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 3 seconds.
2025-03-28T17:13:11,517 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391517
2025-03-28T17:13:11,517 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391517
2025-03-28T17:13:11,517 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391517
2025-03-28T17:13:11,517 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391517
2025-03-28T17:13:11,513 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9010.
2025-03-28T17:13:11,517 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:11,517 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:11,517 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:11,517 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:11,517 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:11,517 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:11,517 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:11,517 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:11,517 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:11,517 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:11,517 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:11,517 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:11,518 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:11,518 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:11,521 [INFO ] epollEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,521 [INFO ] epollEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,521 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,521 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,521 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,521 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,522 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,522 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,522 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,522 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,522 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,522 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,522 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 3 seconds.
2025-03-28T17:13:11,522 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 3 seconds.
2025-03-28T17:13:11,518 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:11,522 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:11,522 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:11,522 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:11,522 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:11,522 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:11,522 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stdout
2025-03-28T17:13:11,523 [INFO ] W-9010-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stdout
2025-03-28T17:13:11,524 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stdout
2025-03-28T17:13:11,524 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stdout
2025-03-28T17:13:11,537 [INFO ] W-9010-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stderr
2025-03-28T17:13:11,537 [INFO ] W-9010-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stderr
2025-03-28T17:13:11,551 [INFO ] W-9015-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stderr
2025-03-28T17:13:11,551 [INFO ] W-9015-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stderr
2025-03-28T17:13:11,759 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=303055
2025-03-28T17:13:11,762 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-03-28T17:13:11,775 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:11,775 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - [PID]303055
2025-03-28T17:13:11,775 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,775 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,775 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:13:11,775 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:13:11,775 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:11,775 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:11,776 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-03-28T17:13:11,779 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391779
2025-03-28T17:13:11,779 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391779
2025-03-28T17:13:11,787 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391787
2025-03-28T17:13:11,787 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391787
2025-03-28T17:13:11,788 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:11,790 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:11,790 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:11,790 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:11,790 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:11,790 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:11,790 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:11,790 [INFO ] epollEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,790 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:11,790 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:11,790 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:11,790 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:11,790 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:11,790 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:11,790 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:11,790 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:11,790 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:11,791 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:11,791 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:11,791 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:11,791 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:11,791 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:11,790 [INFO ] epollEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:11,792 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:11,792 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,792 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,792 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,792 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,793 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,793 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,793 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,793 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,793 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,793 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,793 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2025-03-28T17:13:11,793 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2025-03-28T17:13:11,811 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9017, pid=303052
2025-03-28T17:13:11,811 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9017
2025-03-28T17:13:11,815 [INFO ] W-9003-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stdout
2025-03-28T17:13:11,815 [INFO ] W-9003-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stdout
2025-03-28T17:13:11,815 [INFO ] W-9003-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stderr
2025-03-28T17:13:11,815 [INFO ] W-9003-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stderr
2025-03-28T17:13:11,824 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:11,824 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - [PID]303052
2025-03-28T17:13:11,825 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:11,825 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:11,825 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,825 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,825 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:13:11,825 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:13:11,828 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9017.
2025-03-28T17:13:11,830 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391830
2025-03-28T17:13:11,830 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391830
2025-03-28T17:13:11,830 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391830
2025-03-28T17:13:11,830 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391830
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:11,835 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:11,836 [INFO ] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,836 [INFO ] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,837 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,837 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,837 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,836 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:11,837 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:11,838 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:11,838 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:11,838 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:11,838 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:11,837 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,838 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,838 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,838 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,838 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,838 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,838 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,839 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 3 seconds.
2025-03-28T17:13:11,839 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 3 seconds.
2025-03-28T17:13:11,839 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9013, pid=303061
2025-03-28T17:13:11,839 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9013
2025-03-28T17:13:11,850 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:11,850 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - [PID]303061
2025-03-28T17:13:11,850 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:11,850 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:11,850 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,850 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,850 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:13:11,850 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:13:11,851 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391851
2025-03-28T17:13:11,851 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9013.
2025-03-28T17:13:11,851 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391851
2025-03-28T17:13:11,852 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391852
2025-03-28T17:13:11,852 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391852
2025-03-28T17:13:11,852 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:11,854 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:11,855 [INFO ] epollEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,854 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:11,855 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:11,855 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:11,855 [INFO ] epollEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,856 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:11,857 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:11,857 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:11,858 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:11,858 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:11,858 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:11,858 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:11,858 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:11,858 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:11,858 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:11,858 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:11,857 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,858 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:11,858 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:11,858 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:11,858 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:11,858 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:11,858 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:11,859 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:11,859 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:11,859 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:11,858 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,858 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,859 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,859 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,859 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,859 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,859 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,859 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,860 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 3 seconds.
2025-03-28T17:13:11,860 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 3 seconds.
2025-03-28T17:13:11,861 [INFO ] W-9017-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stdout
2025-03-28T17:13:11,861 [INFO ] W-9017-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stdout
2025-03-28T17:13:11,861 [INFO ] W-9017-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stderr
2025-03-28T17:13:11,861 [INFO ] W-9017-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stderr
2025-03-28T17:13:11,870 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9019, pid=303076
2025-03-28T17:13:11,872 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9019
2025-03-28T17:13:11,875 [INFO ] W-9013-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stdout
2025-03-28T17:13:11,875 [INFO ] W-9013-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stdout
2025-03-28T17:13:11,875 [INFO ] W-9013-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stderr
2025-03-28T17:13:11,875 [INFO ] W-9013-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stderr
2025-03-28T17:13:11,885 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:11,885 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - [PID]303076
2025-03-28T17:13:11,885 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:11,885 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:11,886 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,886 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,886 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:13:11,886 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:13:11,887 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9019.
2025-03-28T17:13:11,887 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391887
2025-03-28T17:13:11,887 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391887
2025-03-28T17:13:11,887 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391887
2025-03-28T17:13:11,887 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391887
2025-03-28T17:13:11,887 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:11,889 [INFO ] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:11,889 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:11,890 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:11,889 [INFO ] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,892 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,892 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,892 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,892 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,892 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,892 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,892 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,892 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,892 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,892 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,893 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 3 seconds.
2025-03-28T17:13:11,893 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 3 seconds.
2025-03-28T17:13:11,909 [INFO ] W-9019-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stdout
2025-03-28T17:13:11,909 [INFO ] W-9019-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stderr
2025-03-28T17:13:11,909 [INFO ] W-9019-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stdout
2025-03-28T17:13:11,909 [INFO ] W-9019-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stderr
2025-03-28T17:13:11,977 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=303064
2025-03-28T17:13:11,977 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9016, pid=303058
2025-03-28T17:13:11,978 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9016
2025-03-28T17:13:11,980 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-03-28T17:13:11,991 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:11,991 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:11,991 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - [PID]303058
2025-03-28T17:13:11,991 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:11,991 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:11,991 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,991 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,991 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:13:11,991 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:13:11,991 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - [PID]303064
2025-03-28T17:13:11,991 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:11,991 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,991 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:11,991 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:11,992 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:13:11,992 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:13:11,992 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391992
2025-03-28T17:13:11,992 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9016.
2025-03-28T17:13:11,992 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391992
2025-03-28T17:13:11,992 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391992
2025-03-28T17:13:11,992 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-03-28T17:13:11,992 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391992
2025-03-28T17:13:11,992 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391992
2025-03-28T17:13:11,992 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196391992
2025-03-28T17:13:11,992 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391992
2025-03-28T17:13:11,992 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196391992
2025-03-28T17:13:11,992 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:11,992 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:11,994 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:11,994 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:11,994 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:11,994 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:11,994 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:11,994 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:11,994 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:11,994 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:11,994 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:11,994 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:11,994 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:11,994 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:11,994 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:11,994 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:11,994 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:11,994 [INFO ] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,994 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:11,994 [INFO ] epollEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,994 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:11,994 [INFO ] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,994 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:11,994 [INFO ] epollEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:11,994 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:11,994 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,994 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:11,994 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,994 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:11,994 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,994 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:11,994 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:11,994 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:11,994 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:11,994 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:11,995 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:11,994 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:11,995 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:11,994 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,995 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,995 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:11,995 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,994 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:11,995 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:11,995 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,995 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:11,995 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:11,995 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:11,995 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,995 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:11,995 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,995 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,995 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,995 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:11,995 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,995 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2025-03-28T17:13:11,995 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:11,995 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:11,996 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 3 seconds.
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:11,996 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 3 seconds.
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stdout
2025-03-28T17:13:11,996 [INFO ] W-9004-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stdout
2025-03-28T17:13:12,009 [INFO ] W-9004-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stderr
2025-03-28T17:13:12,009 [INFO ] W-9004-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stderr
2025-03-28T17:13:12,013 [INFO ] W-9016-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stdout
2025-03-28T17:13:12,013 [INFO ] W-9016-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stdout
2025-03-28T17:13:12,014 [INFO ] W-9016-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stderr
2025-03-28T17:13:12,014 [INFO ] W-9016-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stderr
2025-03-28T17:13:12,020 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9009, pid=303123
2025-03-28T17:13:12,020 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9009
2025-03-28T17:13:12,033 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:12,034 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - [PID]303123
2025-03-28T17:13:12,034 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,034 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,035 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:13:12,034 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:12,035 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:12,035 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:13:12,035 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9009.
2025-03-28T17:13:12,036 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392036
2025-03-28T17:13:12,036 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392036
2025-03-28T17:13:12,036 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392036
2025-03-28T17:13:12,036 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392036
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:12,040 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:12,041 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:12,041 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:12,041 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,041 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,041 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,041 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,041 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:12,041 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:12,041 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:12,041 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:12,041 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:12,041 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:12,041 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:12,041 [INFO ] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,041 [INFO ] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,042 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,042 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,042 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,042 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,042 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,042 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,042 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,042 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,042 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,042 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,043 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 3 seconds.
2025-03-28T17:13:12,043 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 3 seconds.
2025-03-28T17:13:12,054 [INFO ] W-9009-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stdout
2025-03-28T17:13:12,054 [INFO ] W-9009-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stdout
2025-03-28T17:13:12,054 [INFO ] W-9009-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stderr
2025-03-28T17:13:12,054 [INFO ] W-9009-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stderr
2025-03-28T17:13:12,078 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9007, pid=303070
2025-03-28T17:13:12,079 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9007
2025-03-28T17:13:12,080 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=303073
2025-03-28T17:13:12,080 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-03-28T17:13:12,086 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:12,086 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - [PID]303070
2025-03-28T17:13:12,086 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:12,086 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:12,086 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,086 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,086 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:13:12,086 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:13:12,087 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9007.
2025-03-28T17:13:12,087 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392087
2025-03-28T17:13:12,087 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392087
2025-03-28T17:13:12,087 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392087
2025-03-28T17:13:12,087 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392087
2025-03-28T17:13:12,088 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:12,089 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:12,089 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,089 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:12,089 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:12,089 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:12,089 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:12,089 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,089 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,090 [INFO ] epollEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,090 [INFO ] epollEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,090 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,090 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:12,090 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:12,090 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:12,090 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,090 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:12,090 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,090 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:12,090 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,090 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:12,090 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:12,091 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 3 seconds.
2025-03-28T17:13:12,091 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 3 seconds.
2025-03-28T17:13:12,093 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:12,093 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - [PID]303073
2025-03-28T17:13:12,093 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:12,093 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,093 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,093 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:13:12,093 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:12,093 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:13:12,093 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-03-28T17:13:12,093 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392093
2025-03-28T17:13:12,093 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392093
2025-03-28T17:13:12,093 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392093
2025-03-28T17:13:12,093 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392093
2025-03-28T17:13:12,094 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:12,095 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:12,096 [INFO ] epollEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:12,096 [INFO ] epollEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,096 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,096 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,096 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:12,096 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:12,096 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:12,096 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:12,096 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:12,096 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,096 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,096 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:12,096 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:12,097 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:12,097 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:12,097 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:12,097 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:12,097 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:12,097 [INFO ] W-9002-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stdout
2025-03-28T17:13:12,097 [INFO ] W-9002-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stdout
2025-03-28T17:13:12,102 [INFO ] W-9007-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stdout
2025-03-28T17:13:12,102 [INFO ] W-9007-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stdout
2025-03-28T17:13:12,102 [INFO ] W-9007-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stderr
2025-03-28T17:13:12,102 [INFO ] W-9007-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stderr
2025-03-28T17:13:12,108 [INFO ] W-9002-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stderr
2025-03-28T17:13:12,108 [INFO ] W-9002-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stderr
2025-03-28T17:13:12,146 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=303124
2025-03-28T17:13:12,146 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-03-28T17:13:12,148 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=303138
2025-03-28T17:13:12,148 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-03-28T17:13:12,153 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:12,153 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - [PID]303124
2025-03-28T17:13:12,154 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:12,154 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:12,154 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,154 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,154 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:13:12,154 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:13:12,154 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9018, pid=303133
2025-03-28T17:13:12,154 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9018
2025-03-28T17:13:12,154 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-03-28T17:13:12,154 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392154
2025-03-28T17:13:12,154 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392154
2025-03-28T17:13:12,154 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392154
2025-03-28T17:13:12,154 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392154
2025-03-28T17:13:12,155 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:12,155 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:12,155 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,155 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,156 [INFO ] epollEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,156 [INFO ] epollEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:12,156 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:12,156 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,156 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,156 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:12,156 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:12,156 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:12,156 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:12,156 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,156 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,156 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2025-03-28T17:13:12,156 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2025-03-28T17:13:12,156 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:12,157 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - [PID]303138
2025-03-28T17:13:12,157 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:12,157 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:12,157 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,157 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,157 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:13:12,157 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:13:12,157 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392157
2025-03-28T17:13:12,157 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-03-28T17:13:12,157 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392157
2025-03-28T17:13:12,157 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392157
2025-03-28T17:13:12,157 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392157
2025-03-28T17:13:12,157 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:12,158 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:12,158 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,158 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:12,158 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:12,158 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:12,158 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:12,158 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,158 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,158 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,158 [INFO ] epollEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,158 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,158 [INFO ] epollEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,159 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:12,159 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:12,159 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,159 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,159 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,159 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:12,159 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,159 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:12,159 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,159 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2025-03-28T17:13:12,159 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2025-03-28T17:13:12,163 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:12,163 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - [PID]303133
2025-03-28T17:13:12,163 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:12,163 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:12,163 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,163 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,163 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:13:12,163 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:13:12,164 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9018.
2025-03-28T17:13:12,164 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392164
2025-03-28T17:13:12,164 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392164
2025-03-28T17:13:12,164 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392164
2025-03-28T17:13:12,164 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392164
2025-03-28T17:13:12,164 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:12,166 [INFO ] epollEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,166 [INFO ] epollEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,166 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:12,166 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:12,166 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:12,166 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:12,166 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:12,167 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:12,167 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:12,167 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:12,167 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:12,167 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:12,167 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,167 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,167 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,167 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,167 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,167 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,167 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 3 seconds.
2025-03-28T17:13:12,167 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 3 seconds.
2025-03-28T17:13:12,167 [INFO ] W-9005-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stdout
2025-03-28T17:13:12,167 [INFO ] W-9005-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stdout
2025-03-28T17:13:12,167 [INFO ] W-9005-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stderr
2025-03-28T17:13:12,167 [INFO ] W-9005-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stderr
2025-03-28T17:13:12,171 [INFO ] W-9001-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stdout
2025-03-28T17:13:12,171 [INFO ] W-9001-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stderr
2025-03-28T17:13:12,171 [INFO ] W-9001-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stdout
2025-03-28T17:13:12,171 [INFO ] W-9001-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stderr
2025-03-28T17:13:12,179 [INFO ] W-9018-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stdout
2025-03-28T17:13:12,179 [INFO ] W-9018-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stderr
2025-03-28T17:13:12,179 [INFO ] W-9018-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stdout
2025-03-28T17:13:12,179 [INFO ] W-9018-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stderr
2025-03-28T17:13:12,183 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9014, pid=303141
2025-03-28T17:13:12,183 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9014
2025-03-28T17:13:12,190 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:12,190 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - [PID]303141
2025-03-28T17:13:12,190 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:12,190 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:12,190 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,190 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,190 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:13:12,190 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:13:12,191 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392191
2025-03-28T17:13:12,191 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392191
2025-03-28T17:13:12,191 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392191
2025-03-28T17:13:12,191 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392191
2025-03-28T17:13:12,191 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9014.
2025-03-28T17:13:12,191 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,192 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:12,193 [INFO ] epollEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:12,193 [INFO ] epollEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:12,193 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:12,193 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:12,193 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,193 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,193 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,193 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,193 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,193 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,193 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,193 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 3 seconds.
2025-03-28T17:13:12,193 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 3 seconds.
2025-03-28T17:13:12,202 [INFO ] W-9014-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stdout
2025-03-28T17:13:12,202 [INFO ] W-9014-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stdout
2025-03-28T17:13:12,202 [INFO ] W-9014-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stderr
2025-03-28T17:13:12,202 [INFO ] W-9014-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stderr
2025-03-28T17:13:12,214 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9011, pid=303120
2025-03-28T17:13:12,214 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9011
2025-03-28T17:13:12,221 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:12,221 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - [PID]303120
2025-03-28T17:13:12,221 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:12,221 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:12,221 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,221 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,221 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:13:12,221 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:13:12,221 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9011.
2025-03-28T17:13:12,222 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392222
2025-03-28T17:13:12,222 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392222
2025-03-28T17:13:12,222 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392222
2025-03-28T17:13:12,222 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392222
2025-03-28T17:13:12,222 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,223 [INFO ] epollEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,223 [INFO ] epollEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,223 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:12,223 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:12,223 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:12,223 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:12,223 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:12,223 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,223 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:12,223 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,223 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:12,223 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 3 seconds.
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 3 seconds.
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stdout
2025-03-28T17:13:12,223 [INFO ] W-9011-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stdout
2025-03-28T17:13:12,234 [INFO ] W-9011-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stderr
2025-03-28T17:13:12,234 [INFO ] W-9011-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stderr
2025-03-28T17:13:12,244 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9008, pid=303067
2025-03-28T17:13:12,244 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9008
2025-03-28T17:13:12,251 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:12,251 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - [PID]303067
2025-03-28T17:13:12,251 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:12,251 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:12,251 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,251 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,251 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:13:12,251 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:13:12,252 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9008.
2025-03-28T17:13:12,252 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392252
2025-03-28T17:13:12,252 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392252
2025-03-28T17:13:12,252 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392252
2025-03-28T17:13:12,252 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392252
2025-03-28T17:13:12,252 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:12,254 [INFO ] epollEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,254 [INFO ] epollEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:12,254 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:12,254 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:12,254 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:12,254 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:12,254 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,255 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,255 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,255 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,255 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,255 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,255 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 3 seconds.
2025-03-28T17:13:12,255 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 3 seconds.
2025-03-28T17:13:12,269 [INFO ] W-9008-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stdout
2025-03-28T17:13:12,269 [INFO ] W-9008-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stdout
2025-03-28T17:13:12,269 [INFO ] W-9008-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stderr
2025-03-28T17:13:12,269 [INFO ] W-9008-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stderr
2025-03-28T17:13:12,274 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9006, pid=303079
2025-03-28T17:13:12,274 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9006
2025-03-28T17:13:12,278 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9012, pid=303129
2025-03-28T17:13:12,278 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9012
2025-03-28T17:13:12,281 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:12,281 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - [PID]303079
2025-03-28T17:13:12,281 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:12,281 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:12,281 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,281 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,281 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:13:12,281 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:13:12,282 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392282
2025-03-28T17:13:12,282 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392282
2025-03-28T17:13:12,282 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9006.
2025-03-28T17:13:12,282 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392282
2025-03-28T17:13:12,282 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392282
2025-03-28T17:13:12,282 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,284 [INFO ] epollEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,284 [INFO ] epollEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:12,284 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:12,284 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:12,284 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:12,284 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:12,284 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,284 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:12,284 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,284 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,284 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,284 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,284 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,285 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 3 seconds.
2025-03-28T17:13:12,285 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 3 seconds.
2025-03-28T17:13:12,288 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:12,289 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - [PID]303129
2025-03-28T17:13:12,289 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:12,289 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:12,289 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,289 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,289 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:13:12,289 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:13:12,289 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392289
2025-03-28T17:13:12,289 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392289
2025-03-28T17:13:12,289 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9012.
2025-03-28T17:13:12,289 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392289
2025-03-28T17:13:12,289 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392289
2025-03-28T17:13:12,290 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:12,291 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:12,291 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,291 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:12,291 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:12,291 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:12,291 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:12,291 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,291 [INFO ] epollEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,291 [INFO ] epollEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,291 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,291 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,291 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,291 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,291 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,291 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:12,291 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:12,291 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,291 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:12,291 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,291 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,292 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,292 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:12,292 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,292 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:12,292 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,292 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 3 seconds.
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 3 seconds.
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stdout
2025-03-28T17:13:12,292 [INFO ] W-9012-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stdout
2025-03-28T17:13:12,294 [INFO ] W-9006-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stdout
2025-03-28T17:13:12,294 [INFO ] W-9006-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stdout
2025-03-28T17:13:12,294 [INFO ] W-9006-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stderr
2025-03-28T17:13:12,294 [INFO ] W-9006-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stderr
2025-03-28T17:13:12,304 [INFO ] W-9012-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stderr
2025-03-28T17:13:12,304 [INFO ] W-9012-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stderr
2025-03-28T17:13:12,314 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=303132
2025-03-28T17:13:12,314 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-03-28T17:13:12,320 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:12,321 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - [PID]303132
2025-03-28T17:13:12,321 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:12,321 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:12,321 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,321 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:12,321 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:13:12,321 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:13:12,321 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392321
2025-03-28T17:13:12,321 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196392321
2025-03-28T17:13:12,321 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392321
2025-03-28T17:13:12,321 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196392321
2025-03-28T17:13:12,321 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-03-28T17:13:12,322 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:12,323 [INFO ] epollEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:12,323 [INFO ] epollEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:12,323 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:12,323 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:12,323 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:12,323 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:12,323 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:12,323 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:12,323 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,323 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:12,323 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,323 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2025-03-28T17:13:12,323 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2025-03-28T17:13:12,333 [INFO ] W-9000-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stdout
2025-03-28T17:13:12,333 [INFO ] W-9000-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stdout
2025-03-28T17:13:12,333 [INFO ] W-9000-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stderr
2025-03-28T17:13:12,333 [INFO ] W-9000-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stderr
2025-03-28T17:13:14,515 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:14,515 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:14,523 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:14,523 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:14,794 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:14,794 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:14,839 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:14,839 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:14,860 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:14,860 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:14,893 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:14,893 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:14,996 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:14,996 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:14,996 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:14,996 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,043 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,043 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,091 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,091 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,097 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,097 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,157 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,157 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,160 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,160 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,168 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,168 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,194 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,194 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,224 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,224 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,256 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,256 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,285 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,285 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,294 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,294 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,325 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:15,325 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:16,173 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9015, pid=303511
2025-03-28T17:13:16,177 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9015
2025-03-28T17:13:16,244 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:16,244 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - [PID]303511
2025-03-28T17:13:16,244 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:16,244 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:16,245 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:16,245 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:16,245 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:13:16,245 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:13:16,246 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196396246
2025-03-28T17:13:16,246 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196396246
2025-03-28T17:13:16,246 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196396246
2025-03-28T17:13:16,247 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9015.
2025-03-28T17:13:16,246 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196396246
2025-03-28T17:13:16,247 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:16,249 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:16,253 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:16,253 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:16,253 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:16,253 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:16,253 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:16,253 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:16,253 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:16,253 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:16,253 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:16,253 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:16,253 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:16,253 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:16,256 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 5 seconds.
2025-03-28T17:13:16,256 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 5 seconds.
2025-03-28T17:13:16,268 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9010, pid=303508
2025-03-28T17:13:16,268 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9010
2025-03-28T17:13:16,277 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stdout
2025-03-28T17:13:16,277 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stdout
2025-03-28T17:13:16,278 [INFO ] W-9015-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stderr
2025-03-28T17:13:16,278 [INFO ] W-9015-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stderr
2025-03-28T17:13:16,282 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:16,283 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - [PID]303508
2025-03-28T17:13:16,283 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:16,283 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:16,283 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:16,283 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:16,283 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:13:16,283 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:13:16,284 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196396284
2025-03-28T17:13:16,284 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196396284
2025-03-28T17:13:16,284 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9010.
2025-03-28T17:13:16,284 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196396284
2025-03-28T17:13:16,284 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196396284
2025-03-28T17:13:16,284 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:16,288 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:16,289 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:16,289 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:16,289 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:16,289 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:16,289 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:16,289 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:16,289 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:16,289 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:16,289 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:16,289 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:16,289 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:16,289 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:16,289 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:16,289 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:16,289 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:16,289 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:16,289 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:16,290 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:16,290 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:16,290 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:16,290 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:16,290 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:16,290 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:16,291 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 5 seconds.
2025-03-28T17:13:16,291 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 5 seconds.
2025-03-28T17:13:16,317 [INFO ] W-9010-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stdout
2025-03-28T17:13:16,317 [INFO ] W-9010-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stdout
2025-03-28T17:13:16,317 [INFO ] W-9010-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stderr
2025-03-28T17:13:16,317 [INFO ] W-9010-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stderr
2025-03-28T17:13:16,687 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=303516
2025-03-28T17:13:16,691 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-03-28T17:13:16,702 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:16,702 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - [PID]303516
2025-03-28T17:13:16,703 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:16,703 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:16,703 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:16,703 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:16,703 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:13:16,703 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:13:16,706 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196396706
2025-03-28T17:13:16,706 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196396706
2025-03-28T17:13:16,706 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-03-28T17:13:16,707 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196396707
2025-03-28T17:13:16,707 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196396707
2025-03-28T17:13:16,711 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:16,711 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:16,711 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:16,712 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:16,713 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:16,713 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:16,713 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:16,713 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:16,713 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:16,713 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:16,713 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:16,713 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:16,713 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:16,713 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:16,713 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:16,713 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:16,713 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:16,713 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:16,713 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:16,713 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:16,713 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:16,713 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:16,713 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:16,713 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:16,714 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2025-03-28T17:13:16,714 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2025-03-28T17:13:16,731 [INFO ] W-9003-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stdout
2025-03-28T17:13:16,731 [INFO ] W-9003-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stdout
2025-03-28T17:13:16,732 [INFO ] W-9003-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stderr
2025-03-28T17:13:16,732 [INFO ] W-9003-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stderr
2025-03-28T17:13:16,947 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9017, pid=303519
2025-03-28T17:13:16,947 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9017
2025-03-28T17:13:16,956 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:16,956 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - [PID]303519
2025-03-28T17:13:16,956 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:16,956 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:16,956 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:16,956 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:16,956 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:13:16,956 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:13:16,958 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9017.
2025-03-28T17:13:16,960 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196396960
2025-03-28T17:13:16,960 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196396960
2025-03-28T17:13:16,960 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196396960
2025-03-28T17:13:16,960 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196396960
2025-03-28T17:13:16,961 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:16,962 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:16,962 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:16,962 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:16,962 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:16,962 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:16,963 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:16,964 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:16,964 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:16,964 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:16,964 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:16,964 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:16,964 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:16,964 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:16,965 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:16,965 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:16,965 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:16,965 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:16,965 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:16,966 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:16,966 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:16,966 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:16,966 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:16,967 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:16,967 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:16,968 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:16,968 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:16,969 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:16,969 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:16,969 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:16,969 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:16,970 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:16,970 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:16,970 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:16,970 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:16,970 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 5 seconds.
2025-03-28T17:13:16,970 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 5 seconds.
2025-03-28T17:13:16,985 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9019, pid=303563
2025-03-28T17:13:16,985 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9019
2025-03-28T17:13:16,988 [INFO ] W-9017-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stdout
2025-03-28T17:13:16,988 [INFO ] W-9017-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stdout
2025-03-28T17:13:16,988 [INFO ] W-9017-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stderr
2025-03-28T17:13:16,988 [INFO ] W-9017-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stderr
2025-03-28T17:13:17,000 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,000 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - [PID]303563
2025-03-28T17:13:17,000 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,000 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,000 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,000 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,000 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:13:17,000 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:13:17,001 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397001
2025-03-28T17:13:17,001 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9019.
2025-03-28T17:13:17,001 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397001
2025-03-28T17:13:17,001 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397001
2025-03-28T17:13:17,001 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397001
2025-03-28T17:13:17,002 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,003 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,003 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,003 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,003 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,003 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,003 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,003 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,003 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,003 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,004 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,004 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,004 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,004 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,004 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,004 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,004 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,004 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,004 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,004 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,004 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,004 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,004 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,004 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,004 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,005 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,004 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,005 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 5 seconds.
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 5 seconds.
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stdout
2025-03-28T17:13:17,005 [INFO ] W-9019-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stdout
2025-03-28T17:13:17,018 [INFO ] W-9019-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stderr
2025-03-28T17:13:17,018 [INFO ] W-9019-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stderr
2025-03-28T17:13:17,042 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9013, pid=303560
2025-03-28T17:13:17,042 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9013
2025-03-28T17:13:17,047 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=303567
2025-03-28T17:13:17,047 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-03-28T17:13:17,051 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,051 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - [PID]303560
2025-03-28T17:13:17,052 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,052 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,052 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:13:17,052 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:13:17,053 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,053 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,053 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9013.
2025-03-28T17:13:17,053 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397053
2025-03-28T17:13:17,053 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397053
2025-03-28T17:13:17,053 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397053
2025-03-28T17:13:17,053 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397053
2025-03-28T17:13:17,054 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,056 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,056 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,056 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,056 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,056 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,056 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,057 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,057 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,057 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,058 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,058 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,058 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,057 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,057 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,058 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,058 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,060 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,060 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,061 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,061 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,061 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 5 seconds.
2025-03-28T17:13:17,061 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 5 seconds.
2025-03-28T17:13:17,061 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,062 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - [PID]303567
2025-03-28T17:13:17,062 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,062 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,062 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,062 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,062 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:13:17,062 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:13:17,063 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397063
2025-03-28T17:13:17,063 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397063
2025-03-28T17:13:17,063 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397063
2025-03-28T17:13:17,063 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397063
2025-03-28T17:13:17,063 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-03-28T17:13:17,064 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,065 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,065 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,065 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,065 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,065 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,065 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,065 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,065 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,065 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,065 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,065 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,065 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,065 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,065 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,066 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,066 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,066 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,066 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,066 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,066 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,066 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,066 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,066 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,066 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,066 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,066 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,066 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,066 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,066 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,066 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,066 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,066 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,066 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stdout
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stdout
2025-03-28T17:13:17,067 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2025-03-28T17:13:17,078 [INFO ] W-9013-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stdout
2025-03-28T17:13:17,078 [INFO ] W-9013-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stdout
2025-03-28T17:13:17,079 [INFO ] W-9013-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stderr
2025-03-28T17:13:17,079 [INFO ] W-9013-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stderr
2025-03-28T17:13:17,083 [INFO ] W-9004-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stderr
2025-03-28T17:13:17,083 [INFO ] W-9004-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stderr
2025-03-28T17:13:17,165 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9016, pid=303566
2025-03-28T17:13:17,166 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9016
2025-03-28T17:13:17,174 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,174 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - [PID]303566
2025-03-28T17:13:17,174 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,174 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,174 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,174 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,174 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:13:17,174 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:13:17,175 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9016.
2025-03-28T17:13:17,175 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397175
2025-03-28T17:13:17,175 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397175
2025-03-28T17:13:17,175 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397175
2025-03-28T17:13:17,175 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397175
2025-03-28T17:13:17,175 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,178 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,178 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,178 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,184 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,184 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,184 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,184 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,184 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,184 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,184 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,184 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,184 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,184 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 5 seconds.
2025-03-28T17:13:17,184 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 5 seconds.
2025-03-28T17:13:17,194 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=303578
2025-03-28T17:13:17,195 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-03-28T17:13:17,199 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9009, pid=303572
2025-03-28T17:13:17,203 [INFO ] W-9016-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stderr
2025-03-28T17:13:17,203 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9009
2025-03-28T17:13:17,203 [INFO ] W-9016-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stderr
2025-03-28T17:13:17,205 [INFO ] W-9016-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stdout
2025-03-28T17:13:17,205 [INFO ] W-9016-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stdout
2025-03-28T17:13:17,209 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,209 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - [PID]303578
2025-03-28T17:13:17,209 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,209 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,209 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,209 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,209 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:13:17,209 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:13:17,210 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397210
2025-03-28T17:13:17,210 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397210
2025-03-28T17:13:17,210 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-03-28T17:13:17,210 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397210
2025-03-28T17:13:17,210 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397210
2025-03-28T17:13:17,211 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,213 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,213 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,213 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,213 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,213 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,213 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,213 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,213 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,213 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,213 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,213 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,213 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,214 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,213 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,214 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,214 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,214 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,214 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,214 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,214 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,215 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,215 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,215 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,215 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,215 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,215 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - [PID]303572
2025-03-28T17:13:17,216 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,216 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,216 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,215 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,216 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,216 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,216 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:13:17,216 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,216 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:13:17,214 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,216 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,216 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,216 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,216 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,216 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,216 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,216 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,216 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2025-03-28T17:13:17,216 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2025-03-28T17:13:17,217 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9009.
2025-03-28T17:13:17,222 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397222
2025-03-28T17:13:17,222 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397222
2025-03-28T17:13:17,222 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397222
2025-03-28T17:13:17,222 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397222
2025-03-28T17:13:17,226 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,227 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,227 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,227 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,227 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,227 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,227 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,227 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,227 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,228 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,228 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,228 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,228 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,228 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,228 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,228 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,228 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,228 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,228 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,228 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,228 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,228 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,229 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,229 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,229 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,229 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 5 seconds.
2025-03-28T17:13:17,229 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,229 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 5 seconds.
2025-03-28T17:13:17,229 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,229 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,229 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,229 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,229 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,229 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,229 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,229 [INFO ] W-9009-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stdout
2025-03-28T17:13:17,229 [INFO ] W-9009-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stdout
2025-03-28T17:13:17,231 [INFO ] W-9002-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stdout
2025-03-28T17:13:17,231 [INFO ] W-9002-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stdout
2025-03-28T17:13:17,231 [INFO ] W-9002-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stderr
2025-03-28T17:13:17,231 [INFO ] W-9002-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stderr
2025-03-28T17:13:17,240 [INFO ] W-9009-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stderr
2025-03-28T17:13:17,240 [INFO ] W-9009-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stderr
2025-03-28T17:13:17,248 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9008, pid=303615
2025-03-28T17:13:17,248 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9008
2025-03-28T17:13:17,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - [PID]303615
2025-03-28T17:13:17,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,255 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,255 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,255 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,255 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:13:17,255 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:13:17,259 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397259
2025-03-28T17:13:17,259 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9008.
2025-03-28T17:13:17,259 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397259
2025-03-28T17:13:17,259 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397259
2025-03-28T17:13:17,259 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397259
2025-03-28T17:13:17,260 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,261 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,261 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,261 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,262 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,262 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,262 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,262 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,262 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,262 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,263 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,263 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,263 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,263 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,263 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,263 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,263 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,263 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,263 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,263 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 5 seconds.
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 5 seconds.
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,263 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stdout
2025-03-28T17:13:17,264 [INFO ] W-9008-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stdout
2025-03-28T17:13:17,278 [INFO ] W-9008-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stderr
2025-03-28T17:13:17,278 [INFO ] W-9008-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stderr
2025-03-28T17:13:17,360 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9007, pid=303575
2025-03-28T17:13:17,360 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9007
2025-03-28T17:13:17,372 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9006, pid=303618
2025-03-28T17:13:17,372 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9006
2025-03-28T17:13:17,373 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,373 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - [PID]303575
2025-03-28T17:13:17,373 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,373 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,373 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,373 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,373 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:13:17,373 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:13:17,374 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9007.
2025-03-28T17:13:17,374 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397374
2025-03-28T17:13:17,374 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397374
2025-03-28T17:13:17,374 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397374
2025-03-28T17:13:17,374 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397374
2025-03-28T17:13:17,374 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,376 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,376 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,376 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,376 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,376 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,376 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,376 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,376 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,376 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,376 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,376 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,376 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,376 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 5 seconds.
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 5 seconds.
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stdout
2025-03-28T17:13:17,377 [INFO ] W-9007-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stdout
2025-03-28T17:13:17,380 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,380 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - [PID]303618
2025-03-28T17:13:17,380 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,380 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,380 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,380 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,380 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:13:17,380 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:13:17,381 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397381
2025-03-28T17:13:17,381 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397381
2025-03-28T17:13:17,381 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397381
2025-03-28T17:13:17,381 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9006.
2025-03-28T17:13:17,381 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397381
2025-03-28T17:13:17,381 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,382 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,382 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,382 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,382 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,382 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,382 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,382 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,382 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,382 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,382 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,382 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,382 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,382 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,382 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,382 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,382 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,382 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,382 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,383 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,383 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,383 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,383 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,383 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,383 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 5 seconds.
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 5 seconds.
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stdout
2025-03-28T17:13:17,383 [INFO ] W-9006-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stdout
2025-03-28T17:13:17,389 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=303581
2025-03-28T17:13:17,389 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-03-28T17:13:17,389 [INFO ] W-9007-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stderr
2025-03-28T17:13:17,389 [INFO ] W-9007-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stderr
2025-03-28T17:13:17,396 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=303584
2025-03-28T17:13:17,396 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-03-28T17:13:17,397 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,397 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - [PID]303581
2025-03-28T17:13:17,397 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,397 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,397 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,397 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,397 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:13:17,397 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:13:17,398 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-03-28T17:13:17,398 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397398
2025-03-28T17:13:17,398 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397398
2025-03-28T17:13:17,398 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397398
2025-03-28T17:13:17,398 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397398
2025-03-28T17:13:17,398 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,398 [INFO ] W-9006-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stderr
2025-03-28T17:13:17,398 [INFO ] W-9006-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stderr
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,399 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,399 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,399 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,399 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,399 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,400 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,399 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,399 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,400 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,400 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,400 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,400 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,400 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,400 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,400 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2025-03-28T17:13:17,400 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2025-03-28T17:13:17,407 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,407 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - [PID]303584
2025-03-28T17:13:17,407 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,407 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,407 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,407 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,407 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:13:17,407 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:13:17,408 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-03-28T17:13:17,408 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397408
2025-03-28T17:13:17,408 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397408
2025-03-28T17:13:17,408 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397408
2025-03-28T17:13:17,408 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397408
2025-03-28T17:13:17,408 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,409 [INFO ] W-9005-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stdout
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,409 [INFO ] W-9005-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stdout
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,409 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,409 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,409 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,409 [INFO ] W-9005-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stderr
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,409 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,409 [INFO ] W-9005-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stderr
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,409 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,409 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,409 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,410 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,410 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,410 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,410 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,410 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,410 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stdout
2025-03-28T17:13:17,410 [INFO ] W-9001-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stdout
2025-03-28T17:13:17,410 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9011, pid=303612
2025-03-28T17:13:17,410 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9011
2025-03-28T17:13:17,418 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,418 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - [PID]303612
2025-03-28T17:13:17,418 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,418 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,418 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,418 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,418 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:13:17,418 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:13:17,418 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397418
2025-03-28T17:13:17,418 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397418
2025-03-28T17:13:17,418 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397418
2025-03-28T17:13:17,418 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9011.
2025-03-28T17:13:17,418 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397418
2025-03-28T17:13:17,419 [INFO ] W-9001-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stderr
2025-03-28T17:13:17,419 [INFO ] W-9001-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stderr
2025-03-28T17:13:17,419 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,420 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,420 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,420 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,420 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,420 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,420 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,420 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,421 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,421 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,421 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,421 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,421 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,421 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 5 seconds.
2025-03-28T17:13:17,421 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 5 seconds.
2025-03-28T17:13:17,422 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=303624
2025-03-28T17:13:17,422 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-03-28T17:13:17,429 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,429 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - [PID]303624
2025-03-28T17:13:17,429 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,429 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,429 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,429 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,430 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:13:17,430 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:13:17,430 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-03-28T17:13:17,430 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397430
2025-03-28T17:13:17,430 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397430
2025-03-28T17:13:17,430 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397430
2025-03-28T17:13:17,430 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397430
2025-03-28T17:13:17,430 [INFO ] W-9011-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stdout
2025-03-28T17:13:17,430 [INFO ] W-9011-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stdout
2025-03-28T17:13:17,430 [INFO ] W-9011-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stderr
2025-03-28T17:13:17,430 [INFO ] W-9011-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stderr
2025-03-28T17:13:17,431 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,432 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,432 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,432 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,432 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,432 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,432 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,432 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,432 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,432 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,432 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,432 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,432 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,432 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,433 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2025-03-28T17:13:17,433 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2025-03-28T17:13:17,441 [INFO ] W-9000-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stdout
2025-03-28T17:13:17,441 [INFO ] W-9000-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stdout
2025-03-28T17:13:17,442 [INFO ] W-9000-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stderr
2025-03-28T17:13:17,442 [INFO ] W-9000-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stderr
2025-03-28T17:13:17,467 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9018, pid=303587
2025-03-28T17:13:17,467 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9018
2025-03-28T17:13:17,474 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,474 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - [PID]303587
2025-03-28T17:13:17,474 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,474 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,474 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,474 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,474 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:13:17,474 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:13:17,475 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397475
2025-03-28T17:13:17,475 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397475
2025-03-28T17:13:17,475 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397475
2025-03-28T17:13:17,475 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397475
2025-03-28T17:13:17,475 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9018.
2025-03-28T17:13:17,475 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,476 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,476 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,476 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,476 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,476 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,476 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,476 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,476 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,476 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,476 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,476 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,476 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,476 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,477 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 5 seconds.
2025-03-28T17:13:17,477 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 5 seconds.
2025-03-28T17:13:17,491 [INFO ] W-9018-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stdout
2025-03-28T17:13:17,491 [INFO ] W-9018-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stdout
2025-03-28T17:13:17,492 [INFO ] W-9018-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stderr
2025-03-28T17:13:17,492 [INFO ] W-9018-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stderr
2025-03-28T17:13:17,513 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9014, pid=303590
2025-03-28T17:13:17,513 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9014
2025-03-28T17:13:17,520 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,520 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - [PID]303590
2025-03-28T17:13:17,520 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,520 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,520 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,520 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,520 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:13:17,520 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:13:17,521 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9014.
2025-03-28T17:13:17,521 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397521
2025-03-28T17:13:17,521 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397521
2025-03-28T17:13:17,521 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397521
2025-03-28T17:13:17,521 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397521
2025-03-28T17:13:17,521 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,522 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,522 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,522 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,522 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,522 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,522 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,522 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,522 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,522 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,522 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,522 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,522 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,522 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,523 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 5 seconds.
2025-03-28T17:13:17,523 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 5 seconds.
2025-03-28T17:13:17,533 [INFO ] W-9014-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stdout
2025-03-28T17:13:17,533 [INFO ] W-9014-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stdout
2025-03-28T17:13:17,533 [INFO ] W-9014-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stderr
2025-03-28T17:13:17,533 [INFO ] W-9014-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stderr
2025-03-28T17:13:17,541 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9012, pid=303621
2025-03-28T17:13:17,541 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9012
2025-03-28T17:13:17,547 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:17,547 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - [PID]303621
2025-03-28T17:13:17,547 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:17,547 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:17,547 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,547 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:17,548 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:13:17,548 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:13:17,548 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9012.
2025-03-28T17:13:17,548 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397548
2025-03-28T17:13:17,548 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196397548
2025-03-28T17:13:17,548 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397548
2025-03-28T17:13:17,548 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196397548
2025-03-28T17:13:17,548 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:17,549 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:17,549 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,549 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:17,549 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,550 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,550 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:17,550 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:17,550 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:17,550 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,550 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:17,550 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,550 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:17,550 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,550 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:17,550 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,550 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 5 seconds.
2025-03-28T17:13:17,550 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 5 seconds.
2025-03-28T17:13:17,560 [INFO ] W-9012-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stdout
2025-03-28T17:13:17,560 [INFO ] W-9012-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stdout
2025-03-28T17:13:17,560 [INFO ] W-9012-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stderr
2025-03-28T17:13:17,560 [INFO ] W-9012-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stderr
2025-03-28T17:13:21,256 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:21,256 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:21,291 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:21,291 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:21,714 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:21,714 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:21,970 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:21,970 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,005 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,005 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,061 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,061 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,067 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,067 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,185 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,185 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,217 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,217 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,229 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,229 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,264 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,264 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,313 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9015, pid=303965
2025-03-28T17:13:22,313 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9015
2025-03-28T17:13:22,320 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:22,320 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - [PID]303965
2025-03-28T17:13:22,320 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:22,320 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:22,320 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:22,320 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:22,320 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:13:22,320 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:13:22,321 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9015.
2025-03-28T17:13:22,321 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196402321
2025-03-28T17:13:22,321 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196402321
2025-03-28T17:13:22,321 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196402321
2025-03-28T17:13:22,321 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196402321
2025-03-28T17:13:22,321 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:22,323 [INFO ] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:22,323 [INFO ] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:22,323 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:22,323 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:22,323 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:22,323 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:22,323 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:22,323 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:22,323 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:22,323 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:22,323 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:22,323 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 8 seconds.
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:22,324 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:22,323 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 8 seconds.
2025-03-28T17:13:22,324 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:22,324 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:22,324 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:22,324 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:22,324 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:22,324 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:22,324 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:22,324 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:22,324 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:22,324 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:22,324 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:22,324 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stdout
2025-03-28T17:13:22,324 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stdout
2025-03-28T17:13:22,336 [INFO ] W-9015-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stderr
2025-03-28T17:13:22,336 [INFO ] W-9015-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stderr
2025-03-28T17:13:22,377 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,377 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,384 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,384 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,400 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,400 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,410 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,410 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,421 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,421 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,436 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,436 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,479 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,479 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,523 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,523 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,528 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9010, pid=303968
2025-03-28T17:13:22,533 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9010
2025-03-28T17:13:22,547 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:22,547 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - [PID]303968
2025-03-28T17:13:22,548 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:22,548 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:22,548 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:22,548 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:22,548 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:13:22,548 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:13:22,549 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196402549
2025-03-28T17:13:22,549 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196402549
2025-03-28T17:13:22,549 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196402549
2025-03-28T17:13:22,549 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196402549
2025-03-28T17:13:22,549 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9010.
2025-03-28T17:13:22,549 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:22,551 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:22,551 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:22,551 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:22,551 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:22,551 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,551 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:22,551 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:22,551 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:22,551 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:22,551 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:22,551 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:22,551 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:22,552 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:22,552 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:22,552 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:22,552 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:22,552 [INFO ] epollEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:22,552 [INFO ] epollEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:22,552 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:22,552 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:22,552 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:22,552 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:22,552 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:22,553 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:22,552 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:22,553 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:22,553 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:22,553 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:22,553 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:22,553 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:22,553 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:22,553 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:22,553 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:22,553 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:22,553 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:22,553 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:22,554 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:22,554 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:22,554 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:22,554 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:22,554 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:22,553 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:22,554 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:22,554 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:22,554 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:22,555 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 8 seconds.
2025-03-28T17:13:22,555 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 8 seconds.
2025-03-28T17:13:22,554 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:22,558 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:22,558 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:22,558 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:22,558 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:22,558 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:22,558 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:22,558 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:22,558 [INFO ] W-9010-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stdout
2025-03-28T17:13:22,558 [INFO ] W-9010-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stdout
2025-03-28T17:13:22,578 [INFO ] W-9010-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stderr
2025-03-28T17:13:22,578 [INFO ] W-9010-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stderr
2025-03-28T17:13:23,441 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=304013
2025-03-28T17:13:23,441 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-03-28T17:13:23,475 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:23,478 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - [PID]304013
2025-03-28T17:13:23,478 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:23,478 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:23,478 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:23,478 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:23,479 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:13:23,479 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:13:23,479 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-03-28T17:13:23,479 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196403479
2025-03-28T17:13:23,479 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196403479
2025-03-28T17:13:23,480 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:23,481 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:23,481 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:23,481 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:23,481 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:23,481 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:23,481 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:23,481 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:23,481 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:23,482 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:23,487 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196403487
2025-03-28T17:13:23,487 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196403487
2025-03-28T17:13:23,488 [INFO ] epollEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:23,488 [INFO ] epollEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:23,488 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:23,488 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:23,488 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:23,488 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:23,488 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:23,488 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:23,488 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:23,488 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:23,488 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:23,488 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:23,488 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2025-03-28T17:13:23,488 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2025-03-28T17:13:23,517 [INFO ] W-9003-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stdout
2025-03-28T17:13:23,517 [INFO ] W-9003-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stdout
2025-03-28T17:13:23,517 [INFO ] W-9003-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stderr
2025-03-28T17:13:23,517 [INFO ] W-9003-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stderr
2025-03-28T17:13:23,836 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9019, pid=304019
2025-03-28T17:13:23,836 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9019
2025-03-28T17:13:23,844 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:23,844 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - [PID]304019
2025-03-28T17:13:23,844 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:23,844 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:23,844 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:23,844 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:23,844 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:13:23,844 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:13:23,845 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9019.
2025-03-28T17:13:23,845 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196403845
2025-03-28T17:13:23,845 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196403845
2025-03-28T17:13:23,845 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196403845
2025-03-28T17:13:23,845 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196403845
2025-03-28T17:13:23,845 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:23,846 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:23,846 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:23,846 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:23,846 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:23,847 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:23,849 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:23,849 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:23,849 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:23,849 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:23,849 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:23,849 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:23,849 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:23,849 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:23,849 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:23,849 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:23,849 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:23,849 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:23,849 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:23,849 [INFO ] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:23,849 [INFO ] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:23,849 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:23,849 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:23,849 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:23,849 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:23,849 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:23,849 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:23,849 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:23,849 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:23,849 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:23,849 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:23,850 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 8 seconds.
2025-03-28T17:13:23,850 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 8 seconds.
2025-03-28T17:13:23,862 [INFO ] W-9019-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stdout
2025-03-28T17:13:23,862 [INFO ] W-9019-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stdout
2025-03-28T17:13:23,862 [INFO ] W-9019-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stderr
2025-03-28T17:13:23,862 [INFO ] W-9019-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stderr
2025-03-28T17:13:24,060 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=304056
2025-03-28T17:13:24,060 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-03-28T17:13:24,069 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,070 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - [PID]304056
2025-03-28T17:13:24,070 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,070 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,070 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,070 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,070 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:13:24,070 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:13:24,070 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-03-28T17:13:24,071 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404071
2025-03-28T17:13:24,071 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404071
2025-03-28T17:13:24,071 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404071
2025-03-28T17:13:24,071 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404071
2025-03-28T17:13:24,073 [INFO ] epollEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,073 [INFO ] epollEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,073 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,073 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,073 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,073 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,073 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,073 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,073 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,073 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,073 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,073 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,073 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2025-03-28T17:13:24,073 [INFO ] W-9002-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stdout
2025-03-28T17:13:24,073 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2025-03-28T17:13:24,073 [INFO ] W-9002-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stdout
2025-03-28T17:13:24,094 [INFO ] W-9002-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stderr
2025-03-28T17:13:24,094 [INFO ] W-9002-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stderr
2025-03-28T17:13:24,129 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9017, pid=304016
2025-03-28T17:13:24,129 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9017
2025-03-28T17:13:24,143 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,143 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - [PID]304016
2025-03-28T17:13:24,144 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,144 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,144 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,144 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,144 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:13:24,144 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:13:24,144 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9017.
2025-03-28T17:13:24,146 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404146
2025-03-28T17:13:24,146 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404146
2025-03-28T17:13:24,146 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404146
2025-03-28T17:13:24,146 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404146
2025-03-28T17:13:24,147 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:24,148 [INFO ] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:24,148 [INFO ] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:24,148 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:24,148 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:24,148 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,148 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:24,148 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:24,149 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:24,149 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:24,149 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,149 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,149 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,149 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 8 seconds.
2025-03-28T17:13:24,149 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 8 seconds.
2025-03-28T17:13:24,180 [INFO ] W-9017-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stdout
2025-03-28T17:13:24,180 [INFO ] W-9017-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stdout
2025-03-28T17:13:24,180 [INFO ] W-9017-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stderr
2025-03-28T17:13:24,180 [INFO ] W-9017-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stderr
2025-03-28T17:13:24,207 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9011, pid=304096
2025-03-28T17:13:24,207 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9011
2025-03-28T17:13:24,215 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,215 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - [PID]304096
2025-03-28T17:13:24,215 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,215 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,216 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,216 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,216 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:13:24,216 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:13:24,216 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9011.
2025-03-28T17:13:24,216 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404216
2025-03-28T17:13:24,216 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404216
2025-03-28T17:13:24,216 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404216
2025-03-28T17:13:24,216 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404216
2025-03-28T17:13:24,216 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:24,217 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:24,217 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,217 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:24,217 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:24,217 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:24,217 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:24,217 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,217 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,217 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,217 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,218 [INFO ] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:24,218 [INFO ] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:24,218 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,218 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:24,218 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,218 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:24,218 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,218 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,218 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,218 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,218 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:24,218 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:24,218 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:24,219 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 8 seconds.
2025-03-28T17:13:24,219 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 8 seconds.
2025-03-28T17:13:24,235 [INFO ] W-9011-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stdout
2025-03-28T17:13:24,235 [INFO ] W-9011-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stdout
2025-03-28T17:13:24,235 [INFO ] W-9011-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stderr
2025-03-28T17:13:24,235 [INFO ] W-9011-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stderr
2025-03-28T17:13:24,256 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9013, pid=304022
2025-03-28T17:13:24,256 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9013
2025-03-28T17:13:24,263 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,264 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - [PID]304022
2025-03-28T17:13:24,264 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,264 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,264 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,264 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,264 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:13:24,264 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:13:24,264 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404264
2025-03-28T17:13:24,264 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404264
2025-03-28T17:13:24,264 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9013.
2025-03-28T17:13:24,264 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404264
2025-03-28T17:13:24,264 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404264
2025-03-28T17:13:24,265 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:24,266 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:24,266 [INFO ] epollEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,266 [INFO ] epollEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,267 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,267 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,267 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,267 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,267 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,267 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,267 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,267 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,267 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,267 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,268 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 8 seconds.
2025-03-28T17:13:24,268 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 8 seconds.
2025-03-28T17:13:24,279 [INFO ] W-9013-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stdout
2025-03-28T17:13:24,279 [INFO ] W-9013-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stdout
2025-03-28T17:13:24,279 [INFO ] W-9013-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stderr
2025-03-28T17:13:24,279 [INFO ] W-9013-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stderr
2025-03-28T17:13:24,300 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9016, pid=304049
2025-03-28T17:13:24,300 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9016
2025-03-28T17:13:24,308 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9007, pid=304065
2025-03-28T17:13:24,308 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9007
2025-03-28T17:13:24,312 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,313 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - [PID]304049
2025-03-28T17:13:24,313 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,313 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,313 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,313 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,313 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:13:24,313 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:13:24,313 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9016.
2025-03-28T17:13:24,313 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404313
2025-03-28T17:13:24,313 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404313
2025-03-28T17:13:24,313 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404313
2025-03-28T17:13:24,313 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404313
2025-03-28T17:13:24,314 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,316 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:24,316 [INFO ] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,316 [INFO ] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:24,316 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - [PID]304065
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:24,316 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:24,316 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:24,316 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:24,316 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,316 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:24,316 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:13:24,316 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,316 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,316 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,316 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,316 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,316 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,316 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,316 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,316 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:24,316 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,317 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:24,316 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,317 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:24,317 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:24,317 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:24,317 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:24,317 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:24,317 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 8 seconds.
2025-03-28T17:13:24,317 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 8 seconds.
2025-03-28T17:13:24,317 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9007.
2025-03-28T17:13:24,317 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404317
2025-03-28T17:13:24,317 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404317
2025-03-28T17:13:24,317 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404317
2025-03-28T17:13:24,317 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404317
2025-03-28T17:13:24,317 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,319 [INFO ] epollEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:24,319 [INFO ] epollEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:24,319 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:24,319 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:24,319 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:24,320 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,320 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,320 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,320 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,320 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:24,320 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:24,319 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,320 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:24,319 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,320 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:24,320 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:24,320 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,320 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:24,320 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,320 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:24,320 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,320 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,320 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,320 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,320 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 8 seconds.
2025-03-28T17:13:24,320 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 8 seconds.
2025-03-28T17:13:24,324 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9009, pid=304059
2025-03-28T17:13:24,324 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9009
2025-03-28T17:13:24,327 [INFO ] W-9016-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stdout
2025-03-28T17:13:24,327 [INFO ] W-9016-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stdout
2025-03-28T17:13:24,327 [INFO ] W-9016-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stderr
2025-03-28T17:13:24,327 [INFO ] W-9016-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stderr
2025-03-28T17:13:24,333 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,333 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - [PID]304059
2025-03-28T17:13:24,333 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,333 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,333 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,333 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,334 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:13:24,334 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:13:24,334 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404334
2025-03-28T17:13:24,334 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404334
2025-03-28T17:13:24,334 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404334
2025-03-28T17:13:24,334 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9009.
2025-03-28T17:13:24,334 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404334
2025-03-28T17:13:24,334 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:24,335 [INFO ] W-9007-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stdout
2025-03-28T17:13:24,335 [INFO ] W-9007-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stdout
2025-03-28T17:13:24,335 [INFO ] W-9007-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stderr
2025-03-28T17:13:24,335 [INFO ] W-9007-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stderr
2025-03-28T17:13:24,335 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:24,335 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,335 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:24,335 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:24,335 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,336 [INFO ] epollEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,336 [INFO ] epollEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:24,336 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:24,336 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:24,336 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:24,336 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:24,336 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,336 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:24,336 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,336 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:24,336 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,336 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:24,336 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:24,337 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=304025
2025-03-28T17:13:24,337 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-03-28T17:13:24,337 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 8 seconds.
2025-03-28T17:13:24,337 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 8 seconds.
2025-03-28T17:13:24,345 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9008, pid=304062
2025-03-28T17:13:24,345 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9008
2025-03-28T17:13:24,348 [INFO ] W-9009-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stdout
2025-03-28T17:13:24,348 [INFO ] W-9009-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stdout
2025-03-28T17:13:24,348 [INFO ] W-9009-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stderr
2025-03-28T17:13:24,348 [INFO ] W-9009-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stderr
2025-03-28T17:13:24,350 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,351 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - [PID]304025
2025-03-28T17:13:24,351 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,351 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,351 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,351 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,351 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:13:24,351 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:13:24,351 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404351
2025-03-28T17:13:24,351 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-03-28T17:13:24,351 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404351
2025-03-28T17:13:24,351 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404351
2025-03-28T17:13:24,351 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404351
2025-03-28T17:13:24,352 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:24,352 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,353 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - [PID]304062
2025-03-28T17:13:24,353 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,353 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,353 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,353 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,353 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:13:24,353 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:13:24,353 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9008.
2025-03-28T17:13:24,353 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404353
2025-03-28T17:13:24,353 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404353
2025-03-28T17:13:24,353 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404353
2025-03-28T17:13:24,353 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404353
2025-03-28T17:13:24,353 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:24,353 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,353 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:24,353 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:24,353 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:24,353 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:24,353 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,353 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,353 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,353 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,353 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:24,354 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,354 [INFO ] epollEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:24,354 [INFO ] epollEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:24,354 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:24,354 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:24,354 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:24,354 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,354 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,354 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,354 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,354 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,354 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:24,354 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2025-03-28T17:13:24,354 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:24,355 [INFO ] epollEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:24,355 [INFO ] epollEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:24,355 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:24,355 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:24,355 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:24,355 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,355 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,356 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,356 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,356 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,356 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,356 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,356 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,356 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 8 seconds.
2025-03-28T17:13:24,356 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 8 seconds.
2025-03-28T17:13:24,360 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9006, pid=304068
2025-03-28T17:13:24,361 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9006
2025-03-28T17:13:24,368 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,368 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - [PID]304068
2025-03-28T17:13:24,368 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,368 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,368 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,368 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,368 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:13:24,368 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:13:24,369 [INFO ] W-9004-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stdout
2025-03-28T17:13:24,369 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404369
2025-03-28T17:13:24,369 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9006.
2025-03-28T17:13:24,369 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404369
2025-03-28T17:13:24,369 [INFO ] W-9004-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stdout
2025-03-28T17:13:24,369 [INFO ] W-9004-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stderr
2025-03-28T17:13:24,369 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404369
2025-03-28T17:13:24,369 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404369
2025-03-28T17:13:24,369 [INFO ] W-9004-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stderr
2025-03-28T17:13:24,369 [INFO ] W-9008-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stdout
2025-03-28T17:13:24,369 [INFO ] W-9008-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stdout
2025-03-28T17:13:24,369 [INFO ] W-9008-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stderr
2025-03-28T17:13:24,369 [INFO ] W-9008-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stderr
2025-03-28T17:13:24,369 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:24,370 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:24,370 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,370 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:24,370 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:24,370 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:24,370 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:24,370 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,370 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,370 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,370 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,370 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:24,370 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:24,370 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,370 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:24,370 [INFO ] epollEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,370 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,370 [INFO ] epollEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:24,371 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:24,371 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,371 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,371 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,371 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,371 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:24,371 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,371 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,371 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,371 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 8 seconds.
2025-03-28T17:13:24,371 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 8 seconds.
2025-03-28T17:13:24,383 [INFO ] W-9006-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stdout
2025-03-28T17:13:24,383 [INFO ] W-9006-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stdout
2025-03-28T17:13:24,383 [INFO ] W-9006-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stderr
2025-03-28T17:13:24,383 [INFO ] W-9006-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stderr
2025-03-28T17:13:24,485 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=304071
2025-03-28T17:13:24,485 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-03-28T17:13:24,492 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,492 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - [PID]304071
2025-03-28T17:13:24,492 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,492 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,492 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,492 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,492 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:13:24,492 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:13:24,493 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404493
2025-03-28T17:13:24,493 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404493
2025-03-28T17:13:24,493 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404493
2025-03-28T17:13:24,493 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404493
2025-03-28T17:13:24,493 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-03-28T17:13:24,493 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,494 [INFO ] epollEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,494 [INFO ] epollEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:24,494 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:24,494 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:24,494 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,494 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:24,494 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,495 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:24,495 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,495 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,495 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,495 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,495 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,495 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,495 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2025-03-28T17:13:24,495 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2025-03-28T17:13:24,505 [INFO ] W-9005-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stdout
2025-03-28T17:13:24,505 [INFO ] W-9005-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stdout
2025-03-28T17:13:24,505 [INFO ] W-9005-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stderr
2025-03-28T17:13:24,505 [INFO ] W-9005-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stderr
2025-03-28T17:13:24,547 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9018, pid=304121
2025-03-28T17:13:24,547 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9018
2025-03-28T17:13:24,554 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,554 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - [PID]304121
2025-03-28T17:13:24,554 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,554 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,554 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,554 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,554 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:13:24,554 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:13:24,555 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404555
2025-03-28T17:13:24,555 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404555
2025-03-28T17:13:24,555 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404555
2025-03-28T17:13:24,555 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404555
2025-03-28T17:13:24,555 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9018.
2025-03-28T17:13:24,555 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:24,557 [INFO ] epollEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,557 [INFO ] epollEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,557 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:24,557 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:24,557 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,557 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:24,557 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:24,557 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:24,557 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:24,557 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,557 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,557 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,557 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,558 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,558 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,558 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,558 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:24,558 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:24,558 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:24,558 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:24,558 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:24,558 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:24,558 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:24,558 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 8 seconds.
2025-03-28T17:13:24,558 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 8 seconds.
2025-03-28T17:13:24,558 [INFO ] W-9018-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stdout
2025-03-28T17:13:24,558 [INFO ] W-9018-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stdout
2025-03-28T17:13:24,560 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=304105
2025-03-28T17:13:24,561 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-03-28T17:13:24,567 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9012, pid=304127
2025-03-28T17:13:24,567 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9012
2025-03-28T17:13:24,568 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,568 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - [PID]304105
2025-03-28T17:13:24,568 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,568 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,568 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,568 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,568 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:13:24,568 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:13:24,569 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404569
2025-03-28T17:13:24,569 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404569
2025-03-28T17:13:24,569 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404569
2025-03-28T17:13:24,569 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404569
2025-03-28T17:13:24,569 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-03-28T17:13:24,569 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:24,570 [INFO ] W-9018-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stderr
2025-03-28T17:13:24,570 [INFO ] W-9018-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stderr
2025-03-28T17:13:24,570 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:24,570 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,570 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:24,570 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:24,571 [INFO ] epollEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,571 [INFO ] epollEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,571 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,571 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:24,571 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,571 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,571 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,571 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,571 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:24,571 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,571 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:24,571 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stdout
2025-03-28T17:13:24,571 [INFO ] W-9000-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stdout
2025-03-28T17:13:24,575 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,575 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - [PID]304127
2025-03-28T17:13:24,575 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,575 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,575 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,575 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,575 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:13:24,575 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:13:24,576 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404576
2025-03-28T17:13:24,576 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404576
2025-03-28T17:13:24,576 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404576
2025-03-28T17:13:24,576 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404576
2025-03-28T17:13:24,576 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9012.
2025-03-28T17:13:24,576 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,578 [INFO ] epollEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:24,578 [INFO ] epollEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:24,578 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,578 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:24,578 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,578 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:24,578 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,578 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:24,578 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:24,578 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,578 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:24,578 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 8 seconds.
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 8 seconds.
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stdout
2025-03-28T17:13:24,578 [INFO ] W-9012-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stdout
2025-03-28T17:13:24,582 [INFO ] W-9000-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stderr
2025-03-28T17:13:24,582 [INFO ] W-9000-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stderr
2025-03-28T17:13:24,590 [INFO ] W-9012-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stderr
2025-03-28T17:13:24,590 [INFO ] W-9012-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stderr
2025-03-28T17:13:24,627 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9014, pid=304124
2025-03-28T17:13:24,628 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9014
2025-03-28T17:13:24,628 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=304074
2025-03-28T17:13:24,629 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-03-28T17:13:24,634 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,634 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - [PID]304124
2025-03-28T17:13:24,634 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,634 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,635 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,635 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,635 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:13:24,635 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:13:24,635 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9014.
2025-03-28T17:13:24,635 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:24,635 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404635
2025-03-28T17:13:24,635 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404635
2025-03-28T17:13:24,635 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404635
2025-03-28T17:13:24,635 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404635
2025-03-28T17:13:24,635 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - [PID]304074
2025-03-28T17:13:24,635 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:24,635 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:24,635 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,635 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:24,635 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:13:24,635 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:24,636 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404636
2025-03-28T17:13:24,636 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196404636
2025-03-28T17:13:24,636 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404636
2025-03-28T17:13:24,636 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196404636
2025-03-28T17:13:24,636 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-03-28T17:13:24,636 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,636 [INFO ] epollEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,636 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,636 [INFO ] epollEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:24,637 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:24,637 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,637 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:24,637 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:24,637 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:24,637 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:24,637 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,637 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,637 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:24,637 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 8 seconds.
2025-03-28T17:13:24,637 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 8 seconds.
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:24,638 [INFO ] epollEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,638 [INFO ] epollEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,638 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,638 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:24,638 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:24,638 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,638 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:24,638 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:24,638 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,638 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:24,638 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:24,638 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stdout
2025-03-28T17:13:24,638 [INFO ] W-9001-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stdout
2025-03-28T17:13:24,648 [INFO ] W-9001-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stderr
2025-03-28T17:13:24,648 [INFO ] W-9001-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stderr
2025-03-28T17:13:24,649 [INFO ] W-9014-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stdout
2025-03-28T17:13:24,649 [INFO ] W-9014-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stdout
2025-03-28T17:13:24,649 [INFO ] W-9014-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stderr
2025-03-28T17:13:24,649 [INFO ] W-9014-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stderr
2025-03-28T17:13:30,325 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:30,325 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:30,555 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:30,555 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:31,253 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9015, pid=304608
2025-03-28T17:13:31,253 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9015
2025-03-28T17:13:31,258 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:31,259 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - [PID]304608
2025-03-28T17:13:31,259 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:31,259 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:31,259 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:31,259 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:31,259 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:13:31,259 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:13:31,259 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196411259
2025-03-28T17:13:31,259 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196411259
2025-03-28T17:13:31,259 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196411259
2025-03-28T17:13:31,259 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196411259
2025-03-28T17:13:31,259 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9015.
2025-03-28T17:13:31,260 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:31,261 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:31,261 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:31,261 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:31,261 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:31,261 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:31,261 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:31,261 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:31,261 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:31,261 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:31,261 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:31,261 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:31,261 [WARN ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 13 seconds.
2025-03-28T17:13:31,261 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 13 seconds.
2025-03-28T17:13:31,273 [INFO ] W-9015-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stderr
2025-03-28T17:13:31,273 [INFO ] W-9015-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stderr
2025-03-28T17:13:31,273 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stdout
2025-03-28T17:13:31,273 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-densenet161_1.0-stdout
2025-03-28T17:13:31,486 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9010, pid=304611
2025-03-28T17:13:31,486 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9010
2025-03-28T17:13:31,489 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:31,489 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:31,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:31,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - [PID]304611
2025-03-28T17:13:31,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:31,492 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:31,492 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:31,492 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:31,492 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:13:31,492 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:13:31,493 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9010.
2025-03-28T17:13:31,493 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196411493
2025-03-28T17:13:31,493 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196411493
2025-03-28T17:13:31,493 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196411493
2025-03-28T17:13:31,493 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196411493
2025-03-28T17:13:31,493 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:31,494 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:31,494 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:31,494 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:31,494 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:31,494 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:31,494 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:31,494 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:31,494 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:31,494 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:31,494 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:31,494 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:31,494 [WARN ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 13 seconds.
2025-03-28T17:13:31,494 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 13 seconds.
2025-03-28T17:13:31,507 [INFO ] W-9010-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stdout
2025-03-28T17:13:31,507 [INFO ] W-9010-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stdout
2025-03-28T17:13:31,507 [INFO ] W-9010-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stderr
2025-03-28T17:13:31,507 [INFO ] W-9010-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-densenet161_1.0-stderr
2025-03-28T17:13:31,850 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:31,850 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,074 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,074 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,150 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,150 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,219 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,219 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,269 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,269 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,317 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,317 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,320 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,320 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,338 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,338 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,355 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,355 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,356 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,356 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,372 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,372 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,495 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,495 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,560 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,560 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,572 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,572 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,579 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,579 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,581 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=304658
2025-03-28T17:13:32,582 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-03-28T17:13:32,596 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:32,596 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - [PID]304658
2025-03-28T17:13:32,596 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:32,596 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:32,596 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:32,596 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:32,597 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:13:32,597 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:13:32,598 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-03-28T17:13:32,598 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196412598
2025-03-28T17:13:32,598 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196412598
2025-03-28T17:13:32,598 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196412598
2025-03-28T17:13:32,598 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196412598
2025-03-28T17:13:32,598 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:32,600 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:32,600 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:32,600 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:32,600 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:32,600 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:32,602 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:32,602 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:32,603 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:32,603 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:32,603 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:32,602 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:32,604 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:32,604 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:32,604 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:32,604 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:32,604 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:32,604 [WARN ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:32,604 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2025-03-28T17:13:32,604 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2025-03-28T17:13:32,638 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,638 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,639 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,639 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:13:32,666 [INFO ] W-9003-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stdout
2025-03-28T17:13:32,666 [INFO ] W-9003-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stderr
2025-03-28T17:13:32,666 [INFO ] W-9003-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stdout
2025-03-28T17:13:32,666 [INFO ] W-9003-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-densenet161_1.0-stderr
2025-03-28T17:13:33,374 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9019, pid=304680
2025-03-28T17:13:33,374 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9019
2025-03-28T17:13:33,395 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:33,397 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - [PID]304680
2025-03-28T17:13:33,398 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:33,398 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:33,398 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:33,398 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:13:33,398 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:13:33,399 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:33,400 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9019.
2025-03-28T17:13:33,401 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196413401
2025-03-28T17:13:33,401 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196413401
2025-03-28T17:13:33,406 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196413406
2025-03-28T17:13:33,406 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196413406
2025-03-28T17:13:33,406 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:33,406 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:33,407 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:33,407 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:33,407 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:33,407 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:33,407 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:33,408 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:33,408 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:33,408 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:33,408 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:33,408 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:33,408 [WARN ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:33,408 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 13 seconds.
2025-03-28T17:13:33,408 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 13 seconds.
2025-03-28T17:13:33,446 [INFO ] W-9019-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stdout
2025-03-28T17:13:33,446 [INFO ] W-9019-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stdout
2025-03-28T17:13:33,447 [INFO ] W-9019-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stderr
2025-03-28T17:13:33,447 [INFO ] W-9019-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-densenet161_1.0-stderr
2025-03-28T17:13:33,703 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9017, pid=304689
2025-03-28T17:13:33,703 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9017
2025-03-28T17:13:33,712 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:33,712 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - [PID]304689
2025-03-28T17:13:33,712 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:33,712 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:33,712 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:33,712 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:33,712 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:13:33,712 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:13:33,713 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196413713
2025-03-28T17:13:33,713 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9017.
2025-03-28T17:13:33,713 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196413713
2025-03-28T17:13:33,713 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196413713
2025-03-28T17:13:33,713 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196413713
2025-03-28T17:13:33,714 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:33,715 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:33,716 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:33,716 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:33,716 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:33,716 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:33,716 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:33,716 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:33,716 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:33,716 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:33,716 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:33,716 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:33,716 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:33,716 [WARN ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:33,716 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 13 seconds.
2025-03-28T17:13:33,716 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 13 seconds.
2025-03-28T17:13:33,732 [INFO ] W-9017-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stdout
2025-03-28T17:13:33,732 [INFO ] W-9017-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stderr
2025-03-28T17:13:33,732 [INFO ] W-9017-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stdout
2025-03-28T17:13:33,732 [INFO ] W-9017-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-densenet161_1.0-stderr
2025-03-28T17:13:33,980 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9009, pid=304725
2025-03-28T17:13:33,980 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9009
2025-03-28T17:13:33,988 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:33,988 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - [PID]304725
2025-03-28T17:13:33,988 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:33,988 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:33,988 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:33,988 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:33,988 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:13:33,988 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:13:33,989 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9009.
2025-03-28T17:13:33,989 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196413989
2025-03-28T17:13:33,989 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196413989
2025-03-28T17:13:33,990 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196413990
2025-03-28T17:13:33,990 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196413990
2025-03-28T17:13:33,990 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:33,992 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:33,993 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:33,993 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:33,993 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:33,993 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:33,993 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:33,993 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:33,993 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:33,993 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:33,993 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:33,993 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:33,993 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:33,993 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:33,993 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:33,993 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:33,993 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:33,993 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:33,995 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:33,995 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:33,995 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:33,995 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:33,995 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:33,995 [WARN ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:33,995 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 13 seconds.
2025-03-28T17:13:33,995 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 13 seconds.
2025-03-28T17:13:34,012 [INFO ] W-9009-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stdout
2025-03-28T17:13:34,012 [INFO ] W-9009-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stderr
2025-03-28T17:13:34,012 [INFO ] W-9009-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stderr
2025-03-28T17:13:34,012 [INFO ] W-9009-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-densenet161_1.0-stdout
2025-03-28T17:13:34,012 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=304683
2025-03-28T17:13:34,012 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-03-28T17:13:34,025 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:34,025 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - [PID]304683
2025-03-28T17:13:34,025 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:34,025 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:34,025 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,025 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,025 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:13:34,025 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:13:34,026 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414026
2025-03-28T17:13:34,026 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414026
2025-03-28T17:13:34,026 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414026
2025-03-28T17:13:34,026 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414026
2025-03-28T17:13:34,026 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-03-28T17:13:34,026 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,028 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:34,028 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:34,028 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,029 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,029 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,029 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,029 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,029 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:34,029 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,029 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:34,029 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,029 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:34,029 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:34,029 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:34,029 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:34,029 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:34,029 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,029 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,029 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,029 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,029 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,029 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,029 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,029 [WARN ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,029 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2025-03-28T17:13:34,029 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2025-03-28T17:13:34,048 [INFO ] W-9002-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stdout
2025-03-28T17:13:34,048 [INFO ] W-9002-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stderr
2025-03-28T17:13:34,048 [INFO ] W-9002-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stdout
2025-03-28T17:13:34,048 [INFO ] W-9002-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-densenet161_1.0-stderr
2025-03-28T17:13:34,066 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9016, pid=304717
2025-03-28T17:13:34,066 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9016
2025-03-28T17:13:34,074 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:34,074 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - [PID]304717
2025-03-28T17:13:34,074 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:34,074 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:34,075 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,075 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,075 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:13:34,075 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:13:34,076 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414076
2025-03-28T17:13:34,076 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414076
2025-03-28T17:13:34,076 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9016.
2025-03-28T17:13:34,076 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414076
2025-03-28T17:13:34,076 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414076
2025-03-28T17:13:34,076 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:34,077 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:34,077 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,077 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:34,077 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:34,077 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:34,077 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:34,077 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,077 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,077 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,078 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,078 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:34,078 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:34,078 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,078 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:34,078 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,078 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,078 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:34,078 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:34,078 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:34,078 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,078 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,078 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:34,078 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:34,079 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:34,079 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:34,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:34,079 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,079 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,080 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,080 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,080 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,080 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,080 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,080 [WARN ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,082 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 13 seconds.
2025-03-28T17:13:34,082 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 13 seconds.
2025-03-28T17:13:34,093 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9011, pid=304711
2025-03-28T17:13:34,093 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9011
2025-03-28T17:13:34,094 [INFO ] W-9016-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stdout
2025-03-28T17:13:34,094 [INFO ] W-9016-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stdout
2025-03-28T17:13:34,094 [INFO ] W-9016-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stderr
2025-03-28T17:13:34,094 [INFO ] W-9016-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-densenet161_1.0-stderr
2025-03-28T17:13:34,103 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:34,103 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - [PID]304711
2025-03-28T17:13:34,103 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:34,103 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:34,103 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,103 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,104 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:13:34,104 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:13:34,104 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9011.
2025-03-28T17:13:34,104 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414104
2025-03-28T17:13:34,104 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414104
2025-03-28T17:13:34,104 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414104
2025-03-28T17:13:34,104 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414104
2025-03-28T17:13:34,105 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:34,106 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:34,106 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,106 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:34,106 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:34,106 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:34,106 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:34,106 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,106 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,106 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,106 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,106 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,106 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,106 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,106 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,106 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,107 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,107 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,107 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,107 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,107 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,107 [WARN ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,106 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 13 seconds.
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 13 seconds.
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stdout
2025-03-28T17:13:34,107 [INFO ] W-9011-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stdout
2025-03-28T17:13:34,121 [INFO ] W-9011-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stderr
2025-03-28T17:13:34,121 [INFO ] W-9011-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-densenet161_1.0-stderr
2025-03-28T17:13:34,139 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9013, pid=304714
2025-03-28T17:13:34,139 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9013
2025-03-28T17:13:34,146 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:34,146 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - [PID]304714
2025-03-28T17:13:34,146 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:34,146 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:34,146 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,146 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,146 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:13:34,146 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:13:34,147 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9013.
2025-03-28T17:13:34,147 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414147
2025-03-28T17:13:34,147 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414147
2025-03-28T17:13:34,147 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414147
2025-03-28T17:13:34,147 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414147
2025-03-28T17:13:34,148 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:34,149 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:34,149 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:34,149 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,150 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,150 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,150 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,150 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:34,150 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:34,150 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:34,150 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:34,150 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,150 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,150 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:34,150 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:34,150 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:34,150 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,150 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,150 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,150 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,150 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,150 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,150 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,150 [WARN ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,150 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 13 seconds.
2025-03-28T17:13:34,150 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 13 seconds.
2025-03-28T17:13:34,160 [INFO ] W-9013-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stdout
2025-03-28T17:13:34,160 [INFO ] W-9013-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stdout
2025-03-28T17:13:34,160 [INFO ] W-9013-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stderr
2025-03-28T17:13:34,160 [INFO ] W-9013-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-densenet161_1.0-stderr
2025-03-28T17:13:34,224 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9007, pid=304721
2025-03-28T17:13:34,225 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9007
2025-03-28T17:13:34,232 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:34,232 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - [PID]304721
2025-03-28T17:13:34,232 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:34,232 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:34,232 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,232 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,232 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:13:34,232 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:13:34,232 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9007.
2025-03-28T17:13:34,232 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414232
2025-03-28T17:13:34,232 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414232
2025-03-28T17:13:34,233 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414233
2025-03-28T17:13:34,233 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414233
2025-03-28T17:13:34,233 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:34,234 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,234 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:34,234 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:34,234 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:34,234 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:34,234 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:34,234 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,234 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,234 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,234 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,234 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,234 [WARN ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 13 seconds.
2025-03-28T17:13:34,234 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 13 seconds.
2025-03-28T17:13:34,247 [INFO ] W-9007-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stdout
2025-03-28T17:13:34,247 [INFO ] W-9007-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stdout
2025-03-28T17:13:34,247 [INFO ] W-9007-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stderr
2025-03-28T17:13:34,247 [INFO ] W-9007-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-densenet161_1.0-stderr
2025-03-28T17:13:34,249 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9018, pid=304782
2025-03-28T17:13:34,249 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9018
2025-03-28T17:13:34,256 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:34,256 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - [PID]304782
2025-03-28T17:13:34,256 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:34,256 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:34,256 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,256 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,256 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:13:34,256 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:13:34,257 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9018.
2025-03-28T17:13:34,257 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414257
2025-03-28T17:13:34,257 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414257
2025-03-28T17:13:34,257 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414257
2025-03-28T17:13:34,257 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414257
2025-03-28T17:13:34,257 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,258 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,258 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:34,258 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:34,258 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:34,258 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:34,258 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:34,258 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:34,259 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,259 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:34,259 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,259 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,259 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,259 [WARN ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 13 seconds.
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 13 seconds.
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stdout
2025-03-28T17:13:34,259 [INFO ] W-9018-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stdout
2025-03-28T17:13:34,269 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=304729
2025-03-28T17:13:34,269 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-03-28T17:13:34,271 [INFO ] W-9018-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stderr
2025-03-28T17:13:34,271 [INFO ] W-9018-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-densenet161_1.0-stderr
2025-03-28T17:13:34,272 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9008, pid=304732
2025-03-28T17:13:34,272 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9008
2025-03-28T17:13:34,276 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:34,277 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - [PID]304729
2025-03-28T17:13:34,277 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:34,277 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:34,277 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,277 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,277 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:13:34,277 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:13:34,277 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414277
2025-03-28T17:13:34,277 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-03-28T17:13:34,277 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414277
2025-03-28T17:13:34,277 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414277
2025-03-28T17:13:34,277 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414277
2025-03-28T17:13:34,278 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:34,279 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:34,279 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,279 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:34,279 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:34,279 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:34,279 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,280 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,280 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,280 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,280 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:34,280 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:34,280 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:34,280 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:34,280 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:34,280 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:34,280 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,280 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,280 [WARN ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:34,280 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stdout
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stdout
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2025-03-28T17:13:34,280 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2025-03-28T17:13:34,280 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - [PID]304732
2025-03-28T17:13:34,280 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:34,280 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:34,280 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,280 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,280 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:13:34,280 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:13:34,281 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9008.
2025-03-28T17:13:34,281 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414281
2025-03-28T17:13:34,281 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414281
2025-03-28T17:13:34,281 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414281
2025-03-28T17:13:34,281 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414281
2025-03-28T17:13:34,281 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:34,282 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,282 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:34,282 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:34,283 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,283 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:34,283 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,283 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,283 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,283 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,283 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,283 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:34,283 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:34,283 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:34,283 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:34,283 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:34,283 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:34,283 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:34,283 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,283 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,283 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,283 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,283 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,283 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,283 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,283 [WARN ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,283 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 13 seconds.
2025-03-28T17:13:34,283 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 13 seconds.
2025-03-28T17:13:34,294 [INFO ] W-9004-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stderr
2025-03-28T17:13:34,294 [INFO ] W-9004-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-densenet161_1.0-stderr
2025-03-28T17:13:34,295 [INFO ] W-9008-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stdout
2025-03-28T17:13:34,295 [INFO ] W-9008-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stdout
2025-03-28T17:13:34,295 [INFO ] W-9008-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stderr
2025-03-28T17:13:34,295 [INFO ] W-9008-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-densenet161_1.0-stderr
2025-03-28T17:13:34,301 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9006, pid=304738
2025-03-28T17:13:34,301 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9006
2025-03-28T17:13:34,308 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:34,308 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - [PID]304738
2025-03-28T17:13:34,308 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:34,309 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:34,309 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,309 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,309 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:13:34,309 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:13:34,309 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414309
2025-03-28T17:13:34,309 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414309
2025-03-28T17:13:34,309 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414309
2025-03-28T17:13:34,309 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414309
2025-03-28T17:13:34,309 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9006.
2025-03-28T17:13:34,309 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:34,311 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:34,311 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:34,311 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,311 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,311 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:34,311 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,311 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,311 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:34,311 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:34,311 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,311 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:34,311 [WARN ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:34,311 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 13 seconds.
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 13 seconds.
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stdout
2025-03-28T17:13:34,312 [INFO ] W-9006-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stdout
2025-03-28T17:13:34,324 [INFO ] W-9006-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stderr
2025-03-28T17:13:34,324 [INFO ] W-9006-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-densenet161_1.0-stderr
2025-03-28T17:13:34,350 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9012, pid=304788
2025-03-28T17:13:34,351 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9012
2025-03-28T17:13:34,358 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:34,358 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - [PID]304788
2025-03-28T17:13:34,358 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:34,358 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:34,358 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,358 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,358 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:13:34,358 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:13:34,358 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414358
2025-03-28T17:13:34,358 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414358
2025-03-28T17:13:34,358 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9012.
2025-03-28T17:13:34,358 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414358
2025-03-28T17:13:34,358 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414358
2025-03-28T17:13:34,359 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,360 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:34,360 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:34,360 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:34,360 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:34,360 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:34,360 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,360 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,360 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:34,360 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:34,360 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:34,360 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:34,360 [WARN ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 13 seconds.
2025-03-28T17:13:34,360 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 13 seconds.
2025-03-28T17:13:34,370 [INFO ] W-9012-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stdout
2025-03-28T17:13:34,370 [INFO ] W-9012-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stderr
2025-03-28T17:13:34,370 [INFO ] W-9012-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stdout
2025-03-28T17:13:34,370 [INFO ] W-9012-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-densenet161_1.0-stderr
2025-03-28T17:13:34,435 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=304741
2025-03-28T17:13:34,435 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-03-28T17:13:34,442 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:34,442 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - [PID]304741
2025-03-28T17:13:34,442 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:34,442 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:34,442 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,442 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,442 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:13:34,442 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:13:34,442 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-03-28T17:13:34,442 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414442
2025-03-28T17:13:34,442 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414442
2025-03-28T17:13:34,443 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414443
2025-03-28T17:13:34,443 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414443
2025-03-28T17:13:34,443 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:34,444 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:34,444 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,444 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:34,444 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:34,444 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:34,444 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:34,444 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,444 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,444 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,444 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,444 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,444 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,444 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,444 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,444 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:34,444 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:34,444 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:34,444 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,445 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,445 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,445 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,445 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,445 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,445 [WARN ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:34,445 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:34,446 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2025-03-28T17:13:34,446 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2025-03-28T17:13:34,454 [INFO ] W-9005-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stdout
2025-03-28T17:13:34,454 [INFO ] W-9005-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stdout
2025-03-28T17:13:34,454 [INFO ] W-9005-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stderr
2025-03-28T17:13:34,454 [INFO ] W-9005-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-densenet161_1.0-stderr
2025-03-28T17:13:34,526 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=304785
2025-03-28T17:13:34,526 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-03-28T17:13:34,528 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=304792
2025-03-28T17:13:34,528 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-03-28T17:13:34,533 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:34,533 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - [PID]304785
2025-03-28T17:13:34,533 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:34,533 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:34,533 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,533 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,533 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:13:34,533 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:13:34,534 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-03-28T17:13:34,534 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414534
2025-03-28T17:13:34,534 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414534
2025-03-28T17:13:34,534 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414534
2025-03-28T17:13:34,534 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414534
2025-03-28T17:13:34,534 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:34,535 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:34,535 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - [PID]304792
2025-03-28T17:13:34,535 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:34,535 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:34,535 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,535 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,535 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:13:34,535 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:13:34,535 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414535
2025-03-28T17:13:34,535 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414535
2025-03-28T17:13:34,535 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-03-28T17:13:34,535 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414535
2025-03-28T17:13:34,535 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414535
2025-03-28T17:13:34,535 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,536 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,536 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,536 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:34,536 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:34,536 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:34,536 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:34,536 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,536 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:34,536 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:34,536 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,536 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:34,536 [WARN ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,536 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:34,536 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:34,536 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:34,536 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:34,536 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:34,536 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:34,536 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,536 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,536 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:34,536 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2025-03-28T17:13:34,536 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,536 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,536 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:34,536 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2025-03-28T17:13:34,537 [INFO ] W-9000-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stdout
2025-03-28T17:13:34,537 [INFO ] W-9000-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stdout
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:34,537 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,537 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:34,537 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,537 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,537 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,537 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,537 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,537 [WARN ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stdout
2025-03-28T17:13:34,537 [INFO ] W-9001-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stdout
2025-03-28T17:13:34,544 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9014, pid=304791
2025-03-28T17:13:34,544 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9014
2025-03-28T17:13:34,549 [INFO ] W-9000-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stderr
2025-03-28T17:13:34,549 [INFO ] W-9000-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-densenet161_1.0-stderr
2025-03-28T17:13:34,549 [INFO ] W-9001-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stderr
2025-03-28T17:13:34,549 [INFO ] W-9001-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-densenet161_1.0-stderr
2025-03-28T17:13:34,551 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:13:34,551 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - [PID]304791
2025-03-28T17:13:34,552 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:13:34,552 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:13:34,552 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,552 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2025-03-28T17:13:34,552 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:13:34,552 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:13:34,552 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414552
2025-03-28T17:13:34,552 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743196414552
2025-03-28T17:13:34,552 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414552
2025-03-28T17:13:34,552 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743196414552
2025-03-28T17:13:34,552 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9014.
2025-03-28T17:13:34,552 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Backend worker process died.
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 108, in load
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2025-03-28T17:13:34,554 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 153, in _load_handler_file
2025-03-28T17:13:34,554 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,554 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,554 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'image_classifier'
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 301, in <module>
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     worker.run_server()
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 268, in run_server
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 196, in handle_connection
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py", line 133, in load_model
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 110, in load
2025-03-28T17:13:34,554 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2025-03-28T17:13:34,554 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., startupTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1770) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:234) ~[model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_loader.py", line 159, in _load_default_handler
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-03-28T17:13:34,554 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-03-28T17:13:34,554 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: densenet161, error: Worker died.
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-03-28T17:13:34,554 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-03-28T17:13:34,554 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2025-03-28T17:13:34,554 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-03-28T17:13:34,554 [WARN ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/image_classifier.py", line 6, in <module>
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG -     from torchvision import transforms
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'torchvision'
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 13 seconds.
2025-03-28T17:13:34,554 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 13 seconds.
2025-03-28T17:13:34,566 [INFO ] W-9014-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stdout
2025-03-28T17:13:34,566 [INFO ] W-9014-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stdout
2025-03-28T17:13:34,566 [INFO ] W-9014-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stderr
2025-03-28T17:13:34,566 [INFO ] W-9014-densenet161_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-densenet161_1.0-stderr
2025-03-28T17:45:59,747 [DEBUG] main org.pytorch.serve.util.ConfigManager - xpu-smi not available or failed: Cannot run program "xpu-smi": error=2, No such file or directory
2025-03-28T17:45:59,747 [DEBUG] main org.pytorch.serve.util.ConfigManager - xpu-smi not available or failed: Cannot run program "xpu-smi": error=2, No such file or directory
2025-03-28T17:45:59,759 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2025-03-28T17:45:59,759 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2025-03-28T17:45:59,769 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-03-28T17:45:59,769 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-03-28T17:45:59,798 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml
2025-03-28T17:45:59,798 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml
2025-03-28T17:45:59,852 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.12.0
TS Home: /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages
Current directory: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo
Temp directory: /tmp
Metrics config path: /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 20
Max heap size: 16000 M
Python executable: /home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/model_store
Initial Models: model_store/densenet161.mar
Log dir: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/logs
Metrics dir: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 20
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: false
Workflow Store: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
Model API enabled: true
2025-03-28T17:45:59,852 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.12.0
TS Home: /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages
Current directory: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo
Temp directory: /tmp
Metrics config path: /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 20
Max heap size: 16000 M
Python executable: /home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/model_store
Initial Models: model_store/densenet161.mar
Log dir: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/logs
Metrics dir: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 20
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: false
Workflow Store: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
Model API enabled: true
2025-03-28T17:45:59,857 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-03-28T17:45:59,857 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-03-28T17:45:59,866 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model_store/densenet161.mar
2025-03-28T17:45:59,866 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model_store/densenet161.mar
2025-03-28T17:46:00,602 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model densenet161
2025-03-28T17:46:00,602 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model densenet161
2025-03-28T17:46:00,602 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model densenet161
2025-03-28T17:46:00,602 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model densenet161
2025-03-28T17:46:00,602 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model densenet161 loaded.
2025-03-28T17:46:00,602 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model densenet161 loaded.
2025-03-28T17:46:00,602 [WARN ] main org.pytorch.serve.ModelServer - Invalid model config in mar, minWorkers:0, maxWorkers:0
2025-03-28T17:46:00,602 [WARN ] main org.pytorch.serve.ModelServer - Invalid model config in mar, minWorkers:0, maxWorkers:0
2025-03-28T17:46:00,603 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: densenet161, count: 20
2025-03-28T17:46:00,603 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: densenet161, count: 20
2025-03-28T17:46:00,611 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,612 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,612 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,612 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,612 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,612 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,612 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,612 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,611 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,612 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,613 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,613 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:46:00,615 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2025-03-28T17:46:00,615 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2025-03-28T17:46:00,712 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2025-03-28T17:46:00,712 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2025-03-28T17:46:00,712 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2025-03-28T17:46:00,712 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2025-03-28T17:46:00,722 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2025-03-28T17:46:00,722 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2025-03-28T17:46:00,722 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2025-03-28T17:46:00,722 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2025-03-28T17:46:00,723 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2025-03-28T17:46:00,723 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2025-03-28T17:46:01,187 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2025-03-28T17:46:01,187 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2025-03-28T17:46:01,450 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198361
2025-03-28T17:46:01,453 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:216.46366500854492|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198361
2025-03-28T17:46:01,453 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:733.9256172180176|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198361
2025-03-28T17:46:01,453 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:77.2|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198361
2025-03-28T17:46:01,453 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:34567.37109375|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198361
2025-03-28T17:46:01,453 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:20649.25390625|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198361
2025-03-28T17:46:01,454 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:46.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198361
2025-03-28T17:46:02,566 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=325165
2025-03-28T17:46:02,577 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-03-28T17:46:02,579 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9013, pid=325159
2025-03-28T17:46:02,582 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9013
2025-03-28T17:46:02,584 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,585 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - [PID]325165
2025-03-28T17:46:02,585 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,585 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,585 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,585 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,590 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:46:02,590 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:46:02,599 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-03-28T17:46:02,601 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362601
2025-03-28T17:46:02,601 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362601
2025-03-28T17:46:02,601 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,603 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - [PID]325159
2025-03-28T17:46:02,603 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362603
2025-03-28T17:46:02,604 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,603 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,603 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362603
2025-03-28T17:46:02,604 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,604 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:46:02,604 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,604 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:46:02,607 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9013.
2025-03-28T17:46:02,609 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362609
2025-03-28T17:46:02,609 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362609
2025-03-28T17:46:02,610 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362610
2025-03-28T17:46:02,610 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362610
2025-03-28T17:46:02,633 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9012, pid=325163
2025-03-28T17:46:02,634 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9012
2025-03-28T17:46:02,633 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9018, pid=325174
2025-03-28T17:46:02,637 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9018
2025-03-28T17:46:02,648 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,652 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,655 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - [PID]325174
2025-03-28T17:46:02,655 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,655 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,655 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,655 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,655 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:46:02,655 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,655 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:46:02,656 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9015, pid=325168
2025-03-28T17:46:02,657 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9015
2025-03-28T17:46:02,657 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362657
2025-03-28T17:46:02,657 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362657
2025-03-28T17:46:02,657 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9018.
2025-03-28T17:46:02,658 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362658
2025-03-28T17:46:02,658 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362658
2025-03-28T17:46:02,662 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,666 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - [PID]325163
2025-03-28T17:46:02,666 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,666 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,666 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,666 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,666 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:46:02,666 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:46:02,670 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,670 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - [PID]325168
2025-03-28T17:46:02,671 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,671 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,671 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:46:02,671 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:46:02,671 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,671 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,672 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9012.
2025-03-28T17:46:02,672 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362672
2025-03-28T17:46:02,672 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362672
2025-03-28T17:46:02,672 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362672
2025-03-28T17:46:02,672 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362672
2025-03-28T17:46:02,674 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362674
2025-03-28T17:46:02,674 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362674
2025-03-28T17:46:02,675 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362675
2025-03-28T17:46:02,675 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362675
2025-03-28T17:46:02,676 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9015.
2025-03-28T17:46:02,679 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,684 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9009, pid=325169
2025-03-28T17:46:02,685 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9009
2025-03-28T17:46:02,694 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,700 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,701 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - [PID]325169
2025-03-28T17:46:02,702 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,702 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,702 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:46:02,702 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:46:02,703 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,703 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,704 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,706 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362706
2025-03-28T17:46:02,706 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362706
2025-03-28T17:46:02,706 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362706
2025-03-28T17:46:02,706 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362706
2025-03-28T17:46:02,706 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9009.
2025-03-28T17:46:02,708 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9014, pid=325164
2025-03-28T17:46:02,709 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9014
2025-03-28T17:46:02,723 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,724 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - [PID]325164
2025-03-28T17:46:02,725 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,725 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,725 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:46:02,725 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:46:02,724 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,726 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,727 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,731 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9014.
2025-03-28T17:46:02,731 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362731
2025-03-28T17:46:02,731 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362731
2025-03-28T17:46:02,735 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362735
2025-03-28T17:46:02,735 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362735
2025-03-28T17:46:02,753 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,753 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9007, pid=325170
2025-03-28T17:46:02,758 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9007
2025-03-28T17:46:02,765 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9006, pid=325161
2025-03-28T17:46:02,766 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9006
2025-03-28T17:46:02,769 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,770 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - [PID]325170
2025-03-28T17:46:02,770 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,770 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,770 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,771 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,771 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:46:02,771 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:46:02,775 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9007.
2025-03-28T17:46:02,777 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,778 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - [PID]325161
2025-03-28T17:46:02,778 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362778
2025-03-28T17:46:02,778 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,778 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362778
2025-03-28T17:46:02,778 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,778 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:46:02,778 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362778
2025-03-28T17:46:02,778 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:46:02,778 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,778 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362778
2025-03-28T17:46:02,778 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,781 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362781
2025-03-28T17:46:02,781 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362781
2025-03-28T17:46:02,781 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9006.
2025-03-28T17:46:02,782 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362782
2025-03-28T17:46:02,782 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362782
2025-03-28T17:46:02,783 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=325162
2025-03-28T17:46:02,784 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-03-28T17:46:02,791 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9008, pid=325154
2025-03-28T17:46:02,791 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9008
2025-03-28T17:46:02,796 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9010, pid=325156
2025-03-28T17:46:02,797 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9010
2025-03-28T17:46:02,797 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,798 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - [PID]325162
2025-03-28T17:46:02,798 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,798 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,798 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:46:02,798 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:46:02,799 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,799 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,800 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362800
2025-03-28T17:46:02,800 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362800
2025-03-28T17:46:02,800 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362800
2025-03-28T17:46:02,800 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362800
2025-03-28T17:46:02,802 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-03-28T17:46:02,802 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,802 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,803 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,803 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - [PID]325154
2025-03-28T17:46:02,804 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,804 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,804 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,804 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,804 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:46:02,804 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:46:02,808 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9008.
2025-03-28T17:46:02,811 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362811
2025-03-28T17:46:02,811 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362811
2025-03-28T17:46:02,811 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362811
2025-03-28T17:46:02,811 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362811
2025-03-28T17:46:02,819 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,820 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - [PID]325156
2025-03-28T17:46:02,820 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,820 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,821 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,821 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,821 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:46:02,821 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:46:02,827 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9010.
2025-03-28T17:46:02,827 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362827
2025-03-28T17:46:02,827 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362827
2025-03-28T17:46:02,827 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362827
2025-03-28T17:46:02,827 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362827
2025-03-28T17:46:02,830 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,850 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,859 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,878 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=325171
2025-03-28T17:46:02,880 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-03-28T17:46:02,884 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=325157
2025-03-28T17:46:02,888 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-03-28T17:46:02,894 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9019, pid=325176
2025-03-28T17:46:02,896 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,896 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - [PID]325171
2025-03-28T17:46:02,897 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,897 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,897 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,897 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:46:02,896 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9019
2025-03-28T17:46:02,897 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,897 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=325175
2025-03-28T17:46:02,898 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-03-28T17:46:02,897 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:46:02,900 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,900 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - [PID]325157
2025-03-28T17:46:02,901 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,901 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,901 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,901 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:46:02,901 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:46:02,901 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,903 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362903
2025-03-28T17:46:02,903 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-03-28T17:46:02,903 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362903
2025-03-28T17:46:02,903 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-03-28T17:46:02,903 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362903
2025-03-28T17:46:02,903 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362903
2025-03-28T17:46:02,903 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362903
2025-03-28T17:46:02,903 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362903
2025-03-28T17:46:02,904 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362904
2025-03-28T17:46:02,904 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362904
2025-03-28T17:46:02,911 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,912 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,912 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - [PID]325175
2025-03-28T17:46:02,914 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,913 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,914 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,914 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:46:02,914 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:46:02,914 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,916 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - [PID]325176
2025-03-28T17:46:02,916 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9011, pid=325158
2025-03-28T17:46:02,916 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9011
2025-03-28T17:46:02,917 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,917 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,917 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:46:02,917 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:46:02,917 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,918 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,918 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362918
2025-03-28T17:46:02,918 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362918
2025-03-28T17:46:02,918 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362918
2025-03-28T17:46:02,918 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362918
2025-03-28T17:46:02,919 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362919
2025-03-28T17:46:02,919 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362919
2025-03-28T17:46:02,919 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-03-28T17:46:02,920 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9019.
2025-03-28T17:46:02,924 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362924
2025-03-28T17:46:02,924 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362924
2025-03-28T17:46:02,925 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=325172
2025-03-28T17:46:02,929 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,930 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-03-28T17:46:02,928 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,931 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - [PID]325158
2025-03-28T17:46:02,932 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,932 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,932 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,932 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:46:02,932 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:46:02,932 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,935 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9011.
2025-03-28T17:46:02,935 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362935
2025-03-28T17:46:02,935 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362935
2025-03-28T17:46:02,936 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362936
2025-03-28T17:46:02,936 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362936
2025-03-28T17:46:02,940 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,942 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,942 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:02,944 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - [PID]325172
2025-03-28T17:46:02,944 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,944 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:02,945 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:46:02,945 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:46:02,945 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:02,946 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:02,954 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362954
2025-03-28T17:46:02,954 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198362954
2025-03-28T17:46:02,954 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-03-28T17:46:02,954 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362954
2025-03-28T17:46:02,954 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198362954
2025-03-28T17:46:02,954 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,960 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:02,972 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:03,009 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9016, pid=325166
2025-03-28T17:46:03,010 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9016
2025-03-28T17:46:03,024 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:03,024 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - [PID]325166
2025-03-28T17:46:03,024 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:03,025 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:03,025 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:03,025 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:46:03,025 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:03,025 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:46:03,032 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198363032
2025-03-28T17:46:03,032 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198363032
2025-03-28T17:46:03,032 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198363032
2025-03-28T17:46:03,032 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198363032
2025-03-28T17:46:03,033 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9016.
2025-03-28T17:46:03,048 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:03,090 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9017, pid=325160
2025-03-28T17:46:03,094 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9017
2025-03-28T17:46:03,107 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:46:03,108 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - [PID]325160
2025-03-28T17:46:03,108 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:46:03,108 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:03,108 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:46:03,108 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:46:03,109 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:46:03,109 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:46:03,110 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198363110
2025-03-28T17:46:03,110 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198363110
2025-03-28T17:46:03,112 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9017.
2025-03-28T17:46:03,115 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198363115
2025-03-28T17:46:03,115 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198363115
2025-03-28T17:46:03,132 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:46:04,929 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:04,938 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:04,956 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:04,956 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:04,963 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:04,964 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:04,966 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:04,968 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:04,979 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:04,991 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:04,992 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:04,993 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:04,994 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,006 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,006 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,010 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:05,011 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:05,015 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:05,028 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:05,034 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,034 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,035 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,035 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,046 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,046 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,054 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:05,057 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,057 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,063 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:05,079 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,079 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:05,080 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,089 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,089 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,100 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:05,103 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,104 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,122 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,122 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,171 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:05,173 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:05,185 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:05,194 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,194 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,198 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,199 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,207 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:05,211 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,212 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,218 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:05,229 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,229 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,249 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,250 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,322 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:05,357 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,357 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:05,413 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:46:05,460 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:46:05,461 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:46:19,886 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:19,975 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17021
2025-03-28T17:46:19,975 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17021
2025-03-28T17:46:19,975 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:19,975 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:19,975 [INFO ] W-9002-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:19369.0|#WorkerName:W-9002-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198379
2025-03-28T17:46:19,976 [INFO ] W-9002-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198379
2025-03-28T17:46:23,670 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:23,688 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21016
2025-03-28T17:46:23,688 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21016
2025-03-28T17:46:23,688 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:23,688 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:23,688 [INFO ] W-9012-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:23078.0|#WorkerName:W-9012-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198383
2025-03-28T17:46:23,688 [INFO ] W-9012-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198383
2025-03-28T17:46:25,362 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:25,364 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22428
2025-03-28T17:46:25,364 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22428
2025-03-28T17:46:25,364 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:25,364 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:25,364 [INFO ] W-9011-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:24754.0|#WorkerName:W-9011-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198385
2025-03-28T17:46:25,365 [INFO ] W-9011-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198385
2025-03-28T17:46:27,456 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:27,458 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24426
2025-03-28T17:46:27,458 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24426
2025-03-28T17:46:27,459 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:27,459 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:27,459 [INFO ] W-9016-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:26848.0|#WorkerName:W-9016-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198387
2025-03-28T17:46:27,463 [INFO ] W-9016-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:5.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198387
2025-03-28T17:46:28,090 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:28,135 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 25324
2025-03-28T17:46:28,135 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 25324
2025-03-28T17:46:28,135 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:28,135 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:28,135 [INFO ] W-9008-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:27525.0|#WorkerName:W-9008-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198388
2025-03-28T17:46:28,135 [INFO ] W-9008-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198388
2025-03-28T17:46:28,373 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 25595
2025-03-28T17:46:28,373 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 25595
2025-03-28T17:46:28,373 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:28,373 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:28,373 [INFO ] W-9007-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:27763.0|#WorkerName:W-9007-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198388
2025-03-28T17:46:28,373 [INFO ] W-9007-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198388
2025-03-28T17:46:28,372 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:28,488 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:28,490 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 25815
2025-03-28T17:46:28,490 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 25815
2025-03-28T17:46:28,491 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:28,491 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:28,491 [INFO ] W-9015-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:27881.0|#WorkerName:W-9015-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198388
2025-03-28T17:46:28,494 [INFO ] W-9015-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:5.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198388
2025-03-28T17:46:29,118 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:29,119 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 26319
2025-03-28T17:46:29,119 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 26319
2025-03-28T17:46:29,119 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:29,119 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:29,119 [INFO ] W-9003-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:28513.0|#WorkerName:W-9003-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198389
2025-03-28T17:46:29,120 [INFO ] W-9003-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198389
2025-03-28T17:46:30,009 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:30,011 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 27353
2025-03-28T17:46:30,011 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 27353
2025-03-28T17:46:30,011 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:30,011 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:30,011 [INFO ] W-9018-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:29400.0|#WorkerName:W-9018-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198390
2025-03-28T17:46:30,014 [INFO ] W-9018-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:4.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198390
2025-03-28T17:46:30,259 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:30,268 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 27533
2025-03-28T17:46:30,268 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 27533
2025-03-28T17:46:30,268 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:30,268 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:30,269 [INFO ] W-9014-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:29659.0|#WorkerName:W-9014-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198390
2025-03-28T17:46:30,269 [INFO ] W-9014-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:5.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198390
2025-03-28T17:46:30,277 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 27673
2025-03-28T17:46:30,277 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:30,277 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 27673
2025-03-28T17:46:30,278 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:30,278 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:30,278 [INFO ] W-9004-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:29672.0|#WorkerName:W-9004-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198390
2025-03-28T17:46:30,280 [INFO ] W-9004-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:6.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198390
2025-03-28T17:46:30,509 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:30,512 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 27685
2025-03-28T17:46:30,512 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 27685
2025-03-28T17:46:30,512 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:30,512 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:30,513 [INFO ] W-9010-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:29903.0|#WorkerName:W-9010-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198390
2025-03-28T17:46:30,513 [INFO ] W-9010-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198390
2025-03-28T17:46:31,227 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:31,236 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 28318
2025-03-28T17:46:31,236 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 28318
2025-03-28T17:46:31,236 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:31,236 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:31,236 [INFO ] W-9001-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:30630.0|#WorkerName:W-9001-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198391
2025-03-28T17:46:31,237 [INFO ] W-9001-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198391
2025-03-28T17:46:32,152 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:32,154 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29230
2025-03-28T17:46:32,154 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29230
2025-03-28T17:46:32,154 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:32,154 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:32,154 [INFO ] W-9019-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:31543.0|#WorkerName:W-9019-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198392
2025-03-28T17:46:32,154 [INFO ] W-9019-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:5.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198392
2025-03-28T17:46:32,217 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:32,218 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29103
2025-03-28T17:46:32,218 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29103
2025-03-28T17:46:32,218 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:32,218 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:32,219 [INFO ] W-9017-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:31607.0|#WorkerName:W-9017-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198392
2025-03-28T17:46:32,219 [INFO ] W-9017-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:6.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198392
2025-03-28T17:46:32,269 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:32,270 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29660
2025-03-28T17:46:32,270 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29660
2025-03-28T17:46:32,270 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:32,270 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:32,270 [INFO ] W-9013-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:31660.0|#WorkerName:W-9013-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198392
2025-03-28T17:46:32,271 [INFO ] W-9013-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198392
2025-03-28T17:46:32,292 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:32,294 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29391
2025-03-28T17:46:32,294 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29391
2025-03-28T17:46:32,294 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:32,294 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:32,294 [INFO ] W-9000-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:31689.0|#WorkerName:W-9000-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198392
2025-03-28T17:46:32,295 [INFO ] W-9000-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198392
2025-03-28T17:46:32,413 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:32,414 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29632
2025-03-28T17:46:32,414 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29632
2025-03-28T17:46:32,414 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:32,414 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:32,414 [INFO ] W-9006-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:31804.0|#WorkerName:W-9006-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198392
2025-03-28T17:46:32,414 [INFO ] W-9006-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198392
2025-03-28T17:46:32,510 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:32,511 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29805
2025-03-28T17:46:32,511 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29805
2025-03-28T17:46:32,511 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:32,511 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:32,512 [INFO ] W-9009-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:31902.0|#WorkerName:W-9009-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198392
2025-03-28T17:46:32,512 [INFO ] W-9009-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198392
2025-03-28T17:46:32,710 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Compiled model with backend inductor, mode reduce-overhead
2025-03-28T17:46:32,711 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29807
2025-03-28T17:46:32,711 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29807
2025-03-28T17:46:32,711 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:32,711 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:46:32,711 [INFO ] W-9005-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:32105.0|#WorkerName:W-9005-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198392
2025-03-28T17:46:32,711 [INFO ] W-9005-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198392
2025-03-28T17:47:01,229 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198421
2025-03-28T17:47:01,230 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:216.46340560913086|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198421
2025-03-28T17:47:01,230 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:733.9258460998535|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198421
2025-03-28T17:47:01,230 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:77.2|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198421
2025-03-28T17:47:01,230 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:19079.98828125|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198421
2025-03-28T17:47:01,230 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:36223.4453125|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198421
2025-03-28T17:47:01,230 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:70.2|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198421
2025-03-28T17:47:25,191 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:densenet161,model_version:default|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198445
2025-03-28T17:47:25,192 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1743198445192
2025-03-28T17:47:25,192 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1743198445192
2025-03-28T17:47:25,192 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198445192
2025-03-28T17:47:25,192 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198445192
2025-03-28T17:47:25,193 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Backend received inference at: 1743198445
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Invoking custom service failed.
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/service.py", line 135, in predict
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/base_handler.py", line 458, in handle
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     output = self.inference(data_preprocess)
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/handler_utils/timer.py", line 63, in wrap_func
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     result = func(self, *args, **kwargs)
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/torch_handler/base_handler.py", line 401, in inference
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     results = self.model(marshalled_data, *args, **kwargs)
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return self._call_impl(*args, **kwargs)
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return forward_call(*args, **kwargs)
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 574, in _fn
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return fn(*args, **kwargs)
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return self._call_impl(*args, **kwargs)
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return forward_call(*args, **kwargs)
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1380, in __call__
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return self._torchdynamo_orig_callable(
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1164, in __call__
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     result = self._inner_convert(
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 547, in __call__
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return _compile(
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 986, in _compile
2025-03-28T17:47:38,490 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     guarded_code = compile_inner(code, one_graph, hooks, transform)
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 715, in compile_inner
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return _compile_inner(code, one_graph, hooks, transform)
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return function(*args, **kwargs)
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 750, in _compile_inner
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     out_code = transform_code_object(code, transform)
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1361, in transform_code_object
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     transformations(instructions, code_options)
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 231, in _fn
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return fn(*args, **kwargs)
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 662, in transform
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     tracer.run()
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2868, in run
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     super().run()
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1052, in run
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     while self.step():
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 962, in step
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     self.dispatch_table[inst.opcode](self, inst)
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3048, in RETURN_VALUE
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     self._return(inst)
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3033, in _return
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     self.output.compile_subgraph(
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1101, in compile_subgraph
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     self.compile_and_call_fx_graph(
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1382, in compile_and_call_fx_graph
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     compiled_fn = self.call_user_compiler(gm)
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1432, in call_user_compiler
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return self._call_user_compiler(gm)
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1483, in _call_user_compiler
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 1462, in _call_user_compiler
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     compiled_fn = compiler_fn(gm, self.example_inputs())
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py", line 130, in __call__
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     compiled_gm = compiler_fn(gm, example_inputs)
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/__init__.py", line 2340, in __call__
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return compile_fx(model_, inputs_, config_patches=self.config)
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1552, in compile_fx
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return compile_fx(
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1863, in compile_fx
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return aot_autograd(
2025-03-28T17:47:38,491 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 83, in __call__
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1155, in aot_module_simplified
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     compiled_fn = dispatch_and_compile()
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1131, in dispatch_and_compile
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     compiled_fn, _ = create_aot_dispatcher_function(
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 580, in create_aot_dispatcher_function
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return _create_aot_dispatcher_function(
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 830, in _create_aot_dispatcher_function
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     compiled_fn, fw_metadata = compiler_fn(
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 203, in aot_dispatch_base
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     compiled_fw = compiler(fw_module, updated_flat_args)
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 489, in __call__
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return self.compiler_fn(gm, example_inputs)
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1741, in fw_compiler_base
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return inner_compile(
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/contextlib.py", line 79, in inner
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return func(*args, **kwds)
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 569, in compile_fx_inner
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py", line 102, in debug_wrapper
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     inner_compiled_fn = compiler_fn(gm, example_inputs)
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 685, in _compile_fx_inner
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     mb_compiled_graph = fx_codegen_and_compile(
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1129, in fx_codegen_and_compile
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1044, in codegen_and_compile
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     compiled_fn = graph.compile_to_module().call
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2027, in compile_to_module
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return self._compile_to_module()
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2033, in _compile_to_module
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/graph.py", line 1968, in codegen
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     self.scheduler.codegen()
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/scheduler.py", line 3477, in codegen
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return self._codegen()
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/scheduler.py", line 3554, in _codegen
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     self.get_backend(device).codegen_node(node)
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/codegen/cpp.py", line 4781, in codegen_node
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     cpp_kernel_proxy = CppKernelProxy(kernel_group)
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/codegen/cpp.py", line 3632, in __init__
2025-03-28T17:47:38,492 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     self.picked_vec_isa: cpu_vec_isa.VecISA = cpu_vec_isa.pick_vec_isa()
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/cpu_vec_isa.py", line 414, in pick_vec_isa
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     _valid_vec_isa_list: List[VecISA] = valid_vec_isa_list()
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/cpu_vec_isa.py", line 401, in valid_vec_isa_list
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     isa_list.extend(
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/cpu_vec_isa.py", line 401, in <genexpr>
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     isa_list.extend(
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/cpu_vec_isa.py", line 142, in __bool__
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return self.__bool__impl(config.cpp.vec_isa_ok)
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/cpu_vec_isa.py", line 152, in __bool__impl
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     return self.check_build(VecISA._avx_code)
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/cpu_vec_isa.py", line 102, in check_build
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     extra=_get_isa_dry_compile_fingerprint(self._arch_flags),
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/cpu_vec_isa.py", line 28, in _get_isa_dry_compile_fingerprint
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     compiler_info = get_compiler_version_info(get_cpp_compiler())
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/cpp_builder.py", line 152, in get_cpp_compiler
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     compiler = cpp_compiler_search(search)
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -   File "/home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/torch/_inductor/cpp_builder.py", line 94, in cpp_compiler_search
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     raise exc.InvalidCxxCompiler
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - InvalidCxxCompiler: No working C++ compiler found in torch._inductor.config.cpp.cxx: (None, 'g++')
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - You can suppress this exception and fall back to eager by setting:
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     import torch._dynamo
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG -     torch._dynamo.config.suppress_errors = True
2025-03-28T17:47:38,493 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - 
2025-03-28T17:47:38,496 [INFO ] W-9002-densenet161_1.0 ACCESS_LOG - /127.0.0.1:55736 "PUT /predictions/densenet161 HTTP/1.1" 503 13306
2025-03-28T17:47:38,496 [INFO ] W-9002-densenet161_1.0 TS_METRICS - Requests5XX.Count:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198458
2025-03-28T17:47:38,496 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 109023, Inference time ns: 13304747542
2025-03-28T17:47:38,496 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 109023, Inference time ns: 13304747542
2025-03-28T17:47:38,496 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13302
2025-03-28T17:47:38,496 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13302
2025-03-28T17:47:38,496 [INFO ] W-9002-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198458
2025-03-28T17:48:01,221 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198481
2025-03-28T17:48:01,221 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:216.4615707397461|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198481
2025-03-28T17:48:01,221 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:733.9277420043945|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198481
2025-03-28T17:48:01,221 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:77.2|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198481
2025-03-28T17:48:01,221 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:18881.1796875|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198481
2025-03-28T17:48:01,221 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:36386.48046875|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198481
2025-03-28T17:48:01,221 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:70.5|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198481
2025-03-28T17:50:49,123 [DEBUG] main org.pytorch.serve.util.ConfigManager - xpu-smi not available or failed: Cannot run program "xpu-smi": error=2, No such file or directory
2025-03-28T17:50:49,123 [DEBUG] main org.pytorch.serve.util.ConfigManager - xpu-smi not available or failed: Cannot run program "xpu-smi": error=2, No such file or directory
2025-03-28T17:50:49,125 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2025-03-28T17:50:49,125 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2025-03-28T17:50:49,137 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-03-28T17:50:49,137 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-03-28T17:50:49,166 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml
2025-03-28T17:50:49,166 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml
2025-03-28T17:50:49,223 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.12.0
TS Home: /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages
Current directory: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo
Temp directory: /tmp
Metrics config path: /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 20
Max heap size: 16000 M
Python executable: /home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/model_store
Initial Models: model_store/densenet161.mar
Log dir: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/logs
Metrics dir: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 20
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: false
Workflow Store: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
Model API enabled: true
2025-03-28T17:50:49,223 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.12.0
TS Home: /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages
Current directory: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo
Temp directory: /tmp
Metrics config path: /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 20
Max heap size: 16000 M
Python executable: /home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/model_store
Initial Models: model_store/densenet161.mar
Log dir: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/logs
Metrics dir: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 20
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: false
Workflow Store: /home/equarmjn/Documents/support-cases-sessions/openvino-modelserver-demo/model_store
CPP log config: N/A
Model config: N/A
System metrics command: default
Model API enabled: true
2025-03-28T17:50:49,228 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-03-28T17:50:49,228 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-03-28T17:50:49,237 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model_store/densenet161.mar
2025-03-28T17:50:49,237 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model_store/densenet161.mar
2025-03-28T17:50:49,950 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model densenet161
2025-03-28T17:50:49,950 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model densenet161
2025-03-28T17:50:49,950 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model densenet161
2025-03-28T17:50:49,950 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model densenet161
2025-03-28T17:50:49,951 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model densenet161 loaded.
2025-03-28T17:50:49,951 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model densenet161 loaded.
2025-03-28T17:50:49,951 [WARN ] main org.pytorch.serve.ModelServer - Invalid model config in mar, minWorkers:0, maxWorkers:0
2025-03-28T17:50:49,951 [WARN ] main org.pytorch.serve.ModelServer - Invalid model config in mar, minWorkers:0, maxWorkers:0
2025-03-28T17:50:49,951 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: densenet161, count: 20
2025-03-28T17:50:49,951 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: densenet161, count: 20
2025-03-28T17:50:49,959 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,960 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,960 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,960 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,960 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,960 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,960 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9019, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,960 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9018, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,960 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,960 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,962 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2025-03-28T17:50:49,960 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,962 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2025-03-28T17:50:49,960 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9016, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,960 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9017, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:49,959 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/equarmjn/.pyenv/versions/3.10.16/bin/python3.10, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011, --metrics-config, /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml]
2025-03-28T17:50:50,043 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2025-03-28T17:50:50,043 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2025-03-28T17:50:50,044 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2025-03-28T17:50:50,044 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2025-03-28T17:50:50,046 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2025-03-28T17:50:50,046 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2025-03-28T17:50:50,048 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2025-03-28T17:50:50,048 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2025-03-28T17:50:50,054 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2025-03-28T17:50:50,054 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2025-03-28T17:50:50,459 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2025-03-28T17:50:50,459 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2025-03-28T17:50:50,616 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198650
2025-03-28T17:50:50,620 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:216.46179962158203|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198650
2025-03-28T17:50:50,621 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:733.9274826049805|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198650
2025-03-28T17:50:50,621 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:77.2|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198650
2025-03-28T17:50:50,623 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:34429.75|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198650
2025-03-28T17:50:50,627 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:20806.0390625|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198650
2025-03-28T17:50:50,628 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:46.2|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198650
2025-03-28T17:50:51,904 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9017, pid=329091
2025-03-28T17:50:51,910 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9017
2025-03-28T17:50:51,910 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9010, pid=329082
2025-03-28T17:50:51,914 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9010
2025-03-28T17:50:51,920 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9009, pid=329086
2025-03-28T17:50:51,923 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9009
2025-03-28T17:50:51,922 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:51,925 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - [PID]329091
2025-03-28T17:50:51,926 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:51,926 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:51,926 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:51,927 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:51,927 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:51,927 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - [PID]329082
2025-03-28T17:50:51,928 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:51,928 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:51,931 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:51,931 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:51,932 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:50:51,932 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2025-03-28T17:50:51,935 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:50:51,935 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:51,935 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9017
2025-03-28T17:50:51,937 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - [PID]329086
2025-03-28T17:50:51,937 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:51,937 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:51,937 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:51,938 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:51,938 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:50:51,938 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2025-03-28T17:50:51,943 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9017.
2025-03-28T17:50:51,943 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9009.
2025-03-28T17:50:51,946 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198651946
2025-03-28T17:50:51,946 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198651946
2025-03-28T17:50:51,946 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198651946
2025-03-28T17:50:51,944 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9010.
2025-03-28T17:50:51,946 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198651946
2025-03-28T17:50:51,948 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198651948
2025-03-28T17:50:51,948 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198651948
2025-03-28T17:50:51,948 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198651948
2025-03-28T17:50:51,948 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198651948
2025-03-28T17:50:51,949 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198651949
2025-03-28T17:50:51,949 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198651949
2025-03-28T17:50:51,949 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198651949
2025-03-28T17:50:51,949 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198651949
2025-03-28T17:50:51,952 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=329085
2025-03-28T17:50:51,959 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-03-28T17:50:51,954 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9012, pid=329077
2025-03-28T17:50:51,959 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9012
2025-03-28T17:50:51,962 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:51,963 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - [PID]329077
2025-03-28T17:50:51,963 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:51,963 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:51,964 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:51,964 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:51,964 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:50:51,964 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2025-03-28T17:50:51,968 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:51,968 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9012.
2025-03-28T17:50:51,968 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - [PID]329085
2025-03-28T17:50:51,968 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:51,968 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:51,968 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198651968
2025-03-28T17:50:51,968 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198651968
2025-03-28T17:50:51,969 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198651969
2025-03-28T17:50:51,969 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198651969
2025-03-28T17:50:51,969 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:51,969 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:51,970 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:50:51,970 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2025-03-28T17:50:51,972 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198651972
2025-03-28T17:50:51,972 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198651972
2025-03-28T17:50:51,972 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198651972
2025-03-28T17:50:51,972 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198651972
2025-03-28T17:50:51,975 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-03-28T17:50:51,988 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9008, pid=329092
2025-03-28T17:50:51,988 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9008
2025-03-28T17:50:51,990 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9015, pid=329084
2025-03-28T17:50:51,990 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9015
2025-03-28T17:50:51,992 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:51,996 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:51,997 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:51,997 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - [PID]329092
2025-03-28T17:50:51,997 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:51,997 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:51,997 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:51,998 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:51,998 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:51,998 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:50:51,998 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2025-03-28T17:50:52,000 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,000 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,001 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9008.
2025-03-28T17:50:52,001 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652001
2025-03-28T17:50:52,001 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652001
2025-03-28T17:50:52,002 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652002
2025-03-28T17:50:52,002 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652002
2025-03-28T17:50:52,005 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:52,005 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - [PID]329084
2025-03-28T17:50:52,006 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:52,006 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,006 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,006 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:50:52,006 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:52,006 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2025-03-28T17:50:52,008 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9019, pid=329088
2025-03-28T17:50:52,009 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9019
2025-03-28T17:50:52,017 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652017
2025-03-28T17:50:52,017 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652017
2025-03-28T17:50:52,017 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652017
2025-03-28T17:50:52,017 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652017
2025-03-28T17:50:52,017 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9011, pid=329093
2025-03-28T17:50:52,017 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9011
2025-03-28T17:50:52,021 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,021 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9015.
2025-03-28T17:50:52,027 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:52,028 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - [PID]329088
2025-03-28T17:50:52,028 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:52,028 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:52,029 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,029 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,029 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:50:52,029 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9019
2025-03-28T17:50:52,030 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652030
2025-03-28T17:50:52,030 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652030
2025-03-28T17:50:52,031 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9019.
2025-03-28T17:50:52,031 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652031
2025-03-28T17:50:52,031 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652031
2025-03-28T17:50:52,033 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:52,033 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - [PID]329093
2025-03-28T17:50:52,033 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:52,033 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:52,033 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,033 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,034 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:50:52,034 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2025-03-28T17:50:52,035 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652035
2025-03-28T17:50:52,035 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652035
2025-03-28T17:50:52,035 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9011.
2025-03-28T17:50:52,035 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652035
2025-03-28T17:50:52,035 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652035
2025-03-28T17:50:52,035 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,046 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=329078
2025-03-28T17:50:52,047 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-03-28T17:50:52,049 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,058 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,061 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:52,062 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - [PID]329078
2025-03-28T17:50:52,062 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:52,062 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:52,063 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,063 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,063 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:50:52,063 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2025-03-28T17:50:52,065 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9016, pid=329090
2025-03-28T17:50:52,066 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9016
2025-03-28T17:50:52,066 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-03-28T17:50:52,067 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652067
2025-03-28T17:50:52,067 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652067
2025-03-28T17:50:52,067 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652067
2025-03-28T17:50:52,067 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652067
2025-03-28T17:50:52,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:52,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - [PID]329090
2025-03-28T17:50:52,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:52,079 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:52,085 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9014, pid=329083
2025-03-28T17:50:52,080 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,080 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,088 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:50:52,088 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9016
2025-03-28T17:50:52,090 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9014
2025-03-28T17:50:52,090 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9016.
2025-03-28T17:50:52,086 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,094 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652094
2025-03-28T17:50:52,094 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652094
2025-03-28T17:50:52,094 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652094
2025-03-28T17:50:52,094 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652094
2025-03-28T17:50:52,100 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:52,100 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - [PID]329083
2025-03-28T17:50:52,100 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:52,101 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:52,102 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,102 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,103 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:50:52,103 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2025-03-28T17:50:52,108 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9014.
2025-03-28T17:50:52,109 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652109
2025-03-28T17:50:52,109 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652109
2025-03-28T17:50:52,109 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652109
2025-03-28T17:50:52,109 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652109
2025-03-28T17:50:52,119 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9018, pid=329087
2025-03-28T17:50:52,120 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9018
2025-03-28T17:50:52,122 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9013, pid=329089
2025-03-28T17:50:52,123 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9013
2025-03-28T17:50:52,130 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,134 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:52,135 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - [PID]329089
2025-03-28T17:50:52,135 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,135 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,135 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:50:52,135 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2025-03-28T17:50:52,136 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:52,136 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:52,137 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:52,137 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - [PID]329087
2025-03-28T17:50:52,138 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,138 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,138 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:50:52,138 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9018
2025-03-28T17:50:52,138 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:52,138 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:52,138 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,139 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652139
2025-03-28T17:50:52,139 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652139
2025-03-28T17:50:52,140 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9013.
2025-03-28T17:50:52,143 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652143
2025-03-28T17:50:52,143 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652143
2025-03-28T17:50:52,143 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652143
2025-03-28T17:50:52,143 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652143
2025-03-28T17:50:52,143 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652143
2025-03-28T17:50:52,143 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9018.
2025-03-28T17:50:52,143 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652143
2025-03-28T17:50:52,167 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=329074
2025-03-28T17:50:52,168 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-03-28T17:50:52,170 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,175 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,181 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:52,182 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - [PID]329074
2025-03-28T17:50:52,182 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:52,182 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:52,182 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,182 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,182 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:50:52,182 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2025-03-28T17:50:52,188 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=329080
2025-03-28T17:50:52,189 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-03-28T17:50:52,189 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652189
2025-03-28T17:50:52,189 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652189
2025-03-28T17:50:52,189 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652189
2025-03-28T17:50:52,189 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652189
2025-03-28T17:50:52,189 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-03-28T17:50:52,203 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:52,204 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - [PID]329080
2025-03-28T17:50:52,204 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:52,204 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,204 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:52,204 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,206 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:50:52,206 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2025-03-28T17:50:52,208 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9007, pid=329075
2025-03-28T17:50:52,210 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652210
2025-03-28T17:50:52,210 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652210
2025-03-28T17:50:52,211 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652211
2025-03-28T17:50:52,211 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652211
2025-03-28T17:50:52,212 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-03-28T17:50:52,212 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9007
2025-03-28T17:50:52,216 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,221 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:52,222 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - [PID]329075
2025-03-28T17:50:52,222 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:52,222 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:52,223 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,223 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,223 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:50:52,223 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2025-03-28T17:50:52,228 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652228
2025-03-28T17:50:52,228 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652228
2025-03-28T17:50:52,228 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652228
2025-03-28T17:50:52,228 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652228
2025-03-28T17:50:52,228 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9007.
2025-03-28T17:50:52,240 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,242 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,290 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9006, pid=329076
2025-03-28T17:50:52,293 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9006
2025-03-28T17:50:52,307 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:52,308 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - [PID]329076
2025-03-28T17:50:52,310 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:52,310 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:52,311 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,311 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,311 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:50:52,311 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2025-03-28T17:50:52,316 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652316
2025-03-28T17:50:52,316 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652316
2025-03-28T17:50:52,317 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652317
2025-03-28T17:50:52,317 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652317
2025-03-28T17:50:52,318 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9006.
2025-03-28T17:50:52,329 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=329081
2025-03-28T17:50:52,330 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-03-28T17:50:52,338 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,341 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:52,341 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - [PID]329081
2025-03-28T17:50:52,342 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:52,342 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,342 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,342 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:50:52,342 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2025-03-28T17:50:52,342 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:52,348 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652348
2025-03-28T17:50:52,348 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652348
2025-03-28T17:50:52,348 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652348
2025-03-28T17:50:52,348 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652348
2025-03-28T17:50:52,349 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-03-28T17:50:52,374 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:52,376 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=329073
2025-03-28T17:50:52,377 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-03-28T17:50:52,390 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Successfully loaded /home/equarmjn/.pyenv/versions/3.10.16/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-03-28T17:50:52,391 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - [PID]329073
2025-03-28T17:50:52,391 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Torch worker started.
2025-03-28T17:50:52,391 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,391 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change null -> WORKER_STARTED
2025-03-28T17:50:52,391 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:50:52,391 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2025-03-28T17:50:52,391 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Python runtime: 3.10.16
2025-03-28T17:50:52,396 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652396
2025-03-28T17:50:52,396 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1743198652396
2025-03-28T17:50:52,396 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652396
2025-03-28T17:50:52,396 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198652396
2025-03-28T17:50:52,397 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-03-28T17:50:52,428 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - model_name: densenet161, batchSize: 1
2025-03-28T17:50:54,179 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,194 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,202 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,206 [INFO ] W-9009-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,219 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,220 [INFO ] W-9008-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,222 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,226 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,228 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,246 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,247 [INFO ] W-9004-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,252 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,253 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,253 [INFO ] W-9000-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,254 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,258 [INFO ] W-9010-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,263 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,277 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,278 [INFO ] W-9012-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,286 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,287 [INFO ] W-9017-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,290 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,299 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,310 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,310 [INFO ] W-9019-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,314 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,325 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,325 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,346 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,348 [INFO ] W-9011-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,405 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,418 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,430 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,433 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,438 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,438 [INFO ] W-9013-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,454 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,454 [INFO ] W-9014-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,456 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,456 [INFO ] W-9006-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,483 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,483 [INFO ] W-9016-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,489 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,494 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,506 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,511 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,521 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,523 [INFO ] W-9007-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,532 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,532 [INFO ] W-9005-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,538 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,542 [INFO ] W-9018-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,540 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,543 [INFO ] W-9001-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,636 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,661 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,663 [INFO ] W-9002-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:50:54,841 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-03-28T17:50:54,866 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - ONNX enabled
2025-03-28T17:50:54,867 [INFO ] W-9003-densenet161_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-03-28T17:51:11,708 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19691
2025-03-28T17:51:11,708 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19691
2025-03-28T17:51:11,708 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:11,708 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:11,708 [INFO ] W-9015-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:21749.0|#WorkerName:W-9015-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198671
2025-03-28T17:51:11,708 [INFO ] W-9015-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198671
2025-03-28T17:51:12,794 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 20845
2025-03-28T17:51:12,794 [INFO ] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 20845
2025-03-28T17:51:12,795 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:12,795 [DEBUG] W-9010-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:12,803 [INFO ] W-9010-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:22845.0|#WorkerName:W-9010-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198672
2025-03-28T17:51:12,804 [INFO ] W-9010-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:10.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198672
2025-03-28T17:51:13,630 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21483
2025-03-28T17:51:13,630 [INFO ] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21483
2025-03-28T17:51:13,630 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:13,630 [DEBUG] W-9018-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9018-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:13,630 [INFO ] W-9018-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:23670.0|#WorkerName:W-9018-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198673
2025-03-28T17:51:13,630 [INFO ] W-9018-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:4.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198673
2025-03-28T17:51:14,584 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22475
2025-03-28T17:51:14,584 [INFO ] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22475
2025-03-28T17:51:14,584 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:14,584 [DEBUG] W-9014-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:14,584 [INFO ] W-9014-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:24625.0|#WorkerName:W-9014-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198674
2025-03-28T17:51:14,584 [INFO ] W-9014-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198674
2025-03-28T17:51:14,790 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22759
2025-03-28T17:51:14,790 [INFO ] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22759
2025-03-28T17:51:14,790 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:14,790 [DEBUG] W-9019-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9019-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:14,790 [INFO ] W-9019-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:24830.0|#WorkerName:W-9019-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198674
2025-03-28T17:51:14,790 [INFO ] W-9019-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198674
2025-03-28T17:51:14,793 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22758
2025-03-28T17:51:14,793 [INFO ] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22758
2025-03-28T17:51:14,793 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:14,793 [DEBUG] W-9011-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:14,793 [INFO ] W-9011-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:24834.0|#WorkerName:W-9011-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198674
2025-03-28T17:51:14,793 [INFO ] W-9011-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198674
2025-03-28T17:51:14,896 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22894
2025-03-28T17:51:14,896 [INFO ] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22894
2025-03-28T17:51:14,896 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:14,896 [DEBUG] W-9008-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:14,896 [INFO ] W-9008-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:24938.0|#WorkerName:W-9008-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198674
2025-03-28T17:51:14,896 [INFO ] W-9008-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198674
2025-03-28T17:51:15,530 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23581
2025-03-28T17:51:15,530 [INFO ] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23581
2025-03-28T17:51:15,531 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:15,531 [DEBUG] W-9009-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:15,531 [INFO ] W-9009-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:25573.0|#WorkerName:W-9009-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198675
2025-03-28T17:51:15,531 [INFO ] W-9009-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:4.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198675
2025-03-28T17:51:15,642 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23548
2025-03-28T17:51:15,642 [INFO ] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23548
2025-03-28T17:51:15,642 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:15,642 [DEBUG] W-9016-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9016-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:15,642 [INFO ] W-9016-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:25682.0|#WorkerName:W-9016-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198675
2025-03-28T17:51:15,642 [INFO ] W-9016-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198675
2025-03-28T17:51:15,756 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23807
2025-03-28T17:51:15,756 [INFO ] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23807
2025-03-28T17:51:15,756 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:15,756 [DEBUG] W-9017-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9017-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:15,756 [INFO ] W-9017-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:25796.0|#WorkerName:W-9017-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198675
2025-03-28T17:51:15,756 [INFO ] W-9017-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198675
2025-03-28T17:51:15,815 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23846
2025-03-28T17:51:15,815 [INFO ] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23846
2025-03-28T17:51:15,815 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:15,815 [DEBUG] W-9012-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:15,815 [INFO ] W-9012-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:25856.0|#WorkerName:W-9012-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198675
2025-03-28T17:51:15,815 [INFO ] W-9012-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198675
2025-03-28T17:51:15,952 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23556
2025-03-28T17:51:15,952 [INFO ] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23556
2025-03-28T17:51:15,952 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:15,952 [DEBUG] W-9002-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:15,952 [INFO ] W-9002-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:25997.0|#WorkerName:W-9002-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198675
2025-03-28T17:51:15,952 [INFO ] W-9002-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198675
2025-03-28T17:51:16,150 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23833
2025-03-28T17:51:16,150 [INFO ] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23833
2025-03-28T17:51:16,150 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,150 [DEBUG] W-9006-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,150 [INFO ] W-9006-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:26192.0|#WorkerName:W-9006-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:16,150 [INFO ] W-9006-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:16,192 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24219
2025-03-28T17:51:16,192 [INFO ] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24219
2025-03-28T17:51:16,192 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,192 [DEBUG] W-9000-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,192 [INFO ] W-9000-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:26239.0|#WorkerName:W-9000-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:16,192 [INFO ] W-9000-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:16,267 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24124
2025-03-28T17:51:16,267 [INFO ] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24124
2025-03-28T17:51:16,267 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,267 [DEBUG] W-9013-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,267 [INFO ] W-9013-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:26308.0|#WorkerName:W-9013-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:16,267 [INFO ] W-9013-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:4.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:16,280 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24069
2025-03-28T17:51:16,280 [INFO ] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24069
2025-03-28T17:51:16,280 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,280 [DEBUG] W-9001-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,280 [INFO ] W-9001-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:26326.0|#WorkerName:W-9001-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:16,280 [INFO ] W-9001-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:16,282 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24093
2025-03-28T17:51:16,282 [INFO ] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24093
2025-03-28T17:51:16,282 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,282 [DEBUG] W-9005-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,282 [INFO ] W-9005-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:26327.0|#WorkerName:W-9005-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:16,282 [INFO ] W-9005-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:16,287 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24220
2025-03-28T17:51:16,287 [INFO ] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24220
2025-03-28T17:51:16,287 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,287 [DEBUG] W-9004-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,287 [INFO ] W-9004-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:26332.0|#WorkerName:W-9004-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:16,287 [INFO ] W-9004-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:16,318 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24090
2025-03-28T17:51:16,318 [INFO ] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24090
2025-03-28T17:51:16,318 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,318 [DEBUG] W-9007-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,319 [INFO ] W-9007-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:26360.0|#WorkerName:W-9007-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:16,319 [INFO ] W-9007-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:16,325 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23977
2025-03-28T17:51:16,325 [INFO ] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23977
2025-03-28T17:51:16,325 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,325 [DEBUG] W-9003-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-densenet161_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-03-28T17:51:16,325 [INFO ] W-9003-densenet161_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:26370.0|#WorkerName:W-9003-densenet161_1.0,Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:16,325 [INFO ] W-9003-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198676
2025-03-28T17:51:23,146 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:densenet161,model_version:default|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198683
2025-03-28T17:51:23,147 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1743198683147
2025-03-28T17:51:23,147 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1743198683147
2025-03-28T17:51:23,147 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198683147
2025-03-28T17:51:23,147 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1743198683147
2025-03-28T17:51:23,148 [INFO ] W-9015-densenet161_1.0-stdout MODEL_LOG - Backend received inference at: 1743198683
2025-03-28T17:51:23,267 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:119.29|#ModelName:densenet161,Level:Model|#type:GAUGE|#hostname:equarmjn-thinkpadp1gen5.rht.csb,1743198683,d569fa39-19ab-4814-a148-f70f0f08e258, pattern=[METRICS]
2025-03-28T17:51:23,267 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:119.29|#ModelName:densenet161,Level:Model|#type:GAUGE|#hostname:equarmjn-thinkpadp1gen5.rht.csb,1743198683,d569fa39-19ab-4814-a148-f70f0f08e258, pattern=[METRICS]
2025-03-28T17:51:23,268 [INFO ] W-9015-densenet161_1.0-stdout MODEL_METRICS - HandlerTime.ms:119.29|#ModelName:densenet161,Level:Model|#hostname:equarmjn-thinkpadp1gen5.rht.csb,requestID:d569fa39-19ab-4814-a148-f70f0f08e258,timestamp:1743198683
2025-03-28T17:51:23,268 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:119.43|#ModelName:densenet161,Level:Model|#type:GAUGE|#hostname:equarmjn-thinkpadp1gen5.rht.csb,1743198683,d569fa39-19ab-4814-a148-f70f0f08e258, pattern=[METRICS]
2025-03-28T17:51:23,268 [INFO ] W-9015-densenet161_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:119.43|#ModelName:densenet161,Level:Model|#type:GAUGE|#hostname:equarmjn-thinkpadp1gen5.rht.csb,1743198683,d569fa39-19ab-4814-a148-f70f0f08e258, pattern=[METRICS]
2025-03-28T17:51:23,268 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId d569fa39-19ab-4814-a148-f70f0f08e258
2025-03-28T17:51:23,268 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId d569fa39-19ab-4814-a148-f70f0f08e258
2025-03-28T17:51:23,268 [INFO ] W-9015-densenet161_1.0-stdout MODEL_METRICS - PredictionTime.ms:119.43|#ModelName:densenet161,Level:Model|#hostname:equarmjn-thinkpadp1gen5.rht.csb,requestID:d569fa39-19ab-4814-a148-f70f0f08e258,timestamp:1743198683
2025-03-28T17:51:23,268 [INFO ] W-9015-densenet161_1.0 ACCESS_LOG - /127.0.0.1:60264 "PUT /predictions/densenet161 HTTP/1.1" 200 123
2025-03-28T17:51:23,268 [INFO ] W-9015-densenet161_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198683
2025-03-28T17:51:23,269 [INFO ] W-9015-densenet161_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:121423.718|#model_name:densenet161,model_version:default|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198683
2025-03-28T17:51:23,269 [INFO ] W-9015-densenet161_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:135.031|#model_name:densenet161,model_version:default|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198683
2025-03-28T17:51:23,269 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 135031, Backend time ns: 122073360
2025-03-28T17:51:23,269 [DEBUG] W-9015-densenet161_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 135031, Backend time ns: 122073360
2025-03-28T17:51:23,269 [INFO ] W-9015-densenet161_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198683
2025-03-28T17:51:23,269 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 121
2025-03-28T17:51:23,269 [INFO ] W-9015-densenet161_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 121
2025-03-28T17:51:23,269 [INFO ] W-9015-densenet161_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198683
2025-03-28T17:51:50,486 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198710
2025-03-28T17:51:50,486 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:216.46178817749023|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198710
2025-03-28T17:51:50,486 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:733.9274940490723|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198710
2025-03-28T17:51:50,486 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:77.2|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198710
2025-03-28T17:51:50,486 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26291.9453125|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198710
2025-03-28T17:51:50,486 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:28770.1640625|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198710
2025-03-28T17:51:50,487 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:58.9|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198710
2025-03-28T17:52:50,485 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:33.3|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198770
2025-03-28T17:52:50,485 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:216.46058654785156|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198770
2025-03-28T17:52:50,485 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:733.9286956787109|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198770
2025-03-28T17:52:50,485 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:77.2|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198770
2025-03-28T17:52:50,485 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26329.2578125|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198770
2025-03-28T17:52:50,485 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:28802.48828125|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198770
2025-03-28T17:52:50,485 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:58.9|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198770
2025-03-28T17:53:50,490 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198830
2025-03-28T17:53:50,490 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:216.46066284179688|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198830
2025-03-28T17:53:50,490 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:733.9286499023438|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198830
2025-03-28T17:53:50,490 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:77.2|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198830
2025-03-28T17:53:50,490 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26411.2265625|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198830
2025-03-28T17:53:50,490 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:28717.84765625|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198830
2025-03-28T17:53:50,490 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:58.7|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198830
2025-03-28T17:54:50,491 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:33.3|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198890
2025-03-28T17:54:50,491 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:216.46156692504883|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198890
2025-03-28T17:54:50,491 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:733.9277458190918|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198890
2025-03-28T17:54:50,491 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:77.2|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198890
2025-03-28T17:54:50,491 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26396.8984375|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198890
2025-03-28T17:54:50,491 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:28751.57421875|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198890
2025-03-28T17:54:50,491 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:58.8|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198890
2025-03-28T17:55:50,495 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198950
2025-03-28T17:55:50,495 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:216.46070098876953|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198950
2025-03-28T17:55:50,495 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:733.9286117553711|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198950
2025-03-28T17:55:50,495 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:77.2|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198950
2025-03-28T17:55:50,495 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26518.4609375|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198950
2025-03-28T17:55:50,495 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:28742.5390625|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198950
2025-03-28T17:55:50,495 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:58.6|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743198950
2025-03-28T17:56:50,491 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199010
2025-03-28T17:56:50,491 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:212.654052734375|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199010
2025-03-28T17:56:50,491 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:737.7884826660156|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199010
2025-03-28T17:56:50,491 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:77.6|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199010
2025-03-28T17:56:50,492 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26150.00390625|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199010
2025-03-28T17:56:50,492 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:28794.76953125|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199010
2025-03-28T17:56:50,492 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:59.1|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199010
2025-03-28T17:57:50,493 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199070
2025-03-28T17:57:50,493 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:212.44737243652344|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199070
2025-03-28T17:57:50,493 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:738.0027313232422|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199070
2025-03-28T17:57:50,493 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:77.6|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199070
2025-03-28T17:57:50,493 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:25990.984375|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199070
2025-03-28T17:57:50,493 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:28959.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199070
2025-03-28T17:57:50,494 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:59.4|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199070
2025-03-28T17:58:50,495 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199130
2025-03-28T17:58:50,496 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:212.20858001708984|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199130
2025-03-28T17:58:50,496 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:738.2427139282227|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199130
2025-03-28T17:58:50,496 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:77.7|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199130
2025-03-28T17:58:50,496 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:26162.921875|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199130
2025-03-28T17:58:50,496 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:28765.390625|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199130
2025-03-28T17:58:50,496 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:59.1|#Level:Host|#hostname:equarmjn-thinkpadp1gen5.rht.csb,timestamp:1743199130
